[
  {
    "title": "init(kernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondescriptor/1648876-init",
    "html": "Parameters\nkernelWidth\n\nThe width of the kernel window.\n\nThis value must be >0. Larger values will take a longer time to process.\n\nkernelHeight\n\nThe height of the kernel window.\n\nThe value must be >0. Larger values will take a longer time to process.\n\ninputFeatureChannels\n\nThe number of feature channels in the input image.\n\nThis value must be >=1.\n\noutputFeatureChannels\n\nThe number of feature channels in the output image.\n\nThis value must be >=1.\n\nneuronFilter\n\nAn optional neuron filter that can be applied to the output of the convolution operation.\n\nReturn Value\n\nA valid MPSCNNConvolution object or nil, if failure."
  },
  {
    "title": "neuron | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondescriptor/1829442-neuron",
    "html": "Discussion\n\nThe default value is nil."
  },
  {
    "title": "strideInPixelsX | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondescriptor/1648908-strideinpixelsx",
    "html": "Discussion\n\nThe default value is 1."
  },
  {
    "title": "numberOfHistogramEntries | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistograminfo/1618805-numberofhistogramentries",
    "html": "Discussion\n\nThis value must be both a power of 2 and a minimum of 256 bins.\n\nFor example, if you want 256 histogram bins then this value must be set to 256. The value stored in each histogram bin is a 32-bit unsigned integer. The size of the histogram buffer in which these bins will be stored should be more than or equal to:\n\nnumber of histogram entries * sizeof(uint32_t) * number of channels in the image"
  },
  {
    "title": "MPSOrigin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsorigin",
    "html": "Overview\n\nThe double data type is used because some kernel operations require fractional precision—for example, the MPSImageLanczosScale filter.\n\nTopics\nInitializers\ninit()\ninit(x: Double, y: Double, z: Double)\nInstance Properties\nvar x: Double\nThe x coordinate of the position, in pixels.\nvar y: Double\nThe y coordinate of the position, in pixels.\nvar z: Double\nThe z coordinate of the position, in pixels."
  },
  {
    "title": "MPSSize | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpssize",
    "html": "Overview\n\nThe depth of a region is usually 1.0.\n\nThe double data type is used because some kernel operations require fractional precision—for example, the MPSImageLanczosScale filter.\n\nTopics\nInitializers\ninit()\ninit(width: Double, height: Double, depth: Double)\nInstance Properties\nvar depth: Double\nThe depth of the region, in pixels.\nvar height: Double\nThe height of the region, in pixels.\nvar width: Double\nThe width of the region, in pixels."
  },
  {
    "title": "load() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondatasource/2867049-load",
    "html": "Required"
  },
  {
    "title": "dataType() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondatasource/2867139-datatype",
    "html": "Required"
  },
  {
    "title": "label() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondatasource/2881197-label",
    "html": "Required"
  },
  {
    "title": "purge() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondatasource/2867134-purge",
    "html": "Required"
  },
  {
    "title": "biasTerms() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondatasource/2867023-biasterms",
    "html": "Required"
  },
  {
    "title": "descriptor() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondatasource/2867050-descriptor",
    "html": "Required"
  },
  {
    "title": "weights() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondatasource/2867187-weights",
    "html": "Required"
  },
  {
    "title": "skipAPIValidation | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpskerneloptions/1618826-skipapivalidation",
    "html": "Discussion\n\nMost kernels double-check their arguments. This has a small but nonzero CPU cost. Setting this option, however, does not skip checks for memory allocation failure. Turning on this option can result in undefined behavior if the requested operation cannot be completed for some reason. Most error states will be passed through to Metal, which may do nothing or abort the program if Metal API validation is turned on."
  },
  {
    "title": "MPSRNNRecurrentImageState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnrecurrentimagestate",
    "html": "Topics\nInstance Methods\nfunc getMemoryCellImage(forLayerIndex: Int) -> MPSImage?\nfunc getRecurrentOutputImage(forLayerIndex: Int) -> MPSImage?\nRelationships\nInherits From\nMPSState"
  },
  {
    "title": "MPSRNNRecurrentMatrixState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnrecurrentmatrixstate",
    "html": "Topics\nInstance Methods\nfunc getMemoryCellMatrix(forLayerIndex: Int) -> MPSMatrix?\nfunc getRecurrentOutputMatrix(forLayerIndex: Int) -> MPSMatrix?\nRelationships\nInherits From\nMPSState"
  },
  {
    "title": "MPSRNNBidirectionalCombineMode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnbidirectionalcombinemode",
    "html": "Topics\nEnumeration Cases\ncase add\nA mode in which two sequences are summed to form a single output.\ncase concatenate\nA mode in which two sequences are concatenated along the feature channels to form a single output.\ncase none\nA mode in which two sequences are kept separate.\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSRNNDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnndescriptor",
    "html": "Topics\nInstance Properties\nvar inputFeatureChannels: Int\nvar layerSequenceDirection: MPSRNNSequenceDirection\nvar outputFeatureChannels: Int\nvar useFloat32Weights: Bool\nvar useLayerInputUnitTransformMode: Bool\nRelationships\nInherits From\nNSObject"
  },
  {
    "title": "init(device:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronsigmoid/1648890-init",
    "html": "Parameters\ndevice\n\nThe device the filter will run on.\n\nReturn Value\n\nA valid MPSCNNNeuronSigmoid object or nil, if failure."
  },
  {
    "title": "rowBytes | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix/2143208-rowbytes",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the matrix will be used.\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nvar data: MTLBuffer\nThe buffer that stores the matrix data.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "MPSNNPaddingMethod | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnpaddingmethod",
    "html": "Overview\n\nThe MPSNNGraph must make automatic decisions about how big to make the result of each filter node. This is typically determined by a combination of input image size, size of the filter window (for example, convolution weights), filter stride, and a description of how much extra space beyond the edges of the image to allow the filter read. By knowing the properties of the filter, you can then infer the size of the result image. Most of this information is known to the MPSNNGraph as part of its normal operation. However, the amount of padding to add and where to add it is a matter of choice left to you. Different neural network frameworks such as TensorFlow and Caffe make different choices here. Depending on where your network was trained, you will need to adjust the policies used by MPS during inference. In the event that the padding method is not simply described by this enumeration, you may provide you own custom policy definition by overriding the destinationImageDescriptor(forSourceImages:sourceStates:for:suggestedDescriptor:) method in a custom MPSNNPadding child class. Common values that influence the size of the result image by adjusting the amount of padding added to the source images:\n\nvalidOnly Result values are only produced for the area that is guaranteed to have all of its input values defined (i.e. not off the edge). This produces the smallest result image\n\nsizeSame The result image is the same size as the input image. If the stride is not 1, then the result is scaled accordingly.\n\nsizeFull Result values are produced for any position for which at least one input value is defined (i.e. not off the edge).\n\ncustom The sizing and centering policy is given by the destinationImageDescriptor(forSourceImages:sourceStates:for:suggestedDescriptor:).\n\nExcept possibly when custom is used, the area within the source image that is read will be centered on the source image. Even so, at times the area can not be perfectly centered because the source image has odd size and the region read has even size, or vice versa. In such cases, you may use the following values to select where to put the extra padding:\n\ntopLeft\n\n\t\n\nLeftover padding is added to the top or left side of image as appropriate.\n\n\n\n\naddRemainderToBottomRight\n\n\t\n\nLeftover padding is added to the bottom or right side of image as appropriate.\n\nHere again, different external frameworks may use different policies.  \n\nIn some cases, Caffe introduces the notion of a region beyond the padding which is invalid. This can happen when the padding is set to a width narrower than what is needed for a destination size. In such cases, MPSCNNPaddingMethodExcludeEdges is used to adjust normalization factors for filter weights (particularly in pooling) such that invalid regions beyond the padding are not counted towards the filter area. Currently, only pooling supports this feature. Other filters ignore it.\n\n The size and a add remainder policies always appear together in the MPSNNPaddingMethod. There is no provision for a size policy without a remainder policy or vice versa. It is, in practice, used as a bit field.\n\n Most MPS neural network filters are considered forward filters. Some (for example, convolution transpose and unpooling) are considered reverse filters. For the reverse filters, the image stride is measured in destination values rather than source values and has the effect of enlarging the image rather than reducing it. When a reverse filter is used to \"undo\" the effects of a forward filter, the size policy should be the opposite of the forward padding method. For example, if the forward filter used validOnly | topLeft, the reverse filter should use sizeFull | topLeft. Some consideration of the geometry of inputs and outputs will reveal why this is so. It is usually not important to adjust the centering method because the size of the reverse result generally doesn't suffer from centering asymmetries. That is: the size would usually be given by:  \n\nstatic int DestSizeReverse( int sourceSize, int stride, int filterWindowSize, Style style ) {\n    // style = {-1,0,1} for valid-only, same, full\n    return (sourceSize-1) * stride + 1 + style  * (filterWindowSize-1);  \n}  \n\n\nso the result size is exactly the one needed for the source size and there are no centering problems. In some cases where the reverse pass is intended to completely reverse a forward pass, the MPSState object produced by the forward pass should be used to determine the size of the reverse pass result image.\n\n Tensorflow does not appear to provide a full padding method, but instead appears to use its valid-only padding mode for reverse filters to in effect achieve what is called sizeFull here.    \n\nWalkthrough of Operation of Padding Policy\n\nMost MPSCNNKernel objects have two types of encode calls. There is one for which you must pass in a preallocated MPSImage to receive the results. This is for manual configuration. It assumes you know what you are doing, and asks you to correctly set a diversity of properties to correctly position image inputs and size results. It does not use the padding policy. You must size the result correctly, set the clipRect, offset and other properties as needed yourself.\n\nLayered on top of that is usually another flavor of encode call that returns a destination image instead from the left hand side of the function. It is designed to automatically configure itself based on the paddingPolicy. When this more automated encode method is called, it invokes a method in the MPSKernel that looks at the MPSNNPaddingMethod bitfield of the policy. Based on the information therein and the size of the input images and other filter properties, it determines the size of the output, sets the offset property, and returns an appropriate MPSImageDescriptor for the destination image.\n\nIf you set the custom bit in the MPSNNPaddingMethod, then the destinationImageDescriptor(forSourceImages:sourceStates:for:suggestedDescriptor:) method is called. The MPSImageDescriptor prepared earlier is passed in as the last parameter. You can use this descriptor or modify as needed. In addition, you can adjust any properties of the MPSKernel with which it will be used. If, for example, the descriptor is not the right MPSImageFeatureChannelFormat, you can change it, or make your own MPSImageDescriptor based on the one handed to you. This is your opportunity to customize the configuration of the MPSKernel. In some cases (for example, forTensorflowAveragePooling()) you might change other properties such as the filter edging mode, or adjust the offset that was already set for you. When the kernel is fully configured, return the MPSImageDescriptor.\n\nThe MPSImageDescriptor is then passed to the destinationImageAllocator to allocate the image. You might provide such an allocator if you want to use your own custom MTLHeap rather than the MPS internal heap. The allocator can be set either directly in the MPSCNNKernel or through the imageAllocator property.\n\nIt is intended that most of the time, default values for padding method and destination image allocator should be good enough. Only minimal additional configuration should be required, apart from occasional adjustments to set the MPSNNPaddingMethod when something other than default padding for the object is needed. If you find yourself encumbered by frequent adjustments of this kind, you might find it to your advantage to subclass MPSNNFilterNode or MPSCNNKernel objects to adjust the default padding policy and allocator at initialization time.\n\nTopics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var addRemainderToBottomLeft: MPSNNPaddingMethod\nstatic var addRemainderToBottomRight: MPSNNPaddingMethod\nstatic var addRemainderToMask: MPSNNPaddingMethod\nstatic var addRemainderToTopRight: MPSNNPaddingMethod\nstatic var alignBottomRight: MPSNNPaddingMethod\nstatic var alignMask: MPSNNPaddingMethod\nstatic var alignTopLeft: MPSNNPaddingMethod\nstatic var align_reserved: MPSNNPaddingMethod\nstatic var custom: MPSNNPaddingMethod\nstatic var sizeFull: MPSNNPaddingMethod\nstatic var sizeMask: MPSNNPaddingMethod\nstatic var sizeSame: MPSNNPaddingMethod\nstatic var size_reserved: MPSNNPaddingMethod\nstatic var excludeEdges: MPSNNPaddingMethod\nstatic var centered: MPSNNPaddingMethod\nstatic var customAllowForNodeFusion: MPSNNPaddingMethod\nstatic var customWhitelistForNodeFusion: MPSNNPaddingMethod\nDeprecated\nstatic var topLeft: MPSNNPaddingMethod\nA padding method where leftover padding is added to the top or left side of image as appropriate.\nstatic var validOnly: MPSNNPaddingMethod\nA padding method where result values are only produced for the area that is guaranteed to have all of its input values defined\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "matrices | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix/2873334-matrices",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the matrix will be used.\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar data: MTLBuffer\nThe buffer that stores the matrix data.\nvar matrixBytes: Int"
  },
  {
    "title": "matrixBytes | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix/2873344-matrixbytes",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the matrix will be used.\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar data: MTLBuffer\nThe buffer that stores the matrix data.\nvar matrices: Int"
  },
  {
    "title": "data | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix/2143205-data",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the matrix will be used.\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "init(buffer:descriptor:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix/2143201-init",
    "html": "Parameters\nbuffer\n\nThe buffer that stores the matrix data.\n\ndescriptor\n\nThe matrix descriptor.\n\nReturn Value\n\nA valid MPSMatrix object or nil, if failure.\n\nDiscussion\n\nThe dimensions and stride of the matrix are specified by the MPSMatrixDescriptor object. The size of the provided MTLBuffer object must be large enough to store the following amount of bytes:\n\n(descriptor.rows-1) * descriptor.rowBytes + descriptor.columns * (element size)"
  },
  {
    "title": "dataType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix/2143197-datatype",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the matrix will be used.\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar data: MTLBuffer\nThe buffer that stores the matrix data.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "columns | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix/2143207-columns",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the matrix will be used.\nvar rows: Int\nThe number of rows in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar data: MTLBuffer\nThe buffer that stores the matrix data.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "rows | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix/2143210-rows",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the matrix will be used.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar data: MTLBuffer\nThe buffer that stores the matrix data.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "device | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix/2143209-device",
    "html": "See Also\nProperties\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar data: MTLBuffer\nThe buffer that stores the matrix data.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "init(device:transposeLeft:transposeRight:resultRows:resultColumns:interiorColumns:alpha:beta:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixmultiplication/2147845-init",
    "html": "Parameters\ndevice\n\nThe device on which the matrix multiplication kernel will run.\n\ntransposeLeft\n\nA boolean value that indicates if the left input matrix should be used in its transposed form. If the value is true, then op(A) = A**T; otherwise, op(A) = A.\n\ntransposeRight\n\nA boolean value that indicates if the right input matrix should be used in its transposed form. If the value is true, then op(B) = B**T; otherwise, op(B) = B.\n\nresultRows\n\nThe number of rows in the result matrix (M in the BLAS GEMM description).\n\nresultColumns\n\nThe number of columns in the result matrix (N in the BLAS GEMM description).\n\ninteriorColumns\n\nThe number of columns of the left input matrix after the appropriate transpose operation has been applied (K in the BLAS GEMM description).\n\nalpha\n\nThe scale factor to apply to the product, specified in double precision. This value will be converted to the appropriate precision in the implementation itself, subject to rounding and/or clamping as necessary.\n\nbeta\n\nThe scale factor to apply to the initial values of C, specified in double precision. This value will be converted to the appropriate precision in the implementation itself, subject to rounding and/or clamping as necessary.\n\nReturn Value\n\nA valid MPSMatrixMultiplication object or nil, if failure.\n\nSee Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, leftMatrix: MPSMatrix, rightMatrix: MPSMatrix, resultMatrix: MPSMatrix)\nEncodes a matrix multiplication kernel to a command buffer."
  },
  {
    "title": "init(device:a:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronrelu/1648926-init",
    "html": "Parameters\ndevice\n\nThe device the filter will run on.\n\na\n\nThe \"a\" variable of the filter function.\n\nReturn Value\n\nA valid MPSCNNNeuronReLU object or nil, if failure."
  },
  {
    "title": "leftMatrixOrigin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixmultiplication/2147846-leftmatrixorigin",
    "html": "Discussion\n\nThe origin, relative to (0,0), at which to start reading values. If a different origin is desired, you must modify this property before encoding the matrix multiplication kernel. The default value is (0,0,0) (the z value must always be 0).\n\nSee Also\nProperties\nvar rightMatrixOrigin: MTLOrigin\nThe origin of the right input matrix.\nvar resultMatrixOrigin: MTLOrigin\nThe origin of the result matrix.\nvar batchSize: Int\nvar batchStart: Int"
  },
  {
    "title": "encode(commandBuffer:leftMatrix:rightMatrix:resultMatrix:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixmultiplication/2147848-encode",
    "html": "Parameters\ncommandBuffer\n\nThe command buffer that will receive the encoded kernel.\n\nleftMatrix\n\nThe left input matrix.\n\nrightMatrix\n\nThe right input matrix.\n\nresultMatrix\n\nThe addend matrix which will also be overwritten by the operation result.\n\nDiscussion\n\nThe following constraints apply to the sizes of the matrices depending on the transposition operations and the sizes requested at initialization time, as well as the origins at the time this method is called:\n\nThe left input matrix must be large enough to hold an array of size resultRows x interiorColumns elements, beginning at the value of the leftMatrixOrigin property.\n\nThe right input matrix must be large enough to hold an array of size interiorColumns x resultColumns elements, beginning at the value of the rightMatrixOrigin property.\n\nThe result matrix must be large enough to hold an array of size resultRows x resultColumns elements, beginning at the value of the resultMatrixOrigin property.\n\nSee Also\nMethods\ninit(device: MTLDevice, transposeLeft: Bool, transposeRight: Bool, resultRows: Int, resultColumns: Int, interiorColumns: Int, alpha: Double, beta: Double)\nInitializes a matrix multiplication kernel."
  },
  {
    "title": "rightMatrixOrigin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixmultiplication/2147851-rightmatrixorigin",
    "html": "Discussion\n\nThe origin, relative to (0,0), at which to start reading values. If a different origin is desired, you must modify this property before encoding the matrix multiplication kernel. The default value is (0,0,0) (the z value must always be 0).\n\nSee Also\nProperties\nvar leftMatrixOrigin: MTLOrigin\nThe origin of the left input matrix.\nvar resultMatrixOrigin: MTLOrigin\nThe origin of the result matrix.\nvar batchSize: Int\nvar batchStart: Int"
  },
  {
    "title": "resultMatrixOrigin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixmultiplication/2147847-resultmatrixorigin",
    "html": "Discussion\n\nThe origin, relative to (0,0), at which to start reading values. If a different origin is desired, you must modify this property before encoding the matrix multiplication kernel. The default value is (0,0,0) (the z value must always be 0).\n\nSee Also\nProperties\nvar leftMatrixOrigin: MTLOrigin\nThe origin of the left input matrix.\nvar rightMatrixOrigin: MTLOrigin\nThe origin of the right input matrix.\nvar batchSize: Int\nvar batchStart: Int"
  },
  {
    "title": "batchSize | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixmultiplication/2873082-batchsize",
    "html": "See Also\nProperties\nvar leftMatrixOrigin: MTLOrigin\nThe origin of the left input matrix.\nvar rightMatrixOrigin: MTLOrigin\nThe origin of the right input matrix.\nvar resultMatrixOrigin: MTLOrigin\nThe origin of the result matrix.\nvar batchStart: Int"
  },
  {
    "title": "batchStart | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixmultiplication/2873081-batchstart",
    "html": "See Also\nProperties\nvar leftMatrixOrigin: MTLOrigin\nThe origin of the left input matrix.\nvar rightMatrixOrigin: MTLOrigin\nThe origin of the right input matrix.\nvar resultMatrixOrigin: MTLOrigin\nThe origin of the result matrix.\nvar batchSize: Int"
  },
  {
    "title": "matrixBytes | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor/2873387-matrixbytes",
    "html": "See Also\nProperties\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nenum MPSDataType\nA value to specify a type of data.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar matrices: Int"
  },
  {
    "title": "matrices | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor/2873351-matrices",
    "html": "See Also\nProperties\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nenum MPSDataType\nA value to specify a type of data.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar matrixBytes: Int"
  },
  {
    "title": "MPSDataType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsdatatype",
    "html": "Topics\nConstants\ncase floatBit\nA common bit for all floating point data types.\ncase float32\nA 32-bit floating point type (single precision).\nEnumeration Cases\ncase invalid\ncase float16\ncase int16\ncase int8\ncase normalizedBit\ncase signedBit\ncase uInt16\ncase uInt32\ncase uInt8\ncase unorm1\ncase unorm8\ncase alternateEncodingBit\ncase bFloat16\ncase bool\ncase complexBit\ncase complexFloat16\ncase complexFloat32\ncase int32\ncase int64\ncase uInt64\nType Properties\nstatic var intBit: MPSDataType\nDeprecated\nRelationships\nConforms To\nSendable\nSee Also\nProperties\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "init(dimensions:columns:rowBytes:dataType:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor/2143206-init",
    "html": "Parameters\nrows\n\nThe number of rows in the matrix.\n\ncolumns\n\nThe number of columns in the matrix.\n\nrowBytes\n\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\n\ndataType\n\nThe type of the data to be stored in the matrix.\n\nReturn Value\n\nA valid MPSMatrixDescriptor object.\n\nDiscussion\n\nFor performance considerations, the optimal row stride may not necessarily be equal to the number of columns in the matrix. The rowBytes(fromColumns:dataType:) method may be used to help you determine this value.\n\nSee Also\nMethods\nclass func rowBytes(fromColumns: Int, dataType: MPSDataType) -> Int\nDetermines the recommended matrix row stride, in bytes, for a given number of columns.\nclass func rowBytes(forColumns: Int, dataType: MPSDataType) -> Int"
  },
  {
    "title": "rowBytes | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor/2143199-rowbytes",
    "html": "Discussion\n\nThis value must be a multiple of the element size.\n\nSee Also\nProperties\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nenum MPSDataType\nA value to specify a type of data.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "init(device:convolutionDescriptor:kernelWeights:biasTerms:flags:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnfullyconnected/1829441-init",
    "html": "Parameters\ndevice\n\nThe device on which this kernel will run.\n\nfullyConnectedDescriptor\n\nA valid convolution descriptor.\n\nThe values of thestrideInPixelsX, strideInPixelsY, and groups properties of the descriptor must be set to 1 (i.e. their default values).\n\nkernelWeights\n\nA pointer to a weights array.\n\nEach entry is a float value. The number of entries is equal to inputFeatureChannels * outputFeatureChannels * kernelHeight * kernelWidth.\n\nThe layout of the filter weights is arranged so that it can be reinterpreted as a 4D tensor (array) weight[outputFeatureChannels][kernelHeight][kernelWidth][inputChannels/groups].\n\nWeights are converted to half float precision (fp16) internally for best performance.\n\nbiasTerms\n\nA pointer to bias terms to be applied to the convolution output.\n\nEach entry is a float value. The number of entries is the number of output feature maps.\n\nflags\n\nCurrently unused.\n\nThis value must be MPSCNNConvolutionFlags.none.\n\nReturn Value\n\nA valid MPSCNNFullyConnected object or nil, if failure.\n\nDiscussion\n\nNote\n\nThe encode methods in the MPSCNNKernel class can be used to encode an MPSCNNFullyConnected object to a MTLCommandBuffer object."
  },
  {
    "title": "init(device:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronabsolute/1648809-init",
    "html": "Parameters\ndevice\n\nThe device the filter will run on.\n\nReturn Value\n\nA valid MPSCNNNeuronAbsolute object or nil, if failure."
  },
  {
    "title": "strideInPixelsY | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondescriptor/1648847-strideinpixelsy",
    "html": "Discussion\n\nThe default value is 1."
  },
  {
    "title": "dataType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor/2143202-datatype",
    "html": "See Also\nProperties\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nenum MPSDataType\nA value to specify a type of data.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "columns | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor/2143196-columns",
    "html": "See Also\nProperties\nvar rows: Int\nThe number of rows in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nenum MPSDataType\nA value to specify a type of data.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "rowBytes(fromColumns:dataType:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor/2143204-rowbytes",
    "html": "Parameters\ncolumns\n\nThe number of columns in the matrix.\n\ndataType\n\nThe type of the data to be stored in the matrix.\n\nReturn Value\n\nThe recommended matrix row stride, in bytes.\n\nDiscussion\n\nThe optimal stride between the rows of a matrix is not necessarily equivalent to the number of columns in the matrix. This method returns the row stride, in bytes, which gives the best performance for a given number of columns. Using this row stride to construct your matrix descriptor is recommended, but not required (as long as the stride used is still large enough to allocate a full row of data).\n\nSee Also\nMethods\ninit(dimensions: Int, columns: Int, rowBytes: Int, dataType: MPSDataType)\nCreates a matrix descriptor with the specified dimensions and data type.\nclass func rowBytes(forColumns: Int, dataType: MPSDataType) -> Int"
  },
  {
    "title": "rowBytes(forColumns:dataType:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor/2873394-rowbytes",
    "html": "See Also\nMethods\ninit(dimensions: Int, columns: Int, rowBytes: Int, dataType: MPSDataType)\nCreates a matrix descriptor with the specified dimensions and data type.\nclass func rowBytes(fromColumns: Int, dataType: MPSDataType) -> Int\nDetermines the recommended matrix row stride, in bytes, for a given number of columns."
  },
  {
    "title": "rows | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor/2143203-rows",
    "html": "See Also\nProperties\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nenum MPSDataType\nA value to specify a type of data.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar matrices: Int\nvar matrixBytes: Int"
  },
  {
    "title": "init(device:kernelWidth:kernelHeight:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpooling/1648887-init",
    "html": "Parameters\ndevice\n\nThe device the kernel will run on.\n\nkernelWidth\n\nThe width of the kernel.\n\nThis value can be odd or even.\n\nkernelHeight\n\nThe height of the kernel.\n\nThis value can be odd or even.\n\nReturn Value\n\nA valid MPSCNNPooling object or nil, if failure."
  },
  {
    "title": "init(device:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpooling/1648902-init",
    "html": "Parameters\ndevice\n\nThe device the kernel will run on.\n\nkernelWidth\n\nThe width of the kernel.\n\nThis value can be odd or even.\n\nkernelHeight\n\nThe height of the kernel.\n\nThis value can be odd or even.\n\nstrideInPixelsX\n\nThe output stride (downsampling factor) in the x dimension.\n\nstrideInPixelsY\n\nThe output stride (downsampling factor) in the y dimension.\n\nReturn Value\n\nA valid MPSCNNPooling object or nil, if failure."
  },
  {
    "title": "MPSCNNConvolutionDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondescriptor",
    "html": "Overview\n\nYou use an MPSCNNConvolutionDescriptor object to describe the properties of an MPSCNNConvolution kernel such as its size, pixel format and CPU cache mode.\n\nTopics\nInitializers\ninit?(coder: NSCoder)\ninit(kernelWidth: Int, kernelHeight: Int, inputFeatureChannels: Int, outputFeatureChannels: Int)\ninit(kernelWidth: Int, kernelHeight: Int, inputFeatureChannels: Int, outputFeatureChannels: Int, neuronFilter: MPSCNNNeuron?)\nCreates a convolution descriptor with an optional neuron filter.\nInstance Properties\nvar groups: Int\nThe number of groups that the input and output channels are divided into.\nvar inputFeatureChannels: Int\nThe number of feature channels per pixel in the input image.\nvar kernelHeight: Int\nThe height of the kernel window.\nvar kernelWidth: Int\nThe width of the kernel window.\nvar outputFeatureChannels: Int\nThe number of feature channels per pixel in the output image.\nvar strideInPixelsX: Int\nThe output stride (downsampling factor) in the x dimension.\nvar strideInPixelsY: Int\nThe output stride (downsampling factor) in the y dimension.\nvar neuron: MPSCNNNeuron?\nThe neuron filter to be applied as part of the convolution operation.\nvar dilationRateX: Int\nvar dilationRateY: Int\nfunc neuronParameterA() -> Float\nDeprecated\nfunc neuronParameterB() -> Float\nDeprecated\nfunc neuronType() -> MPSCNNNeuronType\nDeprecated\nvar fusedNeuronDescriptor: MPSNNNeuronDescriptor\nInstance Methods\nfunc encode(with: NSCoder)\nfunc setBatchNormalizationParametersForInferenceWithMean(UnsafePointer<Float>?, variance: UnsafePointer<Float>?, gamma: UnsafePointer<Float>?, beta: UnsafePointer<Float>?, epsilon: Float)\nfunc setNeuronToPReLUWithParametersA(Data)\nDeprecated\nfunc setNeuronType(MPSCNNNeuronType, parameterA: Float, parameterB: Float)\nDeprecated\nType Properties\nclass var supportsSecureCoding: Bool\nRelationships\nInherits From\nNSObject\nConforms To\nNSCopying\nNSSecureCoding"
  },
  {
    "title": "sourceHeight | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagesizeencodingstate/2873329-sourceheight",
    "html": "Required"
  },
  {
    "title": "sourceWidth | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagesizeencodingstate/2873364-sourcewidth",
    "html": "Required"
  },
  {
    "title": "init(device:convolutionDescriptor:kernelWeights:biasTerms:flags:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolution/1648861-init",
    "html": "Parameters\ndevice\n\nThe device on which this kernel will run.\n\nconvolutionDescriptor\n\nA pointer to a valid convolution descriptor.\n\nkernelWeights\n\nA pointer to a weights array.\n\nEach entry is a float value. The number of entries is equal to inputFeatureChannels * outputFeatureChannels * kernelHeight * kernelWidth.\n\nThe layout of the filter weight is arranged so that it can be reinterpreted as a 4D tensor (array) weight[outputChannels][kernelHeight][kernelWidth][inputChannels/groups]\n\nWeights are converted to half float precision (fp16) internally for best performance.\n\nbiasTerms\n\nA pointer to bias terms to be applied to the convolution output.\n\nEach entry is a float value. The number of entries is the number of output feature maps.\n\nflags\n\nCurrently unused.\n\nThis value must be MPSCNNConvolutionFlags.none.\n\nReturn Value\n\nA valid MPSCNNConvolution object or nil, if failure."
  },
  {
    "title": "MPSCNNConvolutionFlags | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutionflags",
    "html": "Topics\nEnumeration Cases\ncase none\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "ps | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalization/1648942-ps",
    "html": "Discussion\n\nThe default value is 1.0."
  },
  {
    "title": "p0 | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalization/1648953-p0",
    "html": "Discussion\n\nThe default value is 1.0."
  },
  {
    "title": "init(device:kernelWidth:kernelHeight:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalization/1648924-init",
    "html": "Parameters\ndevice\n\nThe device the kernel will run on.\n\nkernelWidth\n\nThe width of the kernel.\n\nkernelHeight\n\nThe height of the kernel.\n\nReturn Value\n\nA valid MPSCNNLocalContrastNormalization object or nil, if failure.\n\nDiscussion\n\nNote\n\nThe value of kernelWidth must be equal to the value of kernelHeight."
  },
  {
    "title": "delta | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalization/1648812-delta",
    "html": "Discussion\n\nThe default value is 1/1024."
  },
  {
    "title": "alpha | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalization/1648923-alpha",
    "html": "Discussion\n\nThe default value is 1.0."
  },
  {
    "title": "beta | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalization/1648905-beta",
    "html": "Discussion\n\nThe default value is 0.5."
  },
  {
    "title": "searchLimitRadius | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageeuclideandistancetransform/3547977-searchlimitradius",
    "html": "Discussion\n\nWhen the nonzero pixels in an input image are far apart, the search algorithm works harder to find the closest nonzero pixel. If you don’t need results outside a certain radius, use this property to limit the search and improve kernel performance. If the nonzero pixels are outside the specified radius, the search result is some number larger that the radius.\n\nThe default value for this property is greatestFiniteMagnitude, which results in an exact Euclidean distance transform. Typical values for this property are 32, 64, 96, and 128."
  },
  {
    "title": "init(device:kernelWidth:kernelHeight:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnspatialnormalization/1648831-init",
    "html": "Parameters\ndevice\n\nThe device the kernel will run on.\n\nkernelWidth\n\nThe width of the kernel.\n\nkernelHeight\n\nThe height of the kernel.\n\nReturn Value\n\nA valid MPSCNNSpatialNormalization object or nil, if failure.\n\nDiscussion\n\nNote\n\nThe value of kernelWidth must be equal to the value of kernelHeight."
  },
  {
    "title": "alpha | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnspatialnormalization/1648825-alpha",
    "html": "Discussion\n\nThe default value is 1.0. Values must be non-negative."
  },
  {
    "title": "beta | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnspatialnormalization/1648936-beta",
    "html": "Discussion\n\nThe default value is 5.0."
  },
  {
    "title": "delta | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnspatialnormalization/1648933-delta",
    "html": "Discussion\n\nThe default value is 1.0."
  },
  {
    "title": "pm | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalization/1648907-pm",
    "html": "Discussion\n\nThe default value is 0.0."
  },
  {
    "title": "beta | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnncrosschannelnormalization/1648879-beta",
    "html": "Discussion\n\nThe default value is 5.0."
  },
  {
    "title": "kernelSize | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnncrosschannelnormalization/1648811-kernelsize",
    "html": "Discussion\n\nThe default value is 5."
  },
  {
    "title": "delta | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnncrosschannelnormalization/1648881-delta",
    "html": "Discussion\n\nThe default value is 1.0."
  },
  {
    "title": "init(device:kernelSize:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnncrosschannelnormalization/1648834-init",
    "html": "Parameters\ndevice\n\nThe device the filter will run on.\n\nkernelSize\n\nThe size of the kernel, in both x and y dimensions.\n\nReturn Value\n\nA valid MPSCNNCrossChannelNormalization object or nil, if failure."
  },
  {
    "title": "alpha | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnncrosschannelnormalization/1648896-alpha",
    "html": "Discussion\n\nThe default value is 1.0. Values must be non-negative."
  },
  {
    "title": "MPSScaleTransform | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsscaletransform",
    "html": "Topics\nInitializers\ninit()\ninit(scaleX: Double, scaleY: Double, translateX: Double, translateY: Double)\nInstance Properties\nvar scaleX: Double\nThe horizontal scale factor.\nvar scaleY: Double\nThe vertical scale factor.\nvar translateX: Double\nThe horizontal translation factor.\nvar translateY: Double\nThe vertical translation factor.\nSee Also\nRelated Documentation\nclass MPSImageLanczosScale\nA filter that resizes and changes the aspect ratio of an image using Lanczos resampling."
  },
  {
    "title": "init(device:thresholdValue:maximumValue:linearGrayColorTransform:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdbinary/1618855-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nthresholdValue\n\nThe threshold value to use.\n\nmaximumValue\n\nThe maximum value to use.\n\ntransform\n\nThe color transform to use. This matrix is an array of 3 floats that defaults to the BT.601/JPEG standard: {0.299f, 0.587f, 0.114f}\n\nReturn Value\n\nAn initialized kernel object."
  },
  {
    "title": "maximumValue | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdbinary/1618852-maximumvalue",
    "html": "See Also\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter.\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter."
  },
  {
    "title": "histogramInfo | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogramspecification/1618810-histograminfo",
    "html": "Discussion\n\nReturns a structure describing the format of the histogram."
  },
  {
    "title": "encodeTransform(to:sourceTexture:sourceHistogram:sourceHistogramOffset:desiredHistogram:desiredHistogramOffset:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogramspecification/1618854-encodetransform",
    "html": "Parameters\ncommandBuffer\n\nA valid command buffer.\n\nsource\n\nA valid texture containing the source image for the filter.\n\nsourceHistogram\n\nA valid buffer containing the histogram results for the source image. This filter will use these histogram results to generate the cumulative histogram for equalizing the image. The histogram results per channel are stored together. The number of channels for which histogram results are stored is determined by the number of channels in the image. If the histogramForAlpha value of the histogramInfo property is false and the source image is RGBA, then only histogram results for RGB channels are stored.\n\nsourceHistogramOffset\n\nThe byte offset into the source histogram buffer where the histogram starts. Must conform to alignment requirements for the offset parameter of the setBuffer(_:offset:index:) method.\n\ndesiredHistogram\n\nA valid buffer containing the desired histogram results for the source image. The histogram results per channel are stored together. The number of channels for which histogram results are stored is determined by the number of channels in the image. If the histogramForAlpha value of the histogramInfo property is false and the source image is RGBA, then only histogram results for RGB channels are stored.\n\ndesiredHistogramOffset\n\nThe byte offset into the desired histogram buffer where the histogram starts. Must conform to alignment requirements for the offset parameter of the setBuffer(_:offset:index:) method.\n\nDiscussion\n\nThe transform function will not begin to execute until after the command buffer has been enqueued and committed. This step will need to be repeated with the new MPSKernel object if the copy(with:device:) or copy(with:) method is called.\n\nSee Also\nMethods\ninit(device: MTLDevice, histogramInfo: UnsafePointer<MPSImageHistogramInfo>)\nInitializes a histogram with specific information.\nRelated Documentation\nfunc setBufferOffset(Int, index: Int)\nSets where the data begins in a buffer already bound to the compute shader.\nfunc setBuffer(MTLBuffer?, offset: Int, index: Int)\nSets a buffer for the compute function."
  },
  {
    "title": "transform | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdbinary/1618744-transform",
    "html": "See Also\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter.\nvar maximumValue: Float\nThe maximum value used to initialize the threshold filter."
  },
  {
    "title": "kernelWidth | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedilate/1618279-kernelwidth",
    "html": "See Also\nProperties\nvar kernelHeight: Int\nThe height of the filter window. which must be an odd number."
  },
  {
    "title": "init(device:a:b:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneurontanh/1648815-init",
    "html": "Parameters\ndevice\n\nThe device the filter will run on.\n\na\n\nThe \"a\" variable of the filter function.\n\nb\n\nThe \"b\" variable of the filter function.\n\nReturn Value\n\nA valid MPSCNNNeuronTanH object or nil, if failure."
  },
  {
    "title": "kernelWidth | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagebox/1618834-kernelwidth",
    "html": "See Also\nProperties\nvar kernelHeight: Int\nThe height of the filter window. Must be an odd number."
  },
  {
    "title": "kernelHeight | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagebox/1618739-kernelheight",
    "html": "See Also\nProperties\nvar kernelWidth: Int\nThe width of the filter window. Must be an odd number."
  },
  {
    "title": "init(device:kernelWidth:kernelHeight:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagebox/1618789-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nkernelWidth\n\nThe width of the kernel. Must be an odd number.\n\nkernelHeight\n\nThe height of the kernel. Must be an odd number.\n\nReturn Value\n\nAn initialized box filter object."
  },
  {
    "title": "init(device:linearGrayColorTransform:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagesobel/1618899-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\ntransform\n\nThe color transform to use. This matrix is an array of 3 floats that describes the RGB-to-grayscale color transform:\n\nLuminance = transform[0] * pixel.x + transform[1] * pixel.y + transform[2] * pixel.z\n\nReturn Value\n\nAn initialized Sobel filter object.\n\nSee Also\nMethods\ninit(device: MTLDevice)\nInitializes a Sobel filter on a given device using the default color transform."
  },
  {
    "title": "minKernelDiameter() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagemedian/1618864-minkerneldiameter",
    "html": "Return Value\n\nReturns the minimum diameter, in pixels, of the filter window supported by the median filter.\n\nSee Also\nMethods\ninit(device: MTLDevice, kernelDiameter: Int)\nInitializes a filter for a particular kernel size and device.\nclass func maxKernelDiameter() -> Int\nQueries the maximum diameter, in pixels, of the filter window supported by the median filter."
  },
  {
    "title": "init(device:a:b:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronlinear/1648888-init",
    "html": "Parameters\ndevice\n\nThe device the filter will run on.\n\na\n\nThe \"a\" variable of the filter function.\n\nb\n\nThe \"b\" variable of the filter function.\n\nReturn Value\n\nA valid MPSCNNNeuronLinear object or nil, if failure."
  },
  {
    "title": "init(coder:device:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageeuclideandistancetransform/2953972-init",
    "html": "Parameters\naDecoder\n\nThe decoder for your data.\n\ndevice\n\nThe device that the filter runs on.\n\nDiscussion\n\nUse this initializer to specify the location of your data; otherwise, the framework may guess incorrectly.\n\nSee Also\nCreating a Euclidean distance transform\ninit(device: MTLDevice)\nCreates a Euclidean distance transform that runs on a specified device."
  },
  {
    "title": "init(device:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageeuclideandistancetransform/2953973-init",
    "html": "Parameters\ndevice\n\nThe device that the filter runs on.\n\nSee Also\nCreating a Euclidean distance transform\ninit?(coder: NSCoder, device: MTLDevice)\nCreates a Euclidean distance transform that uses a specified decoder for your data and runs on a specified device."
  },
  {
    "title": "groups | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondescriptor/1648849-groups",
    "html": "Discussion\n\nThe default value is 1.\n\nGroups let you reduce parametrization. If the value of this property is set to n, the input is divided into n groups with inputFeatureChannels/n channels in each group. Similarly, the output is divided into n groups with outputFeatureChannels/n channels in each group. The ith group in the input is only connected to the ith group in the output, so the number of weights (parameters) needed is reduced by a factor of n. Both the value of the inputFeatureChannels and outputFeatureChannels properties must be divisible by n and the number of channels in each group must be a multiple of 4."
  },
  {
    "title": "init(device:kernelWidth:kernelHeight:weights:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagepyramid/1648821-init",
    "html": "Parameters\ndevice\n\nThe device the filter will run on.\n\nkernelWidth\n\nThe width of the filter kernel.\n\nkernelHeight\n\nThe height of the filter kernel.\n\nkernelWeights\n\nA pointer to an array of kernelWidth*kernelHeight values to be used as the kernel. These values are in row-major order.\n\nReturn Value\n\nA valid MPSImagePyramid object or nil, if failure.\n\nSee Also\nMethods\ninit(device: MTLDevice)\nInitializes a downwards 5-tap image pyramid with the default filter kernel and device.\ninit(device: MTLDevice, centerWeight: Float)\nInitialize a downwards 5-tap image pyramid with a central weight parameter and device."
  },
  {
    "title": "init(device:histogramInfo:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogramspecification/1618907-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nhistogramInfo\n\nA pointer to a structure describing the histogram content.\n\nReturn Value\n\nAn initialized histogram object.\n\nSee Also\nMethods\nfunc encodeTransform(to: MTLCommandBuffer, sourceTexture: MTLTexture, sourceHistogram: MTLBuffer, sourceHistogramOffset: Int, desiredHistogram: MTLBuffer, desiredHistogramOffset: Int)\nEncodes the transform function to a command buffer using a compute command encoder. The transform function computes the equalization lookup table."
  },
  {
    "title": "kernelWidth | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageconvolution/1618868-kernelwidth",
    "html": "See Also\nProperties\nvar kernelHeight: Int\nThe height of the filter window. Must be an odd number.\nvar bias: Float\nThe value added to a convolved pixel before it is converted back to its intended storage format."
  },
  {
    "title": "bias | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageconvolution/1618841-bias",
    "html": "Discussion\n\nThis value can be used to convert negative values into a representable range for an unsigned pixel format. For example, many edge detection filters produce results in the range [-k,k]. By scaling the filter weights by 0.5/k and adding 0.5, the results will be in the range [0,1] suitable for use with unsigned normalized formats.\n\nThis value can be used in combination with renormalization of the filter weights to do video ranging as part of the convolution effect. It can also just be used to increase the brightness of the image.\n\nThe default value is 0.0f.\n\nSee Also\nProperties\nvar kernelHeight: Int\nThe height of the filter window. Must be an odd number.\nvar kernelWidth: Int\nThe width of the filter window. Must be an odd number."
  },
  {
    "title": "transform(forSourceImage:handle:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagetransformprovider/2915282-transform",
    "html": "Required"
  },
  {
    "title": "kernelHeight | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageconvolution/1618842-kernelheight",
    "html": "See Also\nProperties\nvar kernelWidth: Int\nThe width of the filter window. Must be an odd number.\nvar bias: Float\nThe value added to a convolved pixel before it is converted back to its intended storage format."
  },
  {
    "title": "numberOfFeatureChannels | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationdatasource/2947961-numberoffeaturechannels",
    "html": "Required"
  },
  {
    "title": "label() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationdatasource/2952998-label",
    "html": "Required"
  },
  {
    "title": "kernelWidth | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagepyramid/1648842-kernelwidth",
    "html": "See Also\nProperties\nvar kernelHeight: Int\nThe height of the filter window. Must be an odd number."
  },
  {
    "title": "kernelHeight | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagepyramid/1648863-kernelheight",
    "html": "See Also\nProperties\nvar kernelWidth: Int\nThe width of the filter window. Must be an odd number."
  },
  {
    "title": "trainingStyle | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnntrainablenode/2952971-trainingstyle",
    "html": "Required"
  },
  {
    "title": "init(device:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagesobel/1618843-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nReturn Value\n\nAn initialized Sobel filter object.\n\nDiscussion\n\nThe default color transform matrix is an array of 3 floats set to the BT.601/JPEG standard: {0.299f, 0.587f, 0.114f}.\n\nSee Also\nMethods\ninit(device: MTLDevice, linearGrayColorTransform: UnsafePointer<Float>)\nInitializes a Sobel filter on a given device using a specific color transform."
  },
  {
    "title": "colorTransform | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagesobel/1618777-colortransform",
    "html": "Discussion\n\nThis property returns a pointer to the array of 3 floats used to convert RGBA, RGB or RG source images to the destination texture format when said destination is monochrome."
  },
  {
    "title": "kernelDiameter | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagemedian/1618909-kerneldiameter",
    "html": "Discussion\n\nThe median filter is applied to a kernelDiameter * kernelDiameter window of pixels centered on the corresponding source pixel for each destination pixel. The kernel diameter must be an odd number."
  },
  {
    "title": "bias | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagelaplacian/1648929-bias",
    "html": "Discussion\n\nThis value can be used to convert negative values into a representable range for a unsigned pixel format. For example, many edge detection filters produce results in the range [-k,k]. By scaling the filter weights by 0.5/k and adding 0.5, the results will be in range [0,1] suitable for use with unsigned normalized pixel formats.\n\nThis value can also be used in combination with renormalization of the filter weights to do video ranging as part of the convolution effect. It can also just be used to increase the brightness of the image.\n\nThe default value is 0.0f."
  },
  {
    "title": "init(device:kernelDiameter:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagemedian/1618837-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nkernelDiameter\n\nThe diameter of the median filter, in pixels. Must be an odd number.\n\nReturn Value\n\nAn initialized median filter object.\n\nSee Also\nMethods\nclass func maxKernelDiameter() -> Int\nQueries the maximum diameter, in pixels, of the filter window supported by the median filter.\nclass func minKernelDiameter() -> Int\nQueries the minimum diameter, in pixels, of the filter window supported by the median filter."
  },
  {
    "title": "kernelWidth | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondescriptor/1648959-kernelwidth",
    "html": "Discussion\n\nThe default value is 3.\n\nAny positive non-zero value is valid, including even values. The position of the left edge of the kernel window is given by offset.x - (kernelWidth>>1)."
  },
  {
    "title": "kernelHeight | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondescriptor/1648904-kernelheight",
    "html": "Discussion\n\nThe default value is 3.\n\nAny positive non-zero value is valid, including even values. The position of the top edge of the kernel window is given by offset.y - (kernelHeight>>1)."
  },
  {
    "title": "init(device:centerWeight:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagepyramid/1648889-init",
    "html": "Parameters\ndevice\n\nThe device the filter will run on.\n\ncenterWeight\n\nDefines the form of the filter kernel through the outer product ww^T, where w = [(1/4 - a/2), 1/4, a, 1/4, (1/4 - a/2)]^T and a is the value of centerWeight.\n\nReturn Value\n\nA valid MPSImagePyramid object or nil, if failure.\n\nSee Also\nMethods\ninit(device: MTLDevice)\nInitializes a downwards 5-tap image pyramid with the default filter kernel and device.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, weights: UnsafePointer<Float>)\nInitialize a downwards n-tap image pyramid with a custom filter kernel and device."
  },
  {
    "title": "init(device:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagepyramid/1648935-init",
    "html": "Parameters\ndevice\n\nThe device the filter will run on.\n\nReturn Value\n\nA valid MPSImagePyramid object or nil, if failure.\n\nDiscussion\n\nThe filter kernel is the outer product of w = [1/16, 1/4, 3/8, 1/4, 1/16]^T, with itself.\n\nSee Also\nMethods\ninit(device: MTLDevice, centerWeight: Float)\nInitialize a downwards 5-tap image pyramid with a central weight parameter and device.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, weights: UnsafePointer<Float>)\nInitialize a downwards n-tap image pyramid with a custom filter kernel and device."
  },
  {
    "title": "transform | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtozero/1618823-transform",
    "html": "See Also\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter."
  },
  {
    "title": "init(device:kernelWidth:kernelHeight:weights:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageconvolution/1618902-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nkernelWidth\n\nThe width of the kernel. Must be an odd number.\n\nkernelHeight\n\nThe height of the kernel. Must be an odd number.\n\nkernelWeights\n\nA pointer to an array of kernelWidth * kernelHeight values to be used as the kernel. These values should be in row-major order.\n\nReturn Value\n\nAn initialized convolution filter object."
  },
  {
    "title": "init(coder:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationdatasource/2947957-init",
    "html": "Required"
  },
  {
    "title": "supportsSecureCoding | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationdatasource/2947952-supportssecurecoding",
    "html": "Required"
  },
  {
    "title": "beta() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationdatasource/2953922-beta",
    "html": "Required"
  },
  {
    "title": "kernelWidth | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageareamax/1618282-kernelwidth",
    "html": "See Also\nProperties\nvar kernelHeight: Int\nThe height of the filter window. Must be an odd number."
  },
  {
    "title": "kernelHeight | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedilate/1618280-kernelheight",
    "html": "See Also\nProperties\nvar kernelWidth: Int\nThe width of the filter window which must be an odd number."
  },
  {
    "title": "gamma() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationdatasource/2953923-gamma",
    "html": "Required"
  },
  {
    "title": "maxKernelDiameter() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagemedian/1618830-maxkerneldiameter",
    "html": "Return Value\n\nReturns the maximum diameter, in pixels, of the filter window supported by the median filter.\n\nSee Also\nMethods\ninit(device: MTLDevice, kernelDiameter: Int)\nInitializes a filter for a particular kernel size and device.\nclass func minKernelDiameter() -> Int\nQueries the minimum diameter, in pixels, of the filter window supported by the median filter."
  },
  {
    "title": "init(device:thresholdValue:maximumValue:linearGrayColorTransform:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdbinaryinverse/1618903-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nthresholdValue\n\nThe threshold value to use.\n\nmaximumValue\n\nThe maximum value to use.\n\ntransform\n\nThe color transform to use. This matrix is an array of 3 floats that defaults to the BT.601/JPEG standard: {0.299f, 0.587f, 0.114f}\n\nReturn Value\n\nAn initialized kernel object."
  },
  {
    "title": "transform | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtozeroinverse/1618828-transform",
    "html": "See Also\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter."
  },
  {
    "title": "thresholdValue | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtozeroinverse/1618914-thresholdvalue",
    "html": "See Also\nProperties\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter."
  },
  {
    "title": "init(device:thresholdValue:linearGrayColorTransform:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtozero/1618865-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nthresholdValue\n\nThe threshold value to use.\n\ntransform\n\nThe color transform to use. This matrix is an array of 3 floats that defaults to the BT.601/JPEG standard: {0.299f, 0.587f, 0.114f}\n\nReturn Value\n\nAn initialized kernel object."
  },
  {
    "title": "thresholdValue | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtozero/1618767-thresholdvalue",
    "html": "See Also\nProperties\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter."
  },
  {
    "title": "init(device:kernelWidth:kernelHeight:values:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedilate/1618285-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nkernelWidth\n\nThe width of the kernel. Must be an odd number.\n\nkernelHeight\n\nThe height of the kernel. Must be an odd number.\n\nvalues\n\nThe set of values to use as the dilate probe. The values are copied into the filter. To avoid image lightening or darkening, the center value should be 0.0f.\n\nReturn Value\n\nReturns an initialized kernel object with specific width, height, and weight values.\n\nDiscussion\n\nEach dilate shape probe defines a 3D surface of values. These are arranged in order left to right, then top to bottom in a 1D array. (values[kernelWidth*y+x] = probe[y][x])\n\nValues should be generally be in the range [0,1] with the center pixel tending towards 0 and edges towards 1. However, any numerical value is allowed. Calculations are subject to the usual floating-point rounding error."
  },
  {
    "title": "kernelHeight | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageareamax/1618277-kernelheight",
    "html": "See Also\nProperties\nvar kernelWidth: Int\nThe width of the filter window. Must be an odd number."
  },
  {
    "title": "init(device:kernelWidth:kernelHeight:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageareamax/1618281-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nkernelWidth\n\nThe width of the kernel. Must be an odd number.\n\nkernelHeight\n\nThe height of the kernel. Must be an odd number.\n\nReturn Value\n\nReturns an initialized kernel object with a specific width and height."
  },
  {
    "title": "MPSAlphaType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsalphatype",
    "html": "Overview\n\nSome image data is premultiplied. That is to say that the color channels are stored instead as color*alpha. This is an optimization for image compositing (alpha blending), but it can get in the way of most other image filters, especially those that apply non-linear effects like the color conversion filters and functions like convolution or resampling filters that look at adjacent pixels, where the alpha may not be the same. The following are some basic conversion cases:\n\nSource\n\n\t\n\nDestination\n\n\t\n\nOperation\n\n\n\n\nNonPremultiplied\n\n\t\n\nNonPremultiplied\n\n\t\n\nNone.\n\n\n\n\nNonPremultiplied\n\n\t\n\nAlphaIsOne\n\n\t\n\nComposite with opaque background color.\n\n\n\n\nNonPremultiplied\n\n\t\n\nPremultiplied\n\n\t\n\nMultiply color channels by alpha.\n\n\n\n\nAlphaIsOne\n\n\t\n\nNonPremultiplied\n\n\t\n\nSet alpha to 1.\n\n\n\n\nAlphaIsOne\n\n\t\n\nAlphaIsOne\n\n\t\n\nSet alpha to 1.\n\n\n\n\nAlphaIsOne\n\n\t\n\nPremultiplied\n\n\t\n\nSet alpha to 1.\n\n\n\n\nPremultiplied\n\n\t\n\nNonPremultiplied\n\n\t\n\nDivide color channels by alpha.\n\n\n\n\nPremultiplied\n\n\t\n\nAlphaIsOne\n\n\t\n\nComposite with opaque background color.\n\n\n\n\nPremultiplied\n\n\t\n\nPremultiplied\n\n\t\n\nNone.\n\nMost MPSKernel objects require non-premultiplied or completely opaque colors to work correctly. They implictly assume that alpha is equal to 1 and do not provide functions for the user to specify alpha channel types. Currently, the only filters that can handle premultiplied data are the color conversion filters provided by MPSImageConversion kernels and they insert extra operations to ensure a correct conversion. Fully opaque images should use MPSAlphaTypeAlphaIsOne\n\nTopics\nConstants\ncase nonPremultiplied\nThe image is not premultiplied by alpha. Alpha is not guaranteed to be 1. (CGImageAlphaInfo.first/CGImageAlphaInfo.last)\ncase alphaIsOne\nAlpha is guaranteed to be 1, even if it is not encoded as 1 or not encoded at all. (CGImageAlphaInfo.noneSkipFirst/CGImageAlphaInfo.noneSkipLast, CGImageAlphaInfo.none)\ncase premultiplied\nThe image is premultiplied by alpha. Alpha is not guaranteed to be 1. (CGImageAlphaInfo.premultipliedFirst/CGImageAlphaInfo.premultipliedLast)\nRelationships\nConforms To\nSendable\nSee Also\nMethods\ninit(device: MTLDevice, srcAlpha: MPSAlphaType, destAlpha: MPSAlphaType, backgroundColor: UnsafeMutablePointer<CGFloat>?, conversionInfo: CGColorConversionInfo?)\nInitializes a filter that can convert texture color space, alpha, and pixel format."
  },
  {
    "title": "init(device:srcAlpha:destAlpha:backgroundColor:conversionInfo:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageconversion/2206722-init",
    "html": "Parameters\ndevice\n\nThe device that the filter will run on.\n\nsrcAlpha\n\nThe alpha encoding for the source texture.\n\ndestAlpha\n\nThe alpha encoding for the destination texture.\n\nbackgroundColor\n\nAn array of CGFloat values giving the background color to use when flattening an image.\n\nThe color is in the source color space. The length of the array is the number of color channels in the source color space. If this parameter is not applicable to your desired conversion, use {0}.\n\nconversionInfo\n\nThe color space conversion to use. This value may be NULL, indicating that no color space conversions need to be done.\n\nReturn Value\n\nAn MPSImageConversion object.\n\nSee Also\nMethods\nenum MPSAlphaType\nPremultiplication description for the color channels of an image."
  },
  {
    "title": "sourceAlpha | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageconversion/1648518-sourcealpha",
    "html": "Discussion\n\nMost color space conversion operations can not work directly on premultiplied data. Use this property to tag premultiplied data so that the source texture can be un-premultiplied prior to the application of these transforms. The default value is MPSAlphaType.alphaIsOne.\n\nSee Also\nProperties\nvar destinationAlpha: MPSAlphaType\nPremultiplication description for the destination texture."
  },
  {
    "title": "destinationAlpha | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageconversion/1648515-destinationalpha",
    "html": "Discussion\n\nColor space conversion operations produce non-premultiplied data. Use this property to tag cases where premultiplied results are required. If the MPSAlphaType.alphaIsOne value is used, the alpha channel will be set to 1. The default value is MPSAlphaType.alphaIsOne.\n\nSee Also\nProperties\nvar sourceAlpha: MPSAlphaType\nPremultiplication description for the source texture."
  },
  {
    "title": "transform | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdbinaryinverse/1618904-transform",
    "html": "See Also\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter.\nvar maximumValue: Float\nThe maximum value used to initialize the threshold filter."
  },
  {
    "title": "maximumValue | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdbinaryinverse/1618906-maximumvalue",
    "html": "See Also\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter.\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter."
  },
  {
    "title": "thresholdValue | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdbinaryinverse/1618845-thresholdvalue",
    "html": "See Also\nProperties\nvar maximumValue: Float\nThe maximum value used to initialize the threshold filter.\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter."
  },
  {
    "title": "init(device:thresholdValue:linearGrayColorTransform:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtozeroinverse/1618911-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nthresholdValue\n\nThe threshold value to use.\n\ntransform\n\nThe color transform to use. This matrix is an array of 3 floats that defaults to the BT.601/JPEG standard: {0.299f, 0.587f, 0.114f}\n\nReturn Value\n\nAn initialized kernel object."
  },
  {
    "title": "init(device:histogramInfo:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogramequalization/1618856-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nhistogramInfo\n\nA pointer to a structure describing the histogram content.\n\nReturn Value\n\nAn initialized histogram object.\n\nSee Also\nMethods\nfunc encodeTransform(to: MTLCommandBuffer, sourceTexture: MTLTexture, histogram: MTLBuffer, histogramOffset: Int)\nEncodes the transform function to a command buffer using a compute command encoder. The transform function computes the equalization lookup table."
  },
  {
    "title": "purge() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2942607-purge",
    "html": "Required"
  },
  {
    "title": "gamma() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2942605-gamma",
    "html": "Required"
  },
  {
    "title": "load() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2942579-load",
    "html": "Required"
  },
  {
    "title": "label() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2953128-label",
    "html": "Required"
  },
  {
    "title": "mean() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2942589-mean",
    "html": "Required"
  },
  {
    "title": "numberOfFeatureChannels() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2942596-numberoffeaturechannels",
    "html": "Required"
  },
  {
    "title": "MPSDimensionSlice | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsdimensionslice",
    "html": "Topics\nInitializers\ninit()\ninit(start: Int, length: Int)\nInstance Properties\nvar length: Int\nvar start: Int"
  },
  {
    "title": "variance() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2942592-variance",
    "html": "Required"
  },
  {
    "title": "supportsSecureCoding | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2951887-supportssecurecoding",
    "html": "Required"
  },
  {
    "title": "init(coder:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2951886-init",
    "html": "Required"
  },
  {
    "title": "beta() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource/2942586-beta",
    "html": "Required"
  },
  {
    "title": "transform | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtruncate/1618787-transform",
    "html": "See Also\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter."
  },
  {
    "title": "thresholdValue | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtruncate/1618882-thresholdvalue",
    "html": "See Also\nProperties\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter."
  },
  {
    "title": "init(device:thresholdValue:linearGrayColorTransform:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtruncate/1618818-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nthresholdValue\n\nThe threshold value to use.\n\ntransform\n\nThe color transform to use. This matrix is an array of 3 floats that defaults to the BT.601/JPEG standard: {0.299f, 0.587f, 0.114f}\n\nReturn Value\n\nAn initialized kernel object."
  },
  {
    "title": "MPSIntersectionDistancePrimitiveIndexBufferIndexCoordinates | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondistanceprimitiveindexbufferindexcoordinates",
    "html": "Topics\nInitializers\ninit()\ninit(distance: Float, primitiveIndex: UInt32, bufferIndex: UInt32, coordinates: vector_float2)\nInstance Properties\nvar bufferIndex: UInt32\nvar coordinates: vector_float2\nvar distance: Float\nvar primitiveIndex: UInt32"
  },
  {
    "title": "encodeTransform(to:sourceTexture:histogram:histogramOffset:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogramequalization/1618746-encodetransform",
    "html": "Parameters\ncommandBuffer\n\nA valid command buffer.\n\nsource\n\nA valid texture containing the source image for the filter.\n\nhistogram\n\nA valid buffer containing the histogram results for an image. This filter will use these histogram results to generate the cumulative histogram for equalizing the image. The histogram results per channel are stored together. The number of channels for which histogram results are stored is determined by the number of channels in the image. If the histogramForAlpha value of the histogramInfo property is false and the source image is RGBA, then only histogram results for RGB channels are stored.\n\nhistogramOffset\n\nThe byte offset into the histogram buffer where the histogram starts. Must conform to alignment requirements for the offset parameter of the setBuffer(_:offset:index:) method.\n\nDiscussion\n\nThe transform function will not begin to execute until after the command buffer has been enqueued and committed. This step will need to be repeated with the new MPSKernel object if the copy(with:device:) or copy(with:) method is called. The transform is stored as internal state to the object. You still need to call the encode(commandBuffer:sourceTexture:destinationTexture:) afterward to apply the transform to produce a result texture.\n\nSee Also\nMethods\ninit(device: MTLDevice, histogramInfo: UnsafePointer<MPSImageHistogramInfo>)\nInitializes a histogram with specific information.\nRelated Documentation\nfunc setBufferOffset(Int, index: Int)\nSets where the data begins in a buffer already bound to the compute shader.\nfunc setBuffer(MTLBuffer?, offset: Int, index: Int)\nSets a buffer for the compute function."
  },
  {
    "title": "histogramInfo | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogramequalization/1618775-histograminfo",
    "html": "Discussion\n\nReturns a structure describing the format of the histogram."
  },
  {
    "title": "MPSRayOriginMinDistanceDirectionMaxDistance | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrayoriginmindistancedirectionmaxdistance",
    "html": "Topics\nInitializers\ninit()\ninit(origin: MPSPackedFloat3, minDistance: Float, direction: MPSPackedFloat3, maxDistance: Float)\nInstance Properties\nvar direction: MPSPackedFloat3\nvar maxDistance: Float\nvar minDistance: Float\nvar origin: MPSPackedFloat3"
  },
  {
    "title": "MPSStateTextureInfo | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsstatetextureinfo",
    "html": "Topics\nInitializers\ninit()\ninit(width: Int, height: Int, depth: Int, arrayLength: Int, pixelFormat: MTLPixelFormat, textureType: MTLTextureType, usage: MTLTextureUsage, _reserved: (Int, Int, Int, Int))\nInstance Properties\nvar arrayLength: Int\nvar depth: Int\nvar height: Int\nvar pixelFormat: MTLPixelFormat\nvar textureType: MTLTextureType\nvar usage: MTLTextureUsage\nvar width: Int"
  },
  {
    "title": "MPSRayPackedOriginDirection | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsraypackedorigindirection",
    "html": "Topics\nInitializers\ninit()\ninit(origin: MPSPackedFloat3, direction: MPSPackedFloat3)\nInstance Properties\nvar direction: MPSPackedFloat3\nvar origin: MPSPackedFloat3"
  },
  {
    "title": "MPSCNNNeuronType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneurontype",
    "html": "Topics\nEnumeration Cases\ncase none\nA neuron type indicating no neuron filter.\ncase reLU\nA neuron type indicating a rectified linear unit neuron filter.\ncase linear\nA neuron type indicating a linear neuron filter.\ncase sigmoid\nA neuron type indicating a sigmoid neuron filter.\ncase hardSigmoid\nA neuron type indicating a hard sigmoid neuron filter.\ncase tanH\nA neuron type indicating a hyperbolic tangent neuron filter.\ncase absolute\nA neuron type indicating an absolute neuron filter.\ncase softPlus\nA neuron type indicating a parametric softplus neuron filter.\ncase softSign\nA neuron type indicating a softsign neuron filter.\ncase ELU\nA neuron type indicating a parametric exponential linear unit neuron filter.\ncase count\ncase exponential\ncase geLU\ncase logarithm\ncase pReLU\ncase power\ncase reLUN\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSMatrixRandomDistribution | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixrandomdistribution",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var `default`: MPSMatrixRandomDistribution\nstatic var normal: MPSMatrixRandomDistribution\nstatic var uniform: MPSMatrixRandomDistribution\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSRayOriginMaskDirectionMaxDistance | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrayoriginmaskdirectionmaxdistance",
    "html": "Topics\nInitializers\ninit()\ninit(origin: MPSPackedFloat3, mask: UInt32, direction: MPSPackedFloat3, maxDistance: Float)\nInstance Properties\nvar direction: MPSPackedFloat3\nvar mask: UInt32\nvar maxDistance: Float\nvar origin: MPSPackedFloat3"
  },
  {
    "title": "MPSRayOriginDirection | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrayorigindirection",
    "html": "Topics\nInitializers\ninit()\ninit(origin: vector_float3, direction: vector_float3)\nInstance Properties\nvar direction: vector_float3\nvar origin: vector_float3"
  },
  {
    "title": "MPSNNConvolutionAccumulatorPrecisionOption | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnconvolutionaccumulatorprecisionoption",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var float: MPSNNConvolutionAccumulatorPrecisionOption\nstatic var half: MPSNNConvolutionAccumulatorPrecisionOption\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSAccelerationStructureUsage | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsaccelerationstructureusage",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var frequentRebuild: MPSAccelerationStructureUsage\nOption indicating that the acceleration structure will be rebuilt frequently.\nstatic var preferCPUBuild: MPSAccelerationStructureUsage\nstatic var preferGPUBuild: MPSAccelerationStructureUsage\nstatic var refit: MPSAccelerationStructureUsage\nOption that enables support for refitting the acceleration structure after it has been built.\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSNNComparisonType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnncomparisontype",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var equal: MPSNNComparisonType\nstatic var greater: MPSNNComparisonType\nstatic var greaterOrEqual: MPSNNComparisonType\nstatic var less: MPSNNComparisonType\nstatic var lessOrEqual: MPSNNComparisonType\nstatic var notEqual: MPSNNComparisonType\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSAliasingStrategy | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsaliasingstrategy",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var aliasingReserved: MPSAliasingStrategy\nstatic var `default`: MPSAliasingStrategy\nstatic var preferNonTemporaryMemory: MPSAliasingStrategy\nstatic var preferTemporaryMemory: MPSAliasingStrategy\nstatic var shallAlias: MPSAliasingStrategy\nstatic var shallNotAlias: MPSAliasingStrategy\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSCNNBatchNormalizationFlags | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationflags",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var CalculateStatisticsAutomatic: MPSCNNBatchNormalizationFlags\nstatic var Default: MPSCNNBatchNormalizationFlags\nstatic var calculateStatisticsAlways: MPSCNNBatchNormalizationFlags\nstatic var calculateStatisticsMask: MPSCNNBatchNormalizationFlags\nstatic var calculateStatisticsNever: MPSCNNBatchNormalizationFlags\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSCNNConvolutionGradientOption | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiongradientoption",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var all: MPSCNNConvolutionGradientOption\nstatic var gradientWithData: MPSCNNConvolutionGradientOption\nstatic var gradientWithWeightsAndBias: MPSCNNConvolutionGradientOption\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSIntersectionDistance | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondistance",
    "html": "Topics\nInitializers\ninit()\ninit(distance: Float)\nInstance Properties\nvar distance: Float"
  },
  {
    "title": "MPSImageType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagetype",
    "html": "Topics\nInitializers\ninit(UInt32)\ninit(rawValue: UInt32)\nInstance Properties\nvar rawValue: UInt32\nRelationships\nConforms To\nRawRepresentable"
  },
  {
    "title": "MPSIntegerDivisionParams | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintegerdivisionparams",
    "html": "Topics\nInitializers\ninit()\ninit(divisor: UInt16, recip: UInt16, addend: UInt16, shift: UInt16)\nInstance Properties\nvar addend: UInt16\nvar divisor: UInt16\nvar recip: UInt16\nvar shift: UInt16"
  },
  {
    "title": "MPSIntersectionDistancePrimitiveIndexBufferIndex | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondistanceprimitiveindexbufferindex",
    "html": "Topics\nInitializers\ninit()\ninit(distance: Float, primitiveIndex: UInt32, bufferIndex: UInt32)\nInstance Properties\nvar bufferIndex: UInt32\nvar distance: Float\nvar primitiveIndex: UInt32"
  },
  {
    "title": "MPSIntersectionDistancePrimitiveIndex | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondistanceprimitiveindex",
    "html": "Topics\nInitializers\ninit()\ninit(distance: Float, primitiveIndex: UInt32)\nInstance Properties\nvar distance: Float\nvar primitiveIndex: UInt32"
  },
  {
    "title": "MPSIntersectionDistancePrimitiveIndexBufferIndexInstanceIndex | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondistanceprimitiveindexbufferindexinstanceindex",
    "html": "Topics\nInitializers\ninit()\ninit(distance: Float, primitiveIndex: UInt32, bufferIndex: UInt32, instanceIndex: UInt32)\nInstance Properties\nvar bufferIndex: UInt32\nvar distance: Float\nvar instanceIndex: UInt32\nvar primitiveIndex: UInt32"
  },
  {
    "title": "MPSIntersectionDistancePrimitiveIndexBufferIndexInstanceIndexCoordinates | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondistanceprimitiveindexbufferindexinstanceindexcoordinates",
    "html": "Topics\nInitializers\ninit()\ninit(distance: Float, primitiveIndex: UInt32, bufferIndex: UInt32, instanceIndex: UInt32, coordinates: vector_float2)\nInstance Properties\nvar bufferIndex: UInt32\nvar coordinates: vector_float2\nvar distance: Float\nvar instanceIndex: UInt32\nvar primitiveIndex: UInt32"
  },
  {
    "title": "minPixelThresholdValue | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogram/2867008-minpixelthresholdvalue",
    "html": "See Also\nProperties\nvar clipRectSource: MTLRegion\nThe source rectangle to use when reading data.\nvar zeroHistogram: Bool\nDetermines whether to zero-initialize the histogram results.\nvar histogramInfo: MPSImageHistogramInfo\nA structure describing the histogram content."
  },
  {
    "title": "encode(to:sourceTexture:histogram:histogramOffset:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogram/1618853-encode",
    "html": "Parameters\ncommandBuffer\n\nA valid command buffer.\n\nsource\n\nA valid texture containing the source image for the filter.\n\nhistogram\n\nA valid buffer to receive the histogram results.\n\nhistogramOffset\n\nThe byte offset into the histogram buffer at which to write the histogram results. Must be a multiple of 32 bytes. The histogram results per channel are stored together. The number of channels for which histogram results are stored is determined by the number of channels in the image. If the histogramForAlpha value of the histogramInfo property is false and the source image is RGBA, then only histogram results for RGB channels are stored.\n\nDiscussion\n\nThe filter will not begin to execute until after the command buffer has been enqueued and committed.\n\nSee Also\nMethods\ninit(device: MTLDevice, histogramInfo: UnsafePointer<MPSImageHistogramInfo>)\nInitializes a histogram with specific information.\nstruct MPSImageHistogramInfo\nThe information used to compute the histogram channels of an image.\nfunc histogramSize(forSourceFormat: MTLPixelFormat) -> Int\nThe amount of space the histogram will take up in the output buffer."
  },
  {
    "title": "MPSRectNoClip | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrectnoclip",
    "html": "Discussion\n\nIf this constant is used in an image filter operation, no clipping is done and the entire image is used."
  },
  {
    "title": "init(device:histogramInfo:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogram/1618910-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nhistogramInfo\n\nA pointer to a structure describing the histogram content.\n\nReturn Value\n\nAn initialized histogram object.\n\nSee Also\nMethods\nstruct MPSImageHistogramInfo\nThe information used to compute the histogram channels of an image.\nfunc encode(to: MTLCommandBuffer, sourceTexture: MTLTexture, histogram: MTLBuffer, histogramOffset: Int)\nEncodes the filter to a command buffer using a compute command encoder.\nfunc histogramSize(forSourceFormat: MTLPixelFormat) -> Int\nThe amount of space the histogram will take up in the output buffer."
  },
  {
    "title": "MPSImageHistogramInfo | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistograminfo",
    "html": "Topics\nInitializers\ninit()\ninit(numberOfHistogramEntries: Int, histogramForAlpha: ObjCBool, minPixelValue: vector_float4, maxPixelValue: vector_float4)\nInstance Properties\nvar histogramForAlpha: ObjCBool\nSpecifies whether the histogram for the alpha channel should be computed or not.\nvar maxPixelValue: vector_float4\nSpecifies the maximum pixel value. Any pixel value greater than this will be clipped to this value (for the purposes of histogram calculation), and assigned to the first histogram entry. This maximum value is applied to each of the four channels separately.\nvar minPixelValue: vector_float4\nSpecifies the minimum pixel value. Any pixel value less than this will be clipped to this value (for the purposes of histogram calculation), and assigned to the first histogram entry. This minimum value is applied to each of the four channels separately.\nvar numberOfHistogramEntries: Int\nSpecifies the number of histogram entries (bins) for each channel.\nSee Also\nMethods\ninit(device: MTLDevice, histogramInfo: UnsafePointer<MPSImageHistogramInfo>)\nInitializes a histogram with specific information.\nfunc encode(to: MTLCommandBuffer, sourceTexture: MTLTexture, histogram: MTLBuffer, histogramOffset: Int)\nEncodes the filter to a command buffer using a compute command encoder.\nfunc histogramSize(forSourceFormat: MTLPixelFormat) -> Int\nThe amount of space the histogram will take up in the output buffer."
  },
  {
    "title": "histogramSize(forSourceFormat:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogram/1618839-histogramsize",
    "html": "Parameters\nsourceFormat\n\nThe pixel format of the source image, corresponding to the sourceTexture object of the encode(to:sourceTexture:histogram:histogramOffset:) method.\n\nReturn Value\n\nThe number of bytes needed to store the histogram results.\n\nDiscussion\n\nThis convenience function calculates the minimum amount of space needed in the output histogram for the results. The buffer should be at least this length and longer if the histogramOffset value in the encode(to:sourceTexture:histogram:histogramOffset:) method is non-zero.\n\nSee Also\nMethods\ninit(device: MTLDevice, histogramInfo: UnsafePointer<MPSImageHistogramInfo>)\nInitializes a histogram with specific information.\nstruct MPSImageHistogramInfo\nThe information used to compute the histogram channels of an image.\nfunc encode(to: MTLCommandBuffer, sourceTexture: MTLTexture, histogram: MTLBuffer, histogramOffset: Int)\nEncodes the filter to a command buffer using a compute command encoder."
  },
  {
    "title": "clipRectSource | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogram/1618765-cliprectsource",
    "html": "Discussion\n\nThis value indicates which part of the source image to read from. If the value of clipRectSource does not lie completely within the source image, then the intersection of the image bounds and the value of clipRectSource will be used. The value of clipRectSource replaces the offset value for this filter, which is ignored.\n\nThe default value is MPSRectNoClip, indicating that the entire source texture is used.\n\nSee Also\nProperties\nvar zeroHistogram: Bool\nDetermines whether to zero-initialize the histogram results.\nvar histogramInfo: MPSImageHistogramInfo\nA structure describing the histogram content.\nvar minPixelThresholdValue: vector_float4"
  },
  {
    "title": "zeroHistogram | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogram/1618891-zerohistogram",
    "html": "Discussion\n\nDetermines whether the memory region in which the histogram results are to be written in the histogram buffer are to be zero-initialized or not.\n\nThe default value is true.\n\nSee Also\nProperties\nvar clipRectSource: MTLRegion\nThe source rectangle to use when reading data.\nvar histogramInfo: MPSImageHistogramInfo\nA structure describing the histogram content.\nvar minPixelThresholdValue: vector_float4"
  },
  {
    "title": "histogramInfo | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogram/1618844-histograminfo",
    "html": "Discussion\n\nReturns a structure describing the format of the histogram.\n\nSee Also\nProperties\nvar clipRectSource: MTLRegion\nThe source rectangle to use when reading data.\nvar zeroHistogram: Bool\nDetermines whether to zero-initialize the histogram results.\nvar minPixelThresholdValue: vector_float4"
  },
  {
    "title": "MPSMatrixCopyOffsets | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixcopyoffsets",
    "html": "Topics\nInitializers\ninit()\ninit(sourceRowOffset: UInt32, sourceColumnOffset: UInt32, destinationRowOffset: UInt32, destinationColumnOffset: UInt32)\nInstance Properties\nvar destinationColumnOffset: UInt32\nvar destinationRowOffset: UInt32\nvar sourceColumnOffset: UInt32\nvar sourceRowOffset: UInt32"
  },
  {
    "title": "MPSNDArrayOffsets | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarrayoffsets",
    "html": "Topics\nInitializers\ninit()\ninit(dimensions: (Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int))\nInstance Properties\nvar dimensions: (Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int)"
  },
  {
    "title": "MPSMatrixOffset | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixoffset",
    "html": "Topics\nInitializers\ninit()\ninit(rowOffset: UInt32, columnOffset: UInt32)\nInstance Properties\nvar columnOffset: UInt32\nvar rowOffset: UInt32"
  },
  {
    "title": "MPSIntersectionDistancePrimitiveIndexCoordinates | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondistanceprimitiveindexcoordinates",
    "html": "Topics\nInitializers\ninit()\ninit(distance: Float, primitiveIndex: UInt32, coordinates: vector_float2)\nInstance Properties\nvar coordinates: vector_float2\nvar distance: Float\nvar primitiveIndex: UInt32"
  },
  {
    "title": "MPSNDArraySizes | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraysizes",
    "html": "Topics\nInitializers\ninit()\ninit(dimensions: (Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int))\nInstance Properties\nvar dimensions: (Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int)"
  },
  {
    "title": "MPSIntersectionDistancePrimitiveIndexInstanceIndexCoordinates | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondistanceprimitiveindexinstanceindexcoordinates",
    "html": "Topics\nInitializers\ninit()\ninit(distance: Float, primitiveIndex: UInt32, instanceIndex: UInt32, coordinates: vector_float2)\nInstance Properties\nvar coordinates: vector_float2\nvar distance: Float\nvar instanceIndex: UInt32\nvar primitiveIndex: UInt32"
  },
  {
    "title": "MPSIntersectionDistancePrimitiveIndexInstanceIndex | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondistanceprimitiveindexinstanceindex",
    "html": "Topics\nInitializers\ninit()\ninit(distance: Float, primitiveIndex: UInt32, instanceIndex: UInt32)\nInstance Properties\nvar distance: Float\nvar instanceIndex: UInt32\nvar primitiveIndex: UInt32"
  },
  {
    "title": "MPSNNTrainingStyle | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnntrainingstyle",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var UpdateDeviceNone: MPSNNTrainingStyle\nstatic var updateDeviceCPU: MPSNNTrainingStyle\nstatic var updateDeviceGPU: MPSNNTrainingStyle\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSRayMaskOptions | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsraymaskoptions",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var instance: MPSRayMaskOptions\nstatic var primitive: MPSRayMaskOptions\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSCustomKernelInfo | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscustomkernelinfo",
    "html": "Topics\nInitializers\ninit()\ninit(clipOrigin: vector_ushort4, clipSize: vector_ushort4, destinationFeatureChannels: UInt16, destImageArraySize: UInt16, sourceImageCount: UInt16, threadgroupSize: UInt16, subbatchIndex: UInt16, subbatchStride: UInt16, idiv: MPSIntegerDivisionParams)\nInstance Properties\nvar clipOrigin: vector_ushort4\nvar clipSize: vector_ushort4\nvar destImageArraySize: UInt16\nvar destinationFeatureChannels: UInt16\nvar idiv: MPSIntegerDivisionParams\nvar sourceImageCount: UInt16\nvar subbatchIndex: UInt16\nvar subbatchStride: UInt16\nvar threadgroupSize: UInt16"
  },
  {
    "title": "MPSCustomKernelSourceInfo | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscustomkernelsourceinfo",
    "html": "Topics\nInitializers\ninit()\ninit(kernelOrigin: vector_short2, kernelPhase: vector_ushort2, kernelSize: vector_ushort2, offset: vector_short2, stride: vector_ushort2, dilationRate: vector_ushort2, featureChannelOffset: UInt16, featureChannels: UInt16, imageArrayOffset: UInt16, imageArraySize: UInt16)\nInstance Properties\nvar dilationRate: vector_ushort2\nvar featureChannelOffset: UInt16\nvar featureChannels: UInt16\nvar imageArrayOffset: UInt16\nvar imageArraySize: UInt16\nvar kernelOrigin: vector_short2\nvar kernelPhase: vector_ushort2\nvar kernelSize: vector_ushort2\nvar offset: vector_short2\nvar stride: vector_ushort2"
  },
  {
    "title": "MPSCustomKernelArgumentCount | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscustomkernelargumentcount",
    "html": "Topics\nInitializers\ninit()\ninit(destinationTextureCount: UInt, sourceTextureCount: UInt, broadcastTextureCount: UInt)\nInstance Properties\nvar broadcastTextureCount: UInt\nvar destinationTextureCount: UInt\nvar sourceTextureCount: UInt"
  },
  {
    "title": "MPSImageRegion | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageregion",
    "html": "Topics\nInitializers\ninit()\ninit(offset: MPSImageCoordinate, size: MPSImageCoordinate)\nInstance Properties\nvar offset: MPSImageCoordinate\nvar size: MPSImageCoordinate"
  },
  {
    "title": "MPSDeviceOptions | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsdeviceoptions",
    "html": "Topics\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var Default: MPSDeviceOptions\nstatic var lowPower: MPSDeviceOptions\nstatic var skipRemovable: MPSDeviceOptions\nRelationships\nConforms To\nOptionSet\nSendable"
  },
  {
    "title": "MPSImageCoordinate | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagecoordinate",
    "html": "Topics\nInitializers\ninit()\ninit(x: Int, y: Int, channel: Int)\nInstance Properties\nvar channel: Int\nvar x: Int\nvar y: Int"
  },
  {
    "title": "MPSDeviceCapsValues | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsdevicecapsvalues",
    "html": "Topics\nInitializers\ninit(UInt32)\ninit(rawValue: UInt32)\nInstance Properties\nvar rawValue: UInt32\nRelationships\nConforms To\nRawRepresentable"
  },
  {
    "title": "MPSCustomKernelIndex | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscustomkernelindex",
    "html": "Topics\nInitializers\ninit(UInt32)\ninit(rawValue: UInt32)\nInstance Properties\nvar rawValue: UInt32\nRelationships\nConforms To\nRawRepresentable"
  },
  {
    "title": "texture(with:width:height:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpssvgftextureallocator/3242918-texture",
    "html": "Required"
  },
  {
    "title": "return(_:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpssvgftextureallocator/3242917-return",
    "html": "Required"
  },
  {
    "title": "clipRect | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnkernel/1648911-cliprect",
    "html": "Discussion\n\nA region that indicates which part of the destination image to overwrite. If the clip rectangle does not lie completely within the destination image, the intersection between the clip rectangle and the destination image bounds is used instead.\n\nThe default value is MPSRectNoClip, indicating that the entire destination image will be overwritten.\n\nThe value of clipRect.origin.z is the index of the starting destination image in batch processing mode. The value of clipRect.size.depth is the number of images to process in batch processing mode."
  },
  {
    "title": "edgeMode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnkernel/1648826-edgemode",
    "html": "Discussion\n\nMost MPSKernel objects can read off the edge of the source image. This can happen because of a negative offset property, because the value of offset + clipRect.size is larger than the source image or because the filter looks at neighboring pixels, such as a convolution filter.\n\nThe default value is MPSImageEdgeMode.zero.\n\nNote\n\nFor an MPSCNNPoolingAverage object, specifying a MPSImageEdgeMode.clamp edge mode is interpreted as a \"shrink-to-edge\" operation, which shrinks the effective filtering window to remain within the source image borders."
  },
  {
    "title": "encode(commandBuffer:sourceImage:destinationImage:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnkernel/1648919-encode",
    "html": "Parameters\ncommandBuffer\n\nA valid command buffer to receive the encoded filter.\n\nsourceImage\n\nA valid source image.\n\ndestinationImage\n\nA valid destination image to be overwritten by the results.\n\nDiscussion\n\nThe destinationImage object may not alias the sourceImage object."
  },
  {
    "title": "MPSCNNBinaryConvolutionType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbinaryconvolutiontype",
    "html": "Topics\nEnumeration Cases\ncase AND\nA convolution type that uses input image binarization and the AND-operation.\ncase XNOR\nA convolution type that uses input image binarization and the XNOR-operation.\ncase binaryWeights\nA convolution type that operates as a normal convolution, except that the weights are binary values.\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSCNNBinaryConvolutionFlags | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbinaryconvolutionflags",
    "html": "Topics\nEnumeration Cases\ncase none\ncase useBetaScaling\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "encode(commandBuffer:sourceTexture:destinationTexture:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsunaryimagekernel/1618741-encode",
    "html": "Parameters\ncommandBuffer\n\nA valid command buffer to receive the encoded kernel.\n\nsourceTexture\n\nA valid texture containing the source image.\n\ndestinationTexture\n\nA valid texture to be overwritten by the result image. destinationTexture may not alias sourceTexture.\n\nSee Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, inPlaceTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\ntypealias MPSCopyAllocator\nA block to make a copy of a source texture for filters that can only execute out of place.\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationImage: MPSImage)\nfunc sourceRegion(destinationSize: MTLSize) -> MPSRegion\nDetermines the region of the source texture that will be read for an encode operation."
  },
  {
    "title": "label() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpshandle/2866414-label",
    "html": "Required"
  },
  {
    "title": "MPSImageFeatureChannelFormat | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagefeaturechannelformat",
    "html": "Overview\n\nA pixel in an MPSImage object may have many channels in it, sometimes many more than 4, that exceed the limit of what a MTLPixelFormat value can encode. The storage format for a single channel within a pixel can be given by the MPSImageFeatureChannelFormat type. The number of channels is defined by the featureChannels property of an MPSImage object. The size of the pixel is the size of the channel format multiplied by the number of feature channels. No padding is allowed, except to round out to a full byte.\n\nTopics\nConstants\ncase none\ncase unorm8\nuint8_t type with value [0,255] and encoding [0,1.0].\ncase unorm16\nuint16_t type with value [0,65535] and encoding [0,1.0].\ncase float16\nIEEE-754 16-bit floating-point type (half precision). Representable normal range is +-[2^-14, 65504], 0, INF, NaN. 11 bits of precision + exponent.\ncase float32\nIEEE-754 32-bit floating-point type (single precision, standard float type in C). 24 bits of precision + exponent.\nEnumeration Cases\ncase count\nRelationships\nConforms To\nSendable\nSee Also\nSupporting Types\nprotocol MPSHandle\nThe protocol that provides resource identification.\nprotocol MPSImageAllocator"
  },
  {
    "title": "encode(commandBuffer:primaryImage:secondaryImage:destinationImage:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/2866330-encode",
    "html": "See Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, inPlaceSecondaryTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, inPlacePrimaryTexture: UnsafeMutablePointer<MTLTexture>, secondaryTexture: MTLTexture, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, secondaryTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out-of-place.\nfunc primarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the primary source texture that will be read for an encode operation.\nfunc secondarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the secondary source texture that will be read for an encode operation."
  },
  {
    "title": "primarySourceRegion(forDestinationSize:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618900-primarysourceregion",
    "html": "Parameters\ndestinationSize\n\nThe size of the full virtual destination image.\n\nReturn Value\n\nThe area in the virtual source image that will be read.\n\nDiscussion\n\nThis method is used to determine which region of the primary source texture will be read by the encode(commandBuffer:primaryTexture:secondaryTexture:destinationTexture:) method when the filter runs. This information may be needed if the primary source image is broken into multiple textures. The size of the full (untiled) destination image is provided. The region of the full (untiled) source image that will be read is returned. You can then piece together an appropriate texture containing that information for use in your tiled context.\n\nThis method will consult the primaryOffset and clipRect properties to determine the full region read by the function. Other properties, such as kernel height and width, will be consulted as necessary. All properties should be set to their intended values prior to calling this method.\n\nImportant\n\nThis function operates using global image coordinates, but the encode(commandBuffer:primaryTexture:secondaryTexture:destinationTexture:) method uses coordinates local to the source and destination image textures. Consequently, the primaryOffset and clipRect properties attached to this object will need to be updated using a global-to-local coordinate transform before the encode(commandBuffer:primaryTexture:secondaryTexture:destinationTexture:) method is called.\n\nSee Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, inPlaceSecondaryTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, inPlacePrimaryTexture: UnsafeMutablePointer<MTLTexture>, secondaryTexture: MTLTexture, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, secondaryTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out-of-place.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, destinationImage: MPSImage)\nfunc secondarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the secondary source texture that will be read for an encode operation."
  },
  {
    "title": "secondarySourceRegion(forDestinationSize:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618838-secondarysourceregion",
    "html": "Parameters\ndestinationSize\n\nThe size of the full virtual destination image.\n\nReturn Value\n\nThe area in the virtual source image that will be read.\n\nDiscussion\n\nThis method is used to determine which region of the secondary source texture will be read by the encode(commandBuffer:primaryTexture:secondaryTexture:destinationTexture:) method when the filter runs. This information may be needed if the secondary source image is broken into multiple textures. The size of the full (untiled) destination image is provided. The region of the full (untiled) source image that will be read is returned. You can then piece together an appropriate texture containing that information for use in your tiled context.\n\nThis method will consult the secondaryOffset and clipRect properties to determine the full region read by the function. Other properties, such as kernel height and width, will be consulted as necessary. All properties should be set to their intended values prior to calling this method.\n\nImportant\n\nThis function operates using global image coordinates, but the encode(commandBuffer:primaryTexture:secondaryTexture:destinationTexture:) method uses coordinates local to the source and destination image textures. Consequently, the secondaryOffset and clipRect properties attached to this object will need to be updated using a global-to-local coordinate transform before the encode(commandBuffer:primaryTexture:secondaryTexture:destinationTexture:) method is called.\n\nSee Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, inPlaceSecondaryTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, inPlacePrimaryTexture: UnsafeMutablePointer<MTLTexture>, secondaryTexture: MTLTexture, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, secondaryTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out-of-place.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, destinationImage: MPSImage)\nfunc primarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the primary source texture that will be read for an encode operation."
  },
  {
    "title": "encode(commandBuffer:sourceImage:destinationImage:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsunaryimagekernel/2866328-encode",
    "html": "See Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, inPlaceTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\ntypealias MPSCopyAllocator\nA block to make a copy of a source texture for filters that can only execute out of place.\nfunc encode(commandBuffer: MTLCommandBuffer, sourceTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out of place.\nfunc sourceRegion(destinationSize: MTLSize) -> MPSRegion\nDetermines the region of the source texture that will be read for an encode operation."
  },
  {
    "title": "MPSOffset | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsoffset",
    "html": "Topics\nInitializers\ninit()\ninit(x: Int, y: Int, z: Int)\nInstance Properties\nvar x: Int\nThe horizontal component of the offset, in pixels.\nvar y: Int\nThe vertical component of the offset, in pixels.\nvar z: Int\nThe depth component of the offset, in pixels.\nSee Also\nProperties\nvar offset: MPSOffset\nThe position of the destination clip rectangle origin relative to the source buffer.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.\nstruct MPSRegion\nA region of an image.\nvar edgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of an image.\nenum MPSImageEdgeMode\nThe options used to control the edge behavior of an image filter when it reads outside the bounds of a source texture."
  },
  {
    "title": "encode(commandBuffer:primaryTexture:secondaryTexture:destinationTexture:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618871-encode",
    "html": "Parameters\ncommandBuffer\n\nA valid command buffer to receive the encoded kernel.\n\nprimaryTexture\n\nA valid texture containing the primary source image.\n\nsecondaryTexture\n\nA valid texture containing the secondary source image.\n\ndestinationTexture\n\nA valid texture to be overwritten by the result image. destinationTexture may not alias primaryTexture nor secondaryTexture.\n\nSee Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, inPlaceSecondaryTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, inPlacePrimaryTexture: UnsafeMutablePointer<MTLTexture>, secondaryTexture: MTLTexture, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, destinationImage: MPSImage)\nfunc primarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the primary source texture that will be read for an encode operation.\nfunc secondarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the secondary source texture that will be read for an encode operation."
  },
  {
    "title": "encode(commandBuffer:primaryTexture:inPlaceSecondaryTexture:fallbackCopyAllocator:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618890-encode",
    "html": "Parameters\ncommandBuffer\n\nA valid command buffer to receive the encoded kernel.\n\nprimaryTexture\n\nA pointer to a valid texture containing the primary source image. It will not be overwritten.\n\ninPlaceSecondaryTexture\n\nA pointer to a valid texture containing the secondary image. On success, the image contents and possibly the texture itself will be replaced with the result image.\n\ncopyAllocator\n\nAn optional block to allocate a new texture to hold the operation results, in case in-place operation is not possible. The allocator may use a different pixel format or size than the original texture. You may enqueue operations on the provided command buffer using the provided compute command encoder to initialize the texture contents.\n\nReturn Value\n\ntrue if the operation succeeded (the texture may have been replaced with a new texture if a copy allocator was provided).\n\nfalse if the operation failed (the texture is unmodified).\n\nDiscussion\n\nThis method attempts to apply the kernel in place on a texture. In-place operation means that the same texture is used both to hold the input image and the results. Operating in-place can be an excellent way to reduce resource utilization, and save time and energy. While simple Metal kernels can not operate in place because textures can not be readable and writable at the same time, some Metal Performance Shaders kernels can operate in place because they use multi-pass algorithms. Whether a kernel can operate in-place can depend on current hardware, OS version, and the parameters and properties passed to it. You should never assume that a kernel will continue to work in place, even if you have observed it doing so before.\n\nIf the in-place operation succeeds, this method returns true. If the in-place operation fails and no copy allocator is provided, then this method returns false. Without a fallback copy allocator, in neither case is the pointer held at texture modified.\n\nFailure during in-place operation is common. You may find it simplifies your code to provide a copy allocator. When an in-place operation fails, your copy allocator will be invoked to create a new texture in which to write the results, allowing the kernel to proceed reliably out-of-place. The original texture will be released, replaced with a pointer to the new texture and true will be returned. If the copy allocator returns an invalid texture, it is released, texture remains unmodified, and false is returned.\n\nSee Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, inPlacePrimaryTexture: UnsafeMutablePointer<MTLTexture>, secondaryTexture: MTLTexture, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, secondaryTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out-of-place.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, destinationImage: MPSImage)\nfunc primarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the primary source texture that will be read for an encode operation.\nfunc secondarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the secondary source texture that will be read for an encode operation.\nRelated Documentation\ntypealias MPSCopyAllocator\nA block to make a copy of a source texture for filters that can only execute out of place."
  },
  {
    "title": "encode(commandBuffer:inPlacePrimaryTexture:secondaryTexture:fallbackCopyAllocator:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618771-encode",
    "html": "Parameters\ncommandBuffer\n\nA valid command buffer to receive the encoded kernel.\n\ninPlacePrimaryTexture\n\nA pointer to a valid texture containing the primary image. On success, the image contents and possibly the texture itself will be replaced with the result image.\n\nsecondaryTexture\n\nA pointer to a valid texture containing the secondary source image. It will not be overwritten.\n\ncopyAllocator\n\nAn optional block to allocate a new texture to hold the operation results, in case in-place operation is not possible. The allocator may use a different pixel format or size than the original texture. You may enqueue operations on the provided command buffer using the provided compute command encoder to initialize the texture contents.\n\nReturn Value\n\ntrue if the operation succeeded (the texture may have been replaced with a new texture if a copy allocator was provided).\n\nfalse if the operation failed (the texture is unmodified).\n\nDiscussion\n\nThis method attempts to apply the kernel in place on a texture. In-place operation means that the same texture is used both to hold the input image and the results. Operating in-place can be an excellent way to reduce resource utilization, and save time and energy. While simple Metal kernels can not operate in place because textures can not be readable and writable at the same time, some Metal Performance Shaders kernels can operate in place because they use multi-pass algorithms. Whether a kernel can operate in-place can depend on current hardware, OS version, and the parameters and properties passed to it. You should never assume that a kernel will continue to work in place, even if you have observed it doing so before.\n\nIf the in-place operation succeeds, this method returns true. If the in-place operation fails and no copy allocator is provided, then this method returns false. Without a fallback copy allocator, in neither case is the pointer held at texture modified.\n\nFailure during in-place operation is common. You may find it simplifies your code to provide a copy allocator. When an in-place operation fails, your copy allocator will be invoked to create a new texture in which to write the results, allowing the kernel to proceed reliably out-of-place. The original texture will be released, replaced with a pointer to the new texture and true will be returned. If the copy allocator returns an invalid texture, it is released, texture remains unmodified, and false is returned.\n\nSee Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, inPlaceSecondaryTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, secondaryTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out-of-place.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, destinationImage: MPSImage)\nfunc primarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the primary source texture that will be read for an encode operation.\nfunc secondarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the secondary source texture that will be read for an encode operation.\nRelated Documentation\ntypealias MPSCopyAllocator\nA block to make a copy of a source texture for filters that can only execute out of place."
  },
  {
    "title": "init(device:sigma:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagegaussianblur/1618813-init",
    "html": "Parameters\ndevice\n\nThe Metal device the filter will run on.\n\nsigma\n\nThe standard deviation of the gaussian blur filter.\n\nGaussian weight w, centered at 0, at integer grid i, is given as:\n\nw(i) = 1/sqrt(2*pi*sigma) * exp(-i^2/2*sigma^2)\n\nIf we take cut off at 1% of w(0) (max weight) beyond which weights are considered 0, we have ceil(sqrt(-log(0.01)*2)*sigma) ~ ceil(3.7*sigma) as the rough estimate of the filter width.\n\nReturn Value\n\nAn initialized Gaussian blur filter object."
  },
  {
    "title": "MPSRegion | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsregion",
    "html": "Topics\nInitializers\ninit()\ninit(origin: MPSOrigin, size: MPSSize)\nInstance Properties\nvar origin: MPSOrigin\nThe top-left corner of the region.\nstruct MPSOrigin\nA position in an image used as the source origin.\nvar size: MPSSize\nThe size of the region.\nstruct MPSSize\nA size of a region in an image.\nSee Also\nProperties\nvar offset: MPSOffset\nThe position of the destination clip rectangle origin relative to the source buffer.\nstruct MPSOffset\nA signed coordinate with x, y, and z components.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.\nvar edgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of an image.\nenum MPSImageEdgeMode\nThe options used to control the edge behavior of an image filter when it reads outside the bounds of a source texture."
  },
  {
    "title": "MPSImageEdgeMode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageedgemode",
    "html": "Topics\nConstants\ncase zero\nOut-of-bound pixels are set to (0.0, 0.0, 0.0, 1.0) for images without an alpha channel or (0.0, 0.0, 0.0, 0.0) for images with an alpha channel, as defined by their pixel format.\ncase clamp\nOut-of-bound pixels are clamped to the nearest edge pixel.\nEnumeration Cases\ncase constant\ncase mirror\ncase mirrorWithEdge\nRelationships\nConforms To\nSendable\nSee Also\nProperties\nvar offset: MPSOffset\nThe position of the destination clip rectangle origin relative to the source buffer.\nstruct MPSOffset\nA signed coordinate with x, y, and z components.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.\nstruct MPSRegion\nA region of an image.\nvar edgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of an image."
  },
  {
    "title": "MPSCNNReductionType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnreductiontype",
    "html": "Topics\nEnumeration Cases\ncase count\ncase mean\ncase none\ncase sum\ncase sumByNonZeroWeights\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSCNNConvolutionWeightsLayout | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutionweightslayout",
    "html": "Topics\nEnumeration Cases\ncase OHWI\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSTransformType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstransformtype",
    "html": "Topics\nEnumeration Cases\ncase float4x4\ncase identity\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSAccelerationStructureStatus | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsaccelerationstructurestatus",
    "html": "Topics\nEnumeration Cases\ncase built\ncase unbuilt\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSCNNLossType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlosstype",
    "html": "Topics\nEnumeration Cases\ncase categoricalCrossEntropy\ncase cosineDistance\ncase count\ncase hinge\ncase huber\ncase kullbackLeiblerDivergence\ncase log\ncase meanAbsoluteError\ncase meanSquaredError\ncase sigmoidCrossEntropy\ncase softMaxCrossEntropy\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSFloatDataTypeBit | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsfloatdatatypebit",
    "html": "Topics\nEnumeration Cases\ncase exponentBit\ncase mantissaBit\ncase signBit\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSCNNWeightsQuantizationType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnweightsquantizationtype",
    "html": "Topics\nEnumeration Cases\ncase none\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSIntersectionDataType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiondatatype",
    "html": "Topics\nEnumeration Cases\ncase distance\ncase distancePrimitiveIndex\ncase distancePrimitiveIndexBufferIndex\ncase distancePrimitiveIndexBufferIndexCoordinates\ncase distancePrimitiveIndexBufferIndexInstanceIndex\ncase distancePrimitiveIndexBufferIndexInstanceIndexCoordinates\ncase distancePrimitiveIndexCoordinates\ncase distancePrimitiveIndexInstanceIndex\ncase distancePrimitiveIndexInstanceIndexCoordinates\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSIntersectionType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsintersectiontype",
    "html": "Topics\nEnumeration Cases\ncase any\ncase nearest\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSFloatDataTypeShift | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsfloatdatatypeshift",
    "html": "Topics\nEnumeration Cases\ncase exponentShift\ncase mantissaShift\ncase signShift\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSRayDataType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsraydatatype",
    "html": "Topics\nEnumeration Cases\ncase originDirection\ncase originMaskDirectionMaxDistance\ncase originMinDistanceDirectionMaxDistance\ncase packedOriginDirection\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSRNNMatrixId | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnmatrixid",
    "html": "Topics\nEnumeration Cases\ncase SingleGateInputWeights\ncase gruInputGateBiasTerms\ncase gruInputGateInputWeights\ncase gruInputGateRecurrentWeights\ncase gruOutputGateBiasTerms\ncase gruOutputGateInputGateWeights\ncase gruOutputGateInputWeights\ncase gruOutputGateRecurrentWeights\ncase gruRecurrentGateBiasTerms\ncase gruRecurrentGateInputWeights\ncase gruRecurrentGateRecurrentWeights\ncase lstmForgetGateBiasTerms\ncase lstmForgetGateInputWeights\ncase lstmForgetGateMemoryWeights\ncase lstmForgetGateRecurrentWeights\ncase lstmInputGateBiasTerms\ncase lstmInputGateInputWeights\ncase lstmInputGateMemoryWeights\ncase lstmInputGateRecurrentWeights\ncase lstmMemoryGateBiasTerms\ncase lstmMemoryGateInputWeights\ncase lstmMemoryGateMemoryWeights\ncase lstmMemoryGateRecurrentWeights\ncase lstmOutputGateBiasTerms\ncase lstmOutputGateInputWeights\ncase lstmOutputGateMemoryWeights\ncase lstmOutputGateRecurrentWeights\ncase singleGateBiasTerms\ncase singleGateRecurrentWeights\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSRayMaskOperator | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsraymaskoperator",
    "html": "Topics\nEnumeration Cases\ncase and\ncase equal\ncase greaterThan\ncase greaterThanOrEqualTo\ncase lessThan\ncase lessThanOrEqualTo\ncase notAnd\ncase notEqual\ncase notOr\ncase notXor\ncase or\ncase xor\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSNNRegularizationType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnregularizationtype",
    "html": "Topics\nEnumeration Cases\ncase L1\ncase L2\ncase None\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSPolygonType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpspolygontype",
    "html": "Topics\nEnumeration Cases\ncase quadrilateral\ncase triangle\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSTriangleIntersectionTestType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstriangleintersectiontesttype",
    "html": "Topics\nEnumeration Cases\ncase `default`\ncase watertight\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "numberOfFeatureChannels | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationdatasource/3152550-numberoffeaturechannels",
    "html": "Required"
  },
  {
    "title": "scalarWeight(forSourceImage:destinationImage:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnlosscallback/3131851-scalarweight",
    "html": "Required"
  },
  {
    "title": "numberOfGroups | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationdatasource/3152551-numberofgroups",
    "html": "Required"
  },
  {
    "title": "array(for:arrayDescriptor:kernel:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarrayallocator/3143490-array",
    "html": "Required"
  },
  {
    "title": "label() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationdatasource/3152549-label",
    "html": "Required"
  },
  {
    "title": "gamma() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationdatasource/3152547-gamma",
    "html": "Required"
  },
  {
    "title": "MPSCNNConvolutionDataSource | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiondatasource",
    "html": "Topics\nInstance Methods\nfunc biasTerms() -> UnsafeMutablePointer<Float>?\n\nRequired\n\nfunc dataType() -> MPSDataType\n\nRequired\n\nfunc descriptor() -> MPSCNNConvolutionDescriptor\n\nRequired\n\nfunc label() -> String?\n\nRequired\n\nfunc load() -> Bool\n\nRequired\n\nfunc lookupTableForUInt8Kernel() -> UnsafeMutablePointer<Float>\nfunc purge()\n\nRequired\n\nfunc rangesForUInt8Kernel() -> UnsafeMutablePointer<vector_float2>\nfunc weights() -> UnsafeMutableRawPointer\n\nRequired\n\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc kernelWeightsDataType() -> MPSDataType\nfunc update(with: MTLCommandBuffer, gradientState: MPSCNNConvolutionGradientState, sourceState: MPSCNNConvolutionWeightsAndBiasesState) -> MPSCNNConvolutionWeightsAndBiasesState?\nfunc update(with: MPSCNNConvolutionGradientState, sourceState: MPSCNNConvolutionWeightsAndBiasesState) -> Bool\nfunc weightsLayout() -> MPSCNNConvolutionWeightsLayout\nfunc weightsQuantizationType() -> MPSCNNWeightsQuantizationType\nRelationships\nInherits From\nNSCopying\nNSObjectProtocol"
  },
  {
    "title": "MPSBoundingBoxIntersectionTestType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsboundingboxintersectiontesttype",
    "html": "Topics\nEnumeration Cases\ncase axisAligned\ncase `default`\ncase fast\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSStateResourceType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsstateresourcetype",
    "html": "Topics\nEnumeration Cases\ncase buffer\ncase none\ncase texture\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "MPSTemporalWeighting | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporalweighting",
    "html": "Topics\nEnumeration Cases\ncase average\ncase exponentialMovingAverage\nRelationships\nConforms To\nSendable"
  },
  {
    "title": "supportsSecureCoding | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationdatasource/3152552-supportssecurecoding",
    "html": "Required"
  },
  {
    "title": "newHeap(with:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsheapprovider/3229861-newheap",
    "html": "Required"
  },
  {
    "title": "alpha(forSourceImage:destinationImage:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngrammatrixcallback/3131846-alpha",
    "html": "Required"
  },
  {
    "title": "init(coder:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationdatasource/3152548-init",
    "html": "Required"
  },
  {
    "title": "beta() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationdatasource/3152543-beta",
    "html": "Required"
  },
  {
    "title": "MPSNNBinaryGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnbinarygradientstate",
    "html": "Relationships\nInherits From\nMPSState"
  },
  {
    "title": "destinationFeatureChannelOffset | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnkernel/2097550-destinationfeaturechanneloffset",
    "html": "Discussion\n\nThis is the starting offset in the destination image in the feature channel dimension at which destination output data is written. This allows you to pass a subset of all the channels in an image as the output of a kernel.\n\nFor example, suppose a destination image has 24 channels and a kernel outputs 8 channels. If we want channels 8 to 15 of this destination image to be used for the output, we can set the value of the destinationFeatureChannelOffset property to 8.\n\nNote that this offset applies independently to each image when the MPSImage object is a container for multiple images and the MPSCNNKernel object is processing multiple images (i.e., clipRect.size.depth > 1).\n\nThe default value is 0. Any other value specified must be a multiple of 4. If the kernel outputs N channels, the destination image must have at least destinationFeatureChannelOffset + N channels. Using a destination image with an insufficient number of feature channels results in an error.\n\nFor example, if a convolution filter outputs 32 channels, and the destination image has 64 channels, then it is an error to set destinationFeatureChannelOffset > 32."
  },
  {
    "title": "height | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648947-height",
    "html": "Discussion\n\nThe formal height of the image, in pixels. The default value is 1.\n\nSee Also\nProperties\nvar width: Int\nThe width of the image.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar pixelFormat: MTLPixelFormat\nThe pixel format for the underlying texture.\nvar channelFormat: MPSImageFeatureChannelFormat\nThe storage format to use for each channel in the image.\nvar cpuCacheMode: MTLCPUCacheMode\nThe CPU cache mode of the underlying texture.\nvar storageMode: MTLStorageMode\nThe storage mode of underlying texture.\nvar usage: MTLTextureUsage\nOptions to specify the intended usage of the underlying texture."
  },
  {
    "title": "image(for:imageDescriptor:kernel:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageallocator/2866966-image",
    "html": "Required"
  },
  {
    "title": "mpsMTLDevice() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsdeviceprovider/2875211-mpsmtldevice",
    "html": "Required"
  },
  {
    "title": "cpuCacheMode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648930-cpucachemode",
    "html": "Discussion\n\nThe default value is MTLCPUCacheMode.defaultCache.\n\nSee Also\nProperties\nvar width: Int\nThe width of the image.\nvar height: Int\nThe height of the image.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar pixelFormat: MTLPixelFormat\nThe pixel format for the underlying texture.\nvar channelFormat: MPSImageFeatureChannelFormat\nThe storage format to use for each channel in the image.\nvar storageMode: MTLStorageMode\nThe storage mode of underlying texture.\nvar usage: MTLTextureUsage\nOptions to specify the intended usage of the underlying texture."
  },
  {
    "title": "offset | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnkernel/1648835-offset",
    "html": "Discussion\n\nThe offset is defined as the position of clipRect.origin in source image coordinates. The default value is {0,0,0}, indicating that the top left corners of the clip rectangle and the source image align.\n\nThe value of offset.z is the index of the starting source image in batch processing mode."
  },
  {
    "title": "storageMode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648955-storagemode",
    "html": "Discussion\n\nThe default value is MTLStorageMode.shared.\n\nSee Also\nProperties\nvar width: Int\nThe width of the image.\nvar height: Int\nThe height of the image.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar pixelFormat: MTLPixelFormat\nThe pixel format for the underlying texture.\nvar channelFormat: MPSImageFeatureChannelFormat\nThe storage format to use for each channel in the image.\nvar cpuCacheMode: MTLCPUCacheMode\nThe CPU cache mode of the underlying texture.\nvar usage: MTLTextureUsage\nOptions to specify the intended usage of the underlying texture."
  },
  {
    "title": "usage | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648937-usage",
    "html": "Discussion\n\nThe default value is shaderRead|shaderWrite.\n\nSee Also\nProperties\nvar width: Int\nThe width of the image.\nvar height: Int\nThe height of the image.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar pixelFormat: MTLPixelFormat\nThe pixel format for the underlying texture.\nvar channelFormat: MPSImageFeatureChannelFormat\nThe storage format to use for each channel in the image.\nvar cpuCacheMode: MTLCPUCacheMode\nThe CPU cache mode of the underlying texture.\nvar storageMode: MTLStorageMode\nThe storage mode of underlying texture."
  },
  {
    "title": "channelFormat | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648818-channelformat",
    "html": "See Also\nProperties\nvar width: Int\nThe width of the image.\nvar height: Int\nThe height of the image.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar pixelFormat: MTLPixelFormat\nThe pixel format for the underlying texture.\nvar cpuCacheMode: MTLCPUCacheMode\nThe CPU cache mode of the underlying texture.\nvar storageMode: MTLStorageMode\nThe storage mode of underlying texture.\nvar usage: MTLTextureUsage\nOptions to specify the intended usage of the underlying texture."
  },
  {
    "title": "pixelFormat | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648913-pixelformat",
    "html": "Discussion\n\nSee Also\nProperties\nvar width: Int\nThe width of the image.\nvar height: Int\nThe height of the image.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar channelFormat: MPSImageFeatureChannelFormat\nThe storage format to use for each channel in the image.\nvar cpuCacheMode: MTLCPUCacheMode\nThe CPU cache mode of the underlying texture.\nvar storageMode: MTLStorageMode\nThe storage mode of underlying texture.\nvar usage: MTLTextureUsage\nOptions to specify the intended usage of the underlying texture."
  },
  {
    "title": "width | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648830-width",
    "html": "Discussion\n\nThe formal width of the image, in pixels. The default value is 1.\n\nSee Also\nProperties\nvar height: Int\nThe height of the image.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar pixelFormat: MTLPixelFormat\nThe pixel format for the underlying texture.\nvar channelFormat: MPSImageFeatureChannelFormat\nThe storage format to use for each channel in the image.\nvar cpuCacheMode: MTLCPUCacheMode\nThe CPU cache mode of the underlying texture.\nvar storageMode: MTLStorageMode\nThe storage mode of underlying texture.\nvar usage: MTLTextureUsage\nOptions to specify the intended usage of the underlying texture."
  },
  {
    "title": "init(channelFormat:width:height:featureChannels:numberOfImages:usage:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648893-init",
    "html": "Parameters\nchannelFormat\n\nThe storage format to use for each channel in the image.\n\nwidth\n\nThe width of the image.\n\nheight\n\nThe height of the image.\n\nfeatureChannels\n\nThe number of feature channels per pixel.\n\nnumberOfImages\n\nThe number of images for batch processing.\n\nusage\n\nThe intended usage of the underlying texture.\n\nReturn Value\n\nA valid MPSImageDescriptor object.\n\nSee Also\nMethods\ninit(channelFormat: MPSImageFeatureChannelFormat, width: Int, height: Int, featureChannels: Int)\nCreates an image descriptor for a single image."
  },
  {
    "title": "init(channelFormat:width:height:featureChannels:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648819-init",
    "html": "Parameters\nchannelFormat\n\nThe storage format to use for each channel in the image.\n\nwidth\n\nThe width of the image.\n\nheight\n\nThe height of the image.\n\nfeatureChannels\n\nThe number of feature channels per pixel.\n\nReturn Value\n\nA valid MPSImageDescriptor object.\n\nSee Also\nMethods\ninit(channelFormat: MPSImageFeatureChannelFormat, width: Int, height: Int, featureChannels: Int, numberOfImages: Int, usage: MTLTextureUsage)\nCreates an image descriptor for an image container with options to set texture usage and batch size (number of images)."
  },
  {
    "title": "rebuild(completionHandler:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsaccelerationstructure/2980770-rebuild",
    "html": "Discussion\n\nConcurrency Note\n\nYou can call this method from synchronous code using a completion handler, as shown on this page, or you can call it as an asynchronous method that has the following declaration:\n\nfunc rebuild() async -> MPSAccelerationStructure?\n\n\nFor information about concurrency and asynchronous code in Swift, see Calling Objective-C APIs Asynchronously."
  },
  {
    "title": "MPSNNPadding | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnpadding",
    "html": "Topics\nInstance Methods\nfunc destinationImageDescriptor(forSourceImages: [MPSImage], sourceStates: [MPSState]?, for: MPSKernel, suggestedDescriptor: MPSImageDescriptor) -> MPSImageDescriptor\nclass MPSImage\nA texture that may have more than four channels for use in convolutional neural networks.\nclass MPSState\nAn opaque data container for large storage in MPS CNN filters.\nclass MPSKernel\nA standard interface for Metal Performance Shaders kernels.\nclass MPSImageDescriptor\nA description of the attributes used to create an MPSImage.\nfunc paddingMethod() -> MPSNNPaddingMethod\n\nRequired\n\nfunc label() -> String\nfunc inverse() -> Self?\nRelationships\nInherits From\nNSObjectProtocol\nNSSecureCoding\nConforming Types\nMPSNNDefaultPadding"
  },
  {
    "title": "paddingMethod() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnpadding/2866950-paddingmethod",
    "html": "Required"
  },
  {
    "title": "options | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpskernel/1618889-options",
    "html": "See Also\nProperties\nstruct MPSKernelOptions\nThe options used when creating a kernel.\nvar device: MTLDevice\nThe device on which the kernel will be used.\nvar label: String?\nThe string that identifies the kernel."
  },
  {
    "title": "MPSCNNNeuronPower | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronpower",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, a: Float, b: Float, c: Float)\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSKernelOptions | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpskerneloptions",
    "html": "Overview\n\nThe Metal Performance Shaders framework uses the same API validation layer that Metal uses to alert you to API mistakes during development. While this option is turned on in your Xcode scheme, common programming errors will either trigger an assert or send a warning to the debug log. Except in the case of serious errors, little or no output should arrive in the console under standard usage. You can set a kernel’s options parameter to the skipAPIValidation value to skip most of this checking. This flag may also lead to small reductions in CPU cost.\n\nTopics\nConstants\nstatic var none: MPSKernelOptions\nThe default option for the kernel. Kernels created with this option will not skip any API validation and will not use reduced precision.\nstatic var skipAPIValidation: MPSKernelOptions\nA property that directs the kernel to perform or skip argument validation.\nstatic var allowReducedPrecision: MPSKernelOptions\nWhen possible, kernels use a higher-precision data representation internally than the destination storage format to avoid excessive accumulation of computational rounding error in the result. This option advises the kernel that the destination storage format already has too much precision for what is ultimately required downstream, and the kernel may use reduced precision internally when it determines that a less precise result would yield better performance. When enabled, the performance win is often small and the precision of the result may vary by hardware and OS.\nstatic var disableInternalTiling: MPSKernelOptions\nSome kernels may automatically split up their work internally into multiple tiles. This improves performance on larger textures and reduces the amount of memory needed by the framework for temporary storage. However, if you are using your own tiling scheme to achieve similar results, your tile sizes and the framework’s choice of tile sizes may interfere with one another, causing the framework to subdivide your tiles for its own use inefficiently. Use this option to force the framework to process your data tile as a single chunk.\nstatic var insertDebugGroups: MPSKernelOptions\nEnabling this option will cause various kernel encode methods to call the pushDebugGroup(_:) and popDebugGroup() methods. The debug string will be drawn from the kernel’s label property, if available, or the name of the class otherwise.\nInitializers\ninit(rawValue: UInt)\nType Properties\nstatic var verbose: MPSKernelOptions\nRelationships\nConforms To\nOptionSet\nSendable\nSee Also\nProperties\nvar options: MPSKernelOptions\nThe set of options used to run the kernel.\nvar device: MTLDevice\nThe device on which the kernel will be used.\nvar label: String?\nThe string that identifies the kernel."
  },
  {
    "title": "device | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpskernel/1618824-device",
    "html": "See Also\nProperties\nvar options: MPSKernelOptions\nThe set of options used to run the kernel.\nstruct MPSKernelOptions\nThe options used when creating a kernel.\nvar label: String?\nThe string that identifies the kernel."
  },
  {
    "title": "label | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpskernel/1618803-label",
    "html": "See Also\nProperties\nvar options: MPSKernelOptions\nThe set of options used to run the kernel.\nstruct MPSKernelOptions\nThe options used when creating a kernel.\nvar device: MTLDevice\nThe device on which the kernel will be used."
  },
  {
    "title": "MPSCNNSoftMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnsoftmax",
    "html": "Overview\n\nThe softmax filter is applied across feature channels in a convolutional manner at all spatial locations. The softmax filter can be seen as the combination of an activation function (exponential) and a normalization operator.\n\nFor each feature channel per pixel in an image in a feature map, the softmax filter computes the following:\n\nWhere R is the result channel in the pixel and N is the number of feature channels.\n\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nSoftmax Layers\nclass MPSCNNLogSoftMax\nA neural transfer function that is useful for constructing a loss function to be minimized when training neural networks.\nclass MPSCNNLogSoftMaxGradient\nA gradient logarithmic softmax filter.\nclass MPSCNNSoftMaxGradient\nA gradient softmax filter."
  },
  {
    "title": "MPSNNGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngradientstate",
    "html": "Relationships\nInherits From\nMPSState"
  },
  {
    "title": "MPSNNBinaryGradientStateNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnbinarygradientstatenode",
    "html": "Relationships\nInherits From\nMPSNNStateNode"
  },
  {
    "title": "MPSNNGradientStateNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngradientstatenode",
    "html": "Relationships\nInherits From\nMPSNNStateNode"
  },
  {
    "title": "MPSNNReshape | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreshape",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationState: AutoreleasingUnsafeMutablePointer<MPSState?>, destinationStateIsTemporary: Bool, reshapedWidth: Int, reshapedHeight: Int, reshapedFeatureChannels: Int) -> MPSImage\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, reshapedWidth: Int, reshapedHeight: Int, reshapedFeatureChannels: Int) -> MPSImage\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], destinationStates: AutoreleasingUnsafeMutablePointer<NSArray?>, destinationStateIsTemporary: Bool, reshapedWidth: Int, reshapedHeight: Int, reshapedFeatureChannels: Int) -> [MPSImage]\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], reshapedWidth: Int, reshapedHeight: Int, reshapedFeatureChannels: Int) -> [MPSImage]\nRelationships\nInherits From\nMPSCNNKernel"
  },
  {
    "title": "MPSRNNSequenceDirection | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnsequencedirection",
    "html": "Topics\nEnumeration Cases\ncase backward\ncase forward\nRelationships\nConforms To\nSendable\nSee Also\nRecurrent Neural Networks\nclass MPSRNNImageInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders images.\nclass MPSRNNMatrixInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders matrices.\nclass MPSRNNSingleGateDescriptor\nA description of a simple recurrent block or layer.\nclass MPSGRUDescriptor\nA description of a gated recurrent unit block or layer.\nclass MPSLSTMDescriptor\nA description of a long short-term memory block or layer.\nclass MPSRNNMatrixTrainingLayer\nA layer for training recurrent neural networks on Metal Performance Shaders matrices.\nclass MPSRNNMatrixTrainingState\nA class that holds data from a forward pass to be used in a backward pass."
  },
  {
    "title": "MPSLSTMDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpslstmdescriptor",
    "html": "Overview\n\nThe recurrent neural network (RNN) layer initialized with MPSLSTMDescriptor transforms the input data (image or matrix), the memory cell data, and previous output with a set of filters. Each produces one feature map in the output data and memory cell according to the long short-term memory (LSTM) formula detailed below.\n\nYou may provide the LSTM unit with a single input or a sequence of inputs.\n\nDescription of Operation\n\nLet x_j be the input data (at time index t of sequence, j index containing quadruplet: batch index, x,y and feature index (x = y = 0 for matrices)).\n\nLet h0_j be the recurrent input (previous output) data from previous time step (at time index t-1 of sequence).\n\nLet h1_i be the output data produced at this time step.\n\nLet c0_j be the previous memory cell data (at time index t-1 of sequence).\n\nLet c1_i be the new memory cell data (at time index t-1 of sequence).\n\nLet Wi_ij, Ui_ij, Vi_ij be the input gate weights for input, recurrent input, and memory cell (peephole) data, respectively.\n\nLet bi_i be the bias for the input gate.\n\nLet Wf_ij, Uf_ij, Vf_ij be the forget gate weights for input, recurrent input, and memory cell data, respectively.\n\nLet bf_i be the bias for the forget gate.\n\nLet Wo_ij, Uo_ij, Vo_ij be the output gate weights for input, recurrent input, and memory cell data, respectively.\n\nLet bo_i be the bias for the output gate.\n\nLet Wc_ij, Uc_ij, Vc_ij be the memory cell gate weights for input, recurrent input, and memory cell data, respectively.\n\nLet bc_i be the bias for the memory cell gate.\n\nLet gi(x), gf(x), go(x), gc(x) be the neuron activation function for the input, forget, output gate, and memory cell gate.\n\nLet gh(x) be the activation function applied to result memory cell data.\n\nThe output of the LSTM layer is computed as follows:\n\nI_i = gi(  Wi_ij * x_j  +  Ui_ij * h0_j  +  Vi_ij * c0_j  + bi_i  )\nF_i = gf(  Wf_ij * x_j  +  Uf_ij * h0_j  +  Vf_ij * c0_j  + bf_i  )\nC_i = gc(  Wc_ij * x_j  +  Uc_ij * h0_j  +  Vc_ij * c0_j  + bc_i  )\n\n\nc1_i = F_i c0_i  +  I_i C_i\n\n\nO_i = go(  Wo_ij * x_j  +  Uo_ij * h0_j  +  Vo_ij * c1_j  + bo_i  )\nh1_i = O_i gh( c1_i )\n\n\nThe * stands for convolution (see MPSRNNImageInferenceLayer) or matrix-vector/matrix multiplication (see MPSRNNMatrixInferenceLayer).\n\nSummation is over index j (except for the batch index), but there's no summation over repeated index i (the output index).\n\nNote that for validity, all intermediate images must be of same size, and all U and V matrices must be square (that is, outputFeatureChannels == inputFeatureChannels). Also, the bias terms are scalars with regard to spatial dimensions.\n\nTopics\nInstance Properties\nvar cellGateInputWeights: MPSCNNConvolutionDataSource?\nvar cellGateMemoryWeights: MPSCNNConvolutionDataSource?\nvar cellGateRecurrentWeights: MPSCNNConvolutionDataSource?\nvar cellToOutputNeuronParamA: Float\nvar cellToOutputNeuronParamB: Float\nvar cellToOutputNeuronType: MPSCNNNeuronType\nenum MPSCNNNeuronType\nThe types of neuron filter to append to a convolution.\nvar forgetGateInputWeights: MPSCNNConvolutionDataSource?\nvar forgetGateMemoryWeights: MPSCNNConvolutionDataSource?\nvar forgetGateRecurrentWeights: MPSCNNConvolutionDataSource?\nvar inputGateInputWeights: MPSCNNConvolutionDataSource?\nvar inputGateMemoryWeights: MPSCNNConvolutionDataSource?\nvar inputGateRecurrentWeights: MPSCNNConvolutionDataSource?\nvar memoryWeightsAreDiagonal: Bool\nvar outputGateInputWeights: MPSCNNConvolutionDataSource?\nvar outputGateMemoryWeights: MPSCNNConvolutionDataSource?\nvar outputGateRecurrentWeights: MPSCNNConvolutionDataSource?\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\nvar cellToOutputNeuronParamC: Float\nType Methods\nclass func createLSTMDescriptor(withInputFeatureChannels: Int, outputFeatureChannels: Int) -> Self\nRelationships\nInherits From\nMPSRNNDescriptor\nSee Also\nRecurrent Neural Networks\nclass MPSRNNImageInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders images.\nclass MPSRNNMatrixInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders matrices.\nclass MPSRNNSingleGateDescriptor\nA description of a simple recurrent block or layer.\nclass MPSGRUDescriptor\nA description of a gated recurrent unit block or layer.\nenum MPSRNNSequenceDirection\nDirections that a sequence of inputs can be processed by a recurrent neural network layer.\nclass MPSRNNMatrixTrainingLayer\nA layer for training recurrent neural networks on Metal Performance Shaders matrices.\nclass MPSRNNMatrixTrainingState\nA class that holds data from a forward pass to be used in a backward pass."
  },
  {
    "title": "MPSGRUDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsgrudescriptor",
    "html": "Overview\n\nThe recurrent neural network (RNN) layer initialized with a MPSGRUDescriptor transforms the input data (image or matrix) and previous output with a set of filters. Each produces one feature map in the output data according to the gated recurrent unit (GRU) unit formula detailed below.\n\nYou may provide the GRU unit with a single input or a sequence of inputs. The layer also supports p-norm gating.\n\nDescription of Operation\n\nLet x_j be the input data (at time index t of sequence, j index containing quadruplet: batch index, x,y and feature index (x = y = 0 for matrices)).\n\nLet h0_j be the recurrent input (previous output) data from previous time step (at time index t-1 of sequence).\n\nLet h_i be the proposed new output.\n\nLet h1_i be the output data produced at this time step.\n\nLet Wz_ij, Uz_ij be the input gate weights for input and recurrent input data, respectively.\n\nLet bi_i be the bias for the input gate.\n\nLet Wr_ij, Ur_ij be the recurrent gate weights for input and recurrent input data, respectively.\n\nLet br_i be the bias for the recurrent gate.\n\nLet Wh_ij, Uh_ij, Vh_ij be the output gate weights for input, recurrent gate, and input gate, respectively.\n\nLet bh_i be the bias for the output gate.\n\nLet gz(x), gr(x), gh(x) be the neuron activation function for the input, recurrent, and output gates.\n\nLet p > 0 be a scalar variable (typical p >= 1.0) that defines the p-norm gating norm value.\n\nThe output of the GRU layer is computed as follows:\n\nz_i = gz(  Wz_ij * x_j  +  Uz_ij * h0_j  +  bz_i  )\nr_i = gr(  Wr_ij * x_j  +  Ur_ij * h0_j  +  br_i  )\nc_i =      Uh_ij * (r_j h0_j)  +  Vh_ij * (z_j h0_j)\nh_i = gh(  Wh_ij * x_j  + c_i + bh_i  )\n\n\nh1_i = ( 1 - z_i ^ p)^(1/p) h0_i + z_i h_i\n\n\nThe * stands for convolution (see MPSRNNImageInferenceLayer) or matrix-vector/matrix multiplication (see MPSRNNMatrixInferenceLayer).\n\nSummation is over index j (except for the batch index), but there's no summation over repeated index i,the output index.\n\nNote that for validity, all intermediate images must be of same size, and all U and V matrices must be square (that is, outputFeatureChannels == inputFeatureChannels). Also, the bias terms are scalars with regard to spatial dimensions. The conventional GRU block is achieved by setting Vh = 0 (nil), and the Minimal Gated Unit is achieved with Uh = 0.\n\nTopics\nInstance Properties\nvar flipOutputGates: Bool\nvar gatePnormValue: Float\nvar inputGateInputWeights: MPSCNNConvolutionDataSource?\nvar inputGateRecurrentWeights: MPSCNNConvolutionDataSource?\nvar outputGateInputGateWeights: MPSCNNConvolutionDataSource?\nvar outputGateInputWeights: MPSCNNConvolutionDataSource?\nvar outputGateRecurrentWeights: MPSCNNConvolutionDataSource?\nvar recurrentGateInputWeights: MPSCNNConvolutionDataSource?\nvar recurrentGateRecurrentWeights: MPSCNNConvolutionDataSource?\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\nType Methods\nclass func createGRUDescriptor(withInputFeatureChannels: Int, outputFeatureChannels: Int) -> Self\nRelationships\nInherits From\nMPSRNNDescriptor\nSee Also\nRecurrent Neural Networks\nclass MPSRNNImageInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders images.\nclass MPSRNNMatrixInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders matrices.\nclass MPSRNNSingleGateDescriptor\nA description of a simple recurrent block or layer.\nclass MPSLSTMDescriptor\nA description of a long short-term memory block or layer.\nenum MPSRNNSequenceDirection\nDirections that a sequence of inputs can be processed by a recurrent neural network layer.\nclass MPSRNNMatrixTrainingLayer\nA layer for training recurrent neural networks on Metal Performance Shaders matrices.\nclass MPSRNNMatrixTrainingState\nA class that holds data from a forward pass to be used in a backward pass."
  },
  {
    "title": "MPSRNNSingleGateDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnsinglegatedescriptor",
    "html": "Overview\n\nThe recurrent neural network (RNN) layer initialized with a MPSRNNSingleGateDescriptor transforms the input data (image or matrix) and previous output with a set of filters. Each produces one feature map in the new output data.\n\nYou may provide the RNN unit with a single input or a sequence of inputs.\n\nDescription of Operation\n\nLet x_j be the input data (at time index t of sequence, j index containing quadruplet: batch index, x,y and feature index (x = y = 0 for matrices)).\n\nLet h0_j be the recurrent input (previous output) data from previous time step (at time index t-1 of sequence).\n\nLet h1_i be the output data produced at this time step.\n\nLet W_ij, U_ij be the weights for input and recurrent input data, respectively.\n\nLet b_i be a bias term.\n\nLet gi(x) be a neuron activation function.\n\nThe new output image h1_i data is computed as follows:\n\nh1_i = gi( W_ij * x_j + U_ij * h0_j  + b_i )\n\n\nThe * stands for convolution (see MPSRNNImageInferenceLayer) or matrix-vector/matrix multiplication (see MPSRNNMatrixInferenceLayer).\n\nSummation is over index j (except for the batch index), but there's no summation over repeated index i (the output index).\n\nNote that for validity, all intermediate images must be of same size, and the U matrix must be square (that is, outputFeatureChannels == inputFeatureChannels). Also, the bias terms are scalars with regard to spatial dimensions.\n\nTopics\nInstance Properties\nvar inputWeights: MPSCNNConvolutionDataSource?\nvar recurrentWeights: MPSCNNConvolutionDataSource?\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\nType Methods\nclass func createRNNSingleGateDescriptor(withInputFeatureChannels: Int, outputFeatureChannels: Int) -> Self\nRelationships\nInherits From\nMPSRNNDescriptor\nSee Also\nRecurrent Neural Networks\nclass MPSRNNImageInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders images.\nclass MPSRNNMatrixInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders matrices.\nclass MPSGRUDescriptor\nA description of a gated recurrent unit block or layer.\nclass MPSLSTMDescriptor\nA description of a long short-term memory block or layer.\nenum MPSRNNSequenceDirection\nDirections that a sequence of inputs can be processed by a recurrent neural network layer.\nclass MPSRNNMatrixTrainingLayer\nA layer for training recurrent neural networks on Metal Performance Shaders matrices.\nclass MPSRNNMatrixTrainingState\nA class that holds data from a forward pass to be used in a backward pass."
  },
  {
    "title": "MPSRNNMatrixInferenceLayer | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnmatrixinferencelayer",
    "html": "Overview\n\nThe MPSRNNMatrixInferenceLayer specifies a recurrent neural network layer for inference on MPSMatrix objects. Two types of recurrent layers are supported:\n\nMPSRNNImageInferenceLayer—Operates with convolutions on images.\n\nMPSRNNMatrixInferenceLayer—Operates on matrices.\n\nYou can use MPSRNNImageInferenceLayer to implement the latter by using 1 x 1 images, but due to image size restrictions and performance, MPSRNNMatrixInferenceLayer is the better choice for linear recurrent layers.\n\nMPSRNNMatrixInferenceLayer is initialized using either of the following:\n\nA single MPSRNNDescriptor instance, which further specifies the recurrent network layer.\n\nAn array of MPSRNNDescriptor instances, which specifies a stack of recurrent layers that can operate in parallel a subset of the inputs in a sequence of inputs and recurrent outputs.\n\nStacks with bidirectionally traversing encode functions don't support starting from a previous set of recurrent states. However, you can achieve this effect by defining two separate unidirectional stacks of layers, running the same input sequence on them separately (one forward and one backward), and ultimately combining the two result sequences.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, rnnDescriptor: MPSRNNDescriptor)\ninit(device: MTLDevice, rnnDescriptors: [MPSRNNDescriptor])\nclass MPSRNNDescriptor\nA description of a recursive neural network block or layer.\nInstance Properties\nvar bidirectionalCombineMode: MPSRNNBidirectionalCombineMode\nenum MPSRNNBidirectionalCombineMode\nModes that define how two images or matrices are combined.\nvar inputFeatureChannels: Int\nvar numberOfLayers: Int\nvar outputFeatureChannels: Int\nvar recurrentOutputIsTemporary: Bool\nvar storeAllIntermediateStates: Bool\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encodeBidirectionalSequence(commandBuffer: MTLCommandBuffer, sourceSequence: [MPSMatrix], destinationForwardMatrices: [MPSMatrix], destinationBackwardMatrices: [MPSMatrix]?)\nfunc encodeSequence(commandBuffer: MTLCommandBuffer, sourceMatrices: [MPSMatrix], destinationMatrices: [MPSMatrix], recurrentInputState: MPSRNNRecurrentMatrixState?, recurrentOutputStates: NSMutableArray?)\nclass MPSRNNRecurrentMatrixState\nA class holds all the data that's passed from one sequence iteration of the matrix-based recurrent neural network layer to the next.\nfunc encodeSequence(commandBuffer: MTLCommandBuffer, sourceMatrices: [MPSMatrix], sourceOffsets: UnsafeMutablePointer<Int>?, destinationMatrices: [MPSMatrix], destinationOffsets: UnsafeMutablePointer<Int>?, recurrentInputState: MPSRNNRecurrentMatrixState?, recurrentOutputStates: NSMutableArray?)\nRelationships\nInherits From\nMPSKernel\nSee Also\nRecurrent Neural Networks\nclass MPSRNNImageInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders images.\nclass MPSRNNSingleGateDescriptor\nA description of a simple recurrent block or layer.\nclass MPSGRUDescriptor\nA description of a gated recurrent unit block or layer.\nclass MPSLSTMDescriptor\nA description of a long short-term memory block or layer.\nenum MPSRNNSequenceDirection\nDirections that a sequence of inputs can be processed by a recurrent neural network layer.\nclass MPSRNNMatrixTrainingLayer\nA layer for training recurrent neural networks on Metal Performance Shaders matrices.\nclass MPSRNNMatrixTrainingState\nA class that holds data from a forward pass to be used in a backward pass."
  },
  {
    "title": "MPSRNNImageInferenceLayer | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnimageinferencelayer",
    "html": "Overview\n\nThe MPSRNNImageInferenceLayer specifies a recurrent neural network layer for inference on MPSImage objects. Two types of recurrent layers are supported:\n\nMPSRNNImageInferenceLayer—Operates with convolutions on images.\n\nMPSRNNMatrixInferenceLayer—Operates on matrices.\n\nYou can use MPSRNNImageInferenceLayer to implement the latter by using 1 x 1 images, but due to image size restrictions and performance, MPSRNNMatrixInferenceLayer is the better choice for linear recurrent layers.\n\nMPSRNNImageInferenceLayer is initialized using either of the following:\n\nA single MPSRNNDescriptor instance, which further specifies the recurrent network layer.\n\nAn array of MPSRNNDescriptor instances, which specifies a stack of recurrent layers that can operate in parallel a subset of the inputs in a sequence of inputs and recurrent outputs.\n\nStacks with bidirectionally traversing encode functions don't support starting from a previous set of recurrent states. However, you can achieve this effect by defining two separate unidirectional stacks of layers, running the same input sequence on them separately (one forward and one backward), and ultimately combining the two result sequences.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, rnnDescriptor: MPSRNNDescriptor)\ninit(device: MTLDevice, rnnDescriptors: [MPSRNNDescriptor])\nclass MPSRNNDescriptor\nA description of a recursive neural network block or layer.\nInstance Properties\nvar bidirectionalCombineMode: MPSRNNBidirectionalCombineMode\nenum MPSRNNBidirectionalCombineMode\nModes that define how two images or matrices are combined.\nvar numberOfLayers: Int\nvar recurrentOutputIsTemporary: Bool\nvar storeAllIntermediateStates: Bool\nvar inputFeatureChannels: Int\nvar outputFeatureChannels: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encodeBidirectionalSequence(commandBuffer: MTLCommandBuffer, sourceSequence: [MPSImage], destinationForwardImages: [MPSImage], destinationBackwardImages: [MPSImage]?)\nfunc encodeSequence(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], destinationImages: [MPSImage], recurrentInputState: MPSRNNRecurrentImageState?, recurrentOutputStates: NSMutableArray?)\nclass MPSRNNRecurrentImageState\nA class that holds all the data that's passed from one sequence iteration of the image-based recurrent neural network layer (stack) to the next.\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nRecurrent Neural Networks\nclass MPSRNNMatrixInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders matrices.\nclass MPSRNNSingleGateDescriptor\nA description of a simple recurrent block or layer.\nclass MPSGRUDescriptor\nA description of a gated recurrent unit block or layer.\nclass MPSLSTMDescriptor\nA description of a long short-term memory block or layer.\nenum MPSRNNSequenceDirection\nDirections that a sequence of inputs can be processed by a recurrent neural network layer.\nclass MPSRNNMatrixTrainingLayer\nA layer for training recurrent neural networks on Metal Performance Shaders matrices.\nclass MPSRNNMatrixTrainingState\nA class that holds data from a forward pass to be used in a backward pass."
  },
  {
    "title": "MPSMatrixSoftMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixsoftmax",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar sourceColumns: Int\nvar sourceRows: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(commandBuffer: MTLCommandBuffer, inputMatrix: MPSMatrix, resultMatrix: MPSMatrix)\nRelationships\nInherits From\nMPSMatrixUnaryKernel\nSee Also\nMatrix Softmax Operations\nclass MPSMatrixLogSoftMax\nA logarithmic softmax kernel that operates on matrices.\nclass MPSMatrixLogSoftMaxGradient\nA logarithmic gradient softmax kernel that operates on matrices.\nclass MPSMatrixSoftMaxGradient\nA gradient softmax kernel that operates on matrices."
  },
  {
    "title": "MPSMatrixBatchNormalizationGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixbatchnormalizationgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar epsilon: Float\nvar sourceInputFeatureChannels: Int\nvar sourceNumberOfFeatureVectors: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(to: MTLCommandBuffer, gradientMatrix: MPSMatrix, inputMatrix: MPSMatrix, mean: MPSVector, varianceVector: MPSVector, gammaVector: MPSVector?, betaVector: MPSVector?, resultGradientForDataMatrix: MPSMatrix, resultGradientForGammaVector: MPSVector?, resultGradientForBetaVector: MPSVector?)\nfunc neuronParameterA() -> Float\nfunc neuronParameterB() -> Float\nfunc neuronParameterC() -> Float\nfunc neuronType() -> MPSCNNNeuronType\nfunc setNeuronType(MPSCNNNeuronType, parameterA: Float, parameterB: Float, parameterC: Float)\nRelationships\nInherits From\nMPSMatrixBinaryKernel\nSee Also\nMatrix Normalization Operations\nclass MPSMatrixBatchNormalization\nA batch normalization kernel that operates on matrices."
  },
  {
    "title": "MPSMatrixSoftMaxGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixsoftmaxgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar sourceColumns: Int\nvar sourceRows: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(to: MTLCommandBuffer, gradientMatrix: MPSMatrix, forwardOutputMatrix: MPSMatrix, resultMatrix: MPSMatrix)\nRelationships\nInherits From\nMPSMatrixBinaryKernel\nSee Also\nMatrix Softmax Operations\nclass MPSMatrixLogSoftMax\nA logarithmic softmax kernel that operates on matrices.\nclass MPSMatrixLogSoftMaxGradient\nA logarithmic gradient softmax kernel that operates on matrices.\nclass MPSMatrixSoftMax\nA softmax kernel that operates on matrices."
  },
  {
    "title": "MPSMatrixNeuronGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixneurongradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar alpha: Double\nvar sourceInputFeatureChannels: Int\nvar sourceNumberOfFeatureVectors: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(to: MTLCommandBuffer, gradientMatrix: MPSMatrix, inputMatrix: MPSMatrix, biasVector: MPSVector?, resultGradientForDataMatrix: MPSMatrix, resultGradientForBiasVector: MPSVector?)\nfunc neuronParameterA() -> Float\nfunc neuronParameterB() -> Float\nfunc neuronParameterC() -> Float\nfunc neuronType() -> MPSCNNNeuronType\nfunc setNeuronToPReLUWithParametersA(Data)\nfunc setNeuronType(MPSCNNNeuronType, parameterA: Float, parameterB: Float, parameterC: Float)\nRelationships\nInherits From\nMPSMatrixBinaryKernel\nSee Also\nMatrix Neural Network Operations\nclass MPSMatrixFullyConnected\nA kernel for applying a fully connected neural network layer.\nclass MPSMatrixFullyConnectedGradient\nA kernel for applying a fully gradient connected neural network layer.\nclass MPSMatrixNeuron\nA neuron activation kernel that operates on matrices."
  },
  {
    "title": "MPSMatrixLogSoftMaxGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixlogsoftmaxgradient",
    "html": "Relationships\nInherits From\nMPSMatrixSoftMaxGradient\nSee Also\nMatrix Softmax Operations\nclass MPSMatrixLogSoftMax\nA logarithmic softmax kernel that operates on matrices.\nclass MPSMatrixSoftMax\nA softmax kernel that operates on matrices.\nclass MPSMatrixSoftMaxGradient\nA gradient softmax kernel that operates on matrices."
  },
  {
    "title": "MPSMatrixLogSoftMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixlogsoftmax",
    "html": "Relationships\nInherits From\nMPSMatrixSoftMax\nSee Also\nMatrix Softmax Operations\nclass MPSMatrixLogSoftMaxGradient\nA logarithmic gradient softmax kernel that operates on matrices.\nclass MPSMatrixSoftMax\nA softmax kernel that operates on matrices.\nclass MPSMatrixSoftMaxGradient\nA gradient softmax kernel that operates on matrices."
  },
  {
    "title": "MPSMatrixNeuron | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixneuron",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar alpha: Double\nvar sourceInputFeatureChannels: Int\nvar sourceNumberOfFeatureVectors: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(commandBuffer: MTLCommandBuffer, inputMatrix: MPSMatrix, biasVector: MPSVector?, resultMatrix: MPSMatrix)\nfunc neuronParameterA() -> Float\nfunc neuronParameterB() -> Float\nfunc neuronParameterC() -> Float\nfunc neuronType() -> MPSCNNNeuronType\nfunc setNeuronToPReLUWithParametersA(Data)\nfunc setNeuronType(MPSCNNNeuronType, parameterA: Float, parameterB: Float, parameterC: Float)\nRelationships\nInherits From\nMPSMatrixUnaryKernel\nSee Also\nMatrix Neural Network Operations\nclass MPSMatrixFullyConnected\nA kernel for applying a fully connected neural network layer.\nclass MPSMatrixFullyConnectedGradient\nA kernel for applying a fully gradient connected neural network layer.\nclass MPSMatrixNeuronGradient\nA gradient neuron activation kernel that operates on matrices."
  },
  {
    "title": "MPSMatrixFullyConnectedGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixfullyconnectedgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar alpha: Double\nvar sourceInputFeatureChannels: Int\nvar sourceNumberOfFeatureVectors: Int\nvar sourceOutputFeatureChannels: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encodeForData(to: MTLCommandBuffer, gradientMatrix: MPSMatrix, weightMatrix: MPSMatrix, resultGradientForDataMatrix: MPSMatrix)\nfunc encodeForWeightsAndBias(to: MTLCommandBuffer, gradientMatrix: MPSMatrix, inputMatrix: MPSMatrix, resultGradientForWeightMatrix: MPSMatrix, resultGradientForBiasVector: MPSVector?)\nRelationships\nInherits From\nMPSMatrixBinaryKernel\nSee Also\nMatrix Neural Network Operations\nclass MPSMatrixFullyConnected\nA kernel for applying a fully connected neural network layer.\nclass MPSMatrixNeuron\nA neuron activation kernel that operates on matrices.\nclass MPSMatrixNeuronGradient\nA gradient neuron activation kernel that operates on matrices."
  },
  {
    "title": "MPSImageCopyToMatrix | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagecopytomatrix",
    "html": "Overview\n\nThis kernel copies image data to a MPSMatrix object. The image data is stored in a row of a matrix. The dataLayout specifies the order in which the feature channels in the image get stored in the matrix. If the MPSImage stores a batch of images, the images are copied into multiple rows, one row per image.\n\nThe number of elements in a row in the matrix must be greater than the image width multiplied its height multiplied by the number of featureChannels in the image.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, dataLayout: MPSDataLayout)\nInstance Properties\nvar dataLayout: MPSDataLayout\nvar destinationMatrixBatchIndex: Int\nvar destinationMatrixOrigin: MTLOrigin\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationMatrix: MPSMatrix)\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], destinationMatrix: MPSMatrix)\nRelationships\nInherits From\nMPSKernel\nSee Also\nMatrix Copying Operations\nclass MPSMatrixCopy\nA class that can perform multiple matrix copy operations.\nclass MPSMatrixCopyToImage\nA kernel that copies matrix data to a Metal Performance Shaders image.\nclass MPSMatrixCopyDescriptor\nA description of multiple matrix copy operations."
  },
  {
    "title": "MPSMatrixCopyToImage | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixcopytoimage",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, dataLayout: MPSDataLayout)\nInstance Properties\nvar dataLayout: MPSDataLayout\nvar sourceMatrixBatchIndex: Int\nvar sourceMatrixOrigin: MTLOrigin\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceMatrix: MPSMatrix, destinationImage: MPSImage)\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceMatrix: MPSMatrix, destinationImages: [MPSImage])\nRelationships\nInherits From\nMPSKernel\nSee Also\nMatrix Copying Operations\nclass MPSMatrixCopy\nA class that can perform multiple matrix copy operations.\nclass MPSMatrixCopyDescriptor\nA description of multiple matrix copy operations.\nclass MPSImageCopyToMatrix\nA class that copies image data to a matrix."
  },
  {
    "title": "MPSMatrixFullyConnected | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixfullyconnected",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar alpha: Double\nvar sourceInputFeatureChannels: Int\nvar sourceNumberOfFeatureVectors: Int\nvar sourceOutputFeatureChannels: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(commandBuffer: MTLCommandBuffer, inputMatrix: MPSMatrix, weightMatrix: MPSMatrix, biasVector: MPSVector?, resultMatrix: MPSMatrix)\nfunc neuronParameterA() -> Float\nfunc neuronParameterB() -> Float\nfunc neuronParameterC() -> Float\nfunc neuronType() -> MPSCNNNeuronType\nfunc setNeuronType(MPSCNNNeuronType, parameterA: Float, parameterB: Float, parameterC: Float)\nRelationships\nInherits From\nMPSMatrixBinaryKernel\nSee Also\nMatrix Neural Network Operations\nclass MPSMatrixFullyConnectedGradient\nA kernel for applying a fully gradient connected neural network layer.\nclass MPSMatrixNeuron\nA neuron activation kernel that operates on matrices.\nclass MPSMatrixNeuronGradient\nA gradient neuron activation kernel that operates on matrices."
  },
  {
    "title": "MPSMatrixCopyDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixcopydescriptor",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, count: Int)\ninit(sourceMatrices: [MPSMatrix], destinationMatrices: [MPSMatrix], offsetVector: MPSVector?, offset: Int)\ninit(sourceMatrix: MPSMatrix, destinationMatrix: MPSMatrix, offsets: MPSMatrixCopyOffsets)\nInstance Methods\nfunc setCopyOperationAt(Int, sourceMatrix: MPSMatrix, destinationMatrix: MPSMatrix, offsets: MPSMatrixCopyOffsets)\nRelationships\nInherits From\nNSObject\nSee Also\nMatrix Copying Operations\nclass MPSMatrixCopy\nA class that can perform multiple matrix copy operations.\nclass MPSMatrixCopyToImage\nA kernel that copies matrix data to a Metal Performance Shaders image.\nclass MPSImageCopyToMatrix\nA class that copies image data to a matrix."
  },
  {
    "title": "MPSMatrixCopy | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixcopy",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, copyRows: Int, copyColumns: Int, sourcesAreTransposed: Bool, destinationsAreTransposed: Bool)\nInstance Properties\nvar copyColumns: Int\nvar copyRows: Int\nvar destinationsAreTransposed: Bool\nvar sourcesAreTransposed: Bool\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, copyDescriptor: MPSMatrixCopyDescriptor)\nfunc encode(commandBuffer: MTLCommandBuffer, copyDescriptor: MPSMatrixCopyDescriptor, rowPermuteIndices: MPSVector?, rowPermuteOffset: Int, columnPermuteIndices: MPSVector?, columnPermuteOffset: Int)\nRelationships\nInherits From\nMPSKernel\nSee Also\nMatrix Copying Operations\nclass MPSMatrixCopyToImage\nA kernel that copies matrix data to a Metal Performance Shaders image.\nclass MPSMatrixCopyDescriptor\nA description of multiple matrix copy operations.\nclass MPSImageCopyToMatrix\nA class that copies image data to a matrix."
  },
  {
    "title": "MPSMatrixFindTopK | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixfindtopk",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, numberOfTopKValues: Int)\nInstance Properties\nvar indexOffset: Int\nvar numberOfTopKValues: Int\nvar sourceColumns: Int\nvar sourceRows: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(commandBuffer: MTLCommandBuffer, inputMatrix: MPSMatrix, resultIndexMatrix: MPSMatrix, resultValueMatrix: MPSMatrix)\nRelationships\nInherits From\nMPSMatrixUnaryKernel\nSee Also\nMatrix Arithmetic Operations\nclass MPSMatrixSum\nA kernel for performing a pointwise summation of a matrix.\nclass MPSMatrixMultiplication\nA matrix multiplication kernel.\nclass MPSMatrixVectorMultiplication\nA matrix-vector multiplication kernel"
  },
  {
    "title": "MPSCNNInstanceNormalizationGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationgradient",
    "html": "Relationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSNNNeuronDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnneurondescriptor",
    "html": "Topics\nInstance Properties\nvar a: Float\nvar b: Float\nvar c: Float\nvar data: Data?\nvar neuronType: MPSCNNNeuronType\nType Methods\nclass func cnnNeuronDescriptor(with: MPSCNNNeuronType) -> MPSNNNeuronDescriptor\nclass func cnnNeuronDescriptor(with: MPSCNNNeuronType, a: Float) -> MPSNNNeuronDescriptor\nclass func cnnNeuronDescriptor(with: MPSCNNNeuronType, a: Float, b: Float) -> MPSNNNeuronDescriptor\nclass func cnnNeuronDescriptor(with: MPSCNNNeuronType, a: Float, b: Float, c: Float) -> MPSNNNeuronDescriptor\nclass func cnnNeuronPReLUDescriptor(with: Data, noCopy: Bool) -> MPSNNNeuronDescriptor\nRelationships\nInherits From\nNSObject\nConforms To\nNSCopying\nNSSecureCoding\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter."
  },
  {
    "title": "MPSCNNBatchNormalizationStatisticsGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationstatisticsgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, fusedNeuronDescriptor: MPSNNNeuronDescriptor?)\nInstance Methods\nfunc encodeBatch(to: MTLCommandBuffer, sourceGradients: [MPSImage], sourceImages: [MPSImage], batchNormalizationState: MPSCNNBatchNormalizationState)\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNInstanceNormalizationGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationgradientstate",
    "html": "Topics\nInstance Properties\nvar beta: MTLBuffer?\nvar gamma: MTLBuffer?\nvar gradientForBeta: MTLBuffer\nvar gradientForGamma: MTLBuffer\nvar instanceNormalization: MPSCNNInstanceNormalization\nRelationships\nInherits From\nMPSNNGradientState\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNNeuronGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneurongradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, neuronDescriptor: MPSNNNeuronDescriptor)\nInstance Properties\nvar a: Float\nvar b: Float\nvar c: Float\nvar data: Data?\nvar neuronType: MPSCNNNeuronType\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSCNNNeuron | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuron",
    "html": "Overview\n\nDo not use this class directly; use one of the MPSCNNNeuron subclasses instead.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, neuronDescriptor: MPSNNNeuronDescriptor)\nInstance Properties\nvar a: Float\nvar b: Float\nvar c: Float\nvar data: Data?\nvar neuronType: MPSCNNNeuronType\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSCNNNeuronSigmoid | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronsigmoid",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nTopics\nInitializers\ninit(device: MTLDevice)\nInitializes a sigmoid neuron filter.\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSMatrixSum | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixsum",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, count: Int, rows: Int, columns: Int, transpose: Bool)\nInstance Properties\nvar columns: Int\nvar count: Int\nvar neuronParameterA: Float\nvar neuronParameterB: Float\nvar neuronParameterC: Float\nvar resultMatrixOrigin: MTLOrigin\nvar rows: Int\nvar transpose: Bool\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceMatrices: [MPSMatrix], resultMatrix: MPSMatrix, scale: MPSVector?, offsetVector: MPSVector?, biasVector: MPSVector?, start: Int)\nfunc neuronType() -> MPSCNNNeuronType\nfunc setNeuronType(MPSCNNNeuronType, parameterA: Float, parameterB: Float, parameterC: Float)\nRelationships\nInherits From\nMPSKernel\nSee Also\nMatrix Arithmetic Operations\nclass MPSMatrixMultiplication\nA matrix multiplication kernel.\nclass MPSMatrixVectorMultiplication\nA matrix-vector multiplication kernel\nclass MPSMatrixFindTopK\nA kernel for computing the top-K values and their corresponding indices in a matrix."
  },
  {
    "title": "MPSMatrixVectorMultiplication | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixvectormultiplication",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, transpose: Bool, rows: Int, columns: Int, alpha: Double, beta: Double)\ninit(device: MTLDevice, rows: Int, columns: Int)\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, inputMatrix: MPSMatrix, inputVector: MPSVector, resultVector: MPSVector)\nRelationships\nInherits From\nMPSMatrixBinaryKernel\nSee Also\nMatrix Arithmetic Operations\nclass MPSMatrixSum\nA kernel for performing a pointwise summation of a matrix.\nclass MPSMatrixMultiplication\nA matrix multiplication kernel.\nclass MPSMatrixFindTopK\nA kernel for computing the top-K values and their corresponding indices in a matrix."
  },
  {
    "title": "MPSMatrixDecompositionStatus | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdecompositionstatus",
    "html": "Topics\nEnumeration Cases\ncase failure\nA status indicating the decomposition was not able to be completed.\ncase nonPositiveDefinite\nA status indicating a non-positive-definite pivot value was calculated.\ncase singular\nA status indicating the resulting decomposition is not suitable for use in a subsequent system solve.\ncase success\nA status indicating the decomposition was performed successfully.\nRelationships\nConforms To\nSendable\nSee Also\nClasses for Decomposition and Solving\nclass MPSMatrixDecompositionCholesky\nA kernel for computing the Cholesky factorization of a matrix.\nclass MPSMatrixSolveCholesky\nA kernel for computing the solution of a linear system of equations using a Cholesky factorization.\nclass MPSMatrixDecompositionLU\nA kernel for computing the LU factorization of a matrix using partial pivoting with row interchanges.\nclass MPSMatrixSolveLU\nA kernel for computing the solution of a linear system of equations using an LU factorization.\nclass MPSMatrixSolveTriangular\nA kernel for computing the solution of a linear system of equations using a triangular coefficient matrix.\nclass MPSMatrixUnaryKernel\nA kernel that consumes one matrix and produces one matrix.\nclass MPSMatrixBinaryKernel\nA kernel that consumes two matrices and produces one matrix."
  },
  {
    "title": "MPSNNDefaultPadding | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnndefaultpadding",
    "html": "Topics\nInitializers\ninit(method: MPSNNPaddingMethod)\nstruct MPSNNPaddingMethod\nOptions that define a graph's padding.\nInstance Methods\nfunc label() -> String\nType Methods\nclass func forTensorflowAveragePooling() -> Self\nclass func forTensorflowAveragePoolingValidOnly() -> Self\nRelationships\nInherits From\nNSObject\nConforms To\nMPSNNPadding"
  },
  {
    "title": "MPSMatrixBinaryKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixbinarykernel",
    "html": "Topics\nInstance Properties\nvar batchSize: Int\nvar batchStart: Int\nvar primarySourceMatrixOrigin: MTLOrigin\nvar resultMatrixOrigin: MTLOrigin\nvar secondarySourceMatrixOrigin: MTLOrigin\nRelationships\nInherits From\nMPSKernel\nSee Also\nClasses for Decomposition and Solving\nclass MPSMatrixDecompositionCholesky\nA kernel for computing the Cholesky factorization of a matrix.\nclass MPSMatrixSolveCholesky\nA kernel for computing the solution of a linear system of equations using a Cholesky factorization.\nclass MPSMatrixDecompositionLU\nA kernel for computing the LU factorization of a matrix using partial pivoting with row interchanges.\nclass MPSMatrixSolveLU\nA kernel for computing the solution of a linear system of equations using an LU factorization.\nclass MPSMatrixSolveTriangular\nA kernel for computing the solution of a linear system of equations using a triangular coefficient matrix.\nclass MPSMatrixUnaryKernel\nA kernel that consumes one matrix and produces one matrix.\nenum MPSMatrixDecompositionStatus"
  },
  {
    "title": "MPSMatrixUnaryKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixunarykernel",
    "html": "Topics\nInstance Properties\nvar batchSize: Int\nvar batchStart: Int\nvar resultMatrixOrigin: MTLOrigin\nvar sourceMatrixOrigin: MTLOrigin\nRelationships\nInherits From\nMPSKernel\nSee Also\nClasses for Decomposition and Solving\nclass MPSMatrixDecompositionCholesky\nA kernel for computing the Cholesky factorization of a matrix.\nclass MPSMatrixSolveCholesky\nA kernel for computing the solution of a linear system of equations using a Cholesky factorization.\nclass MPSMatrixDecompositionLU\nA kernel for computing the LU factorization of a matrix using partial pivoting with row interchanges.\nclass MPSMatrixSolveLU\nA kernel for computing the solution of a linear system of equations using an LU factorization.\nclass MPSMatrixSolveTriangular\nA kernel for computing the solution of a linear system of equations using a triangular coefficient matrix.\nclass MPSMatrixBinaryKernel\nA kernel that consumes two matrices and produces one matrix.\nenum MPSMatrixDecompositionStatus"
  },
  {
    "title": "MPSCNNGradientKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngradientkernel",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar kernelOffsetX: Int\nvar kernelOffsetY: Int\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceGradient: MPSImage, sourceImage: MPSImage, gradientState: MPSState) -> MPSImage\nfunc encode(commandBuffer: MTLCommandBuffer, sourceGradient: MPSImage, sourceImage: MPSImage, gradientState: MPSState, destinationGradient: MPSImage)\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceGradients: [MPSImage], sourceImages: [MPSImage], gradientStates: [MPSState]) -> [MPSImage]\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceGradients: [MPSImage], sourceImages: [MPSImage], gradientStates: [MPSState], destinationGradients: [MPSImage])\nRelationships\nInherits From\nMPSCNNBinaryKernel\nSee Also\nLayer Base Classes\nclass MPSCNNKernel\nBase class for neural network layers.\nclass MPSCNNBinaryKernel\nA convolution neural network kernel."
  },
  {
    "title": "MPSMatrixSolveTriangular | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixsolvetriangular",
    "html": "Overview\n\nThis kernel finds the solution matrix to the system op(A) * X = alpha * B or X * op(A) = alpha * B, where:\n\nA is either an upper or lower triangular matrix\n\nop(A) is either Aᵀ or A\n\nX is the resulting matrix of solutions\n\nB is the array of right hand sides for which the equations are to be solved\n\nTopics\nInitializers\ninit(device: MTLDevice, right: Bool, upper: Bool, transpose: Bool, unit: Bool, order: Int, numberOfRightHandSides: Int, alpha: Double)\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceMatrix: MPSMatrix, rightHandSideMatrix: MPSMatrix, solutionMatrix: MPSMatrix)\nRelationships\nInherits From\nMPSMatrixBinaryKernel\nSee Also\nClasses for Decomposition and Solving\nclass MPSMatrixDecompositionCholesky\nA kernel for computing the Cholesky factorization of a matrix.\nclass MPSMatrixSolveCholesky\nA kernel for computing the solution of a linear system of equations using a Cholesky factorization.\nclass MPSMatrixDecompositionLU\nA kernel for computing the LU factorization of a matrix using partial pivoting with row interchanges.\nclass MPSMatrixSolveLU\nA kernel for computing the solution of a linear system of equations using an LU factorization.\nclass MPSMatrixUnaryKernel\nA kernel that consumes one matrix and produces one matrix.\nclass MPSMatrixBinaryKernel\nA kernel that consumes two matrices and produces one matrix.\nenum MPSMatrixDecompositionStatus"
  },
  {
    "title": "MPSMatrixSolveLU | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixsolvelu",
    "html": "Overview\n\nThis kernel finds the solution matrix to the system op(A) * X = B, where:\n\nop(A) is Aᵀ or A\n\nX is the resulting matrix of solutions\n\nB is the array of right hand sides for which the equations are to be solved\n\nTopics\nInitializers\ninit(device: MTLDevice, transpose: Bool, order: Int, numberOfRightHandSides: Int)\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceMatrix: MPSMatrix, rightHandSideMatrix: MPSMatrix, pivotIndices: MPSMatrix, solutionMatrix: MPSMatrix)\nRelationships\nInherits From\nMPSMatrixBinaryKernel\nSee Also\nClasses for Decomposition and Solving\nclass MPSMatrixDecompositionCholesky\nA kernel for computing the Cholesky factorization of a matrix.\nclass MPSMatrixSolveCholesky\nA kernel for computing the solution of a linear system of equations using a Cholesky factorization.\nclass MPSMatrixDecompositionLU\nA kernel for computing the LU factorization of a matrix using partial pivoting with row interchanges.\nclass MPSMatrixSolveTriangular\nA kernel for computing the solution of a linear system of equations using a triangular coefficient matrix.\nclass MPSMatrixUnaryKernel\nA kernel that consumes one matrix and produces one matrix.\nclass MPSMatrixBinaryKernel\nA kernel that consumes two matrices and produces one matrix.\nenum MPSMatrixDecompositionStatus"
  },
  {
    "title": "MPSMatrixDecompositionLU | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdecompositionlu",
    "html": "Overview\n\nThis kernel object computes an LU factorization, PA = LU, where:\n\nA is a matrix for which the LU factorization is to be computed\n\nL is a unit lower triangular matrix\n\nU is an upper triangular matrix\n\nP is a permutation matrix\n\nTopics\nInitializers\ninit(device: MTLDevice, rows: Int, columns: Int)\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceMatrix: MPSMatrix, resultMatrix: MPSMatrix, pivotIndices: MPSMatrix, info: MTLBuffer?)\nRelationships\nInherits From\nMPSMatrixUnaryKernel\nSee Also\nClasses for Decomposition and Solving\nclass MPSMatrixDecompositionCholesky\nA kernel for computing the Cholesky factorization of a matrix.\nclass MPSMatrixSolveCholesky\nA kernel for computing the solution of a linear system of equations using a Cholesky factorization.\nclass MPSMatrixSolveLU\nA kernel for computing the solution of a linear system of equations using an LU factorization.\nclass MPSMatrixSolveTriangular\nA kernel for computing the solution of a linear system of equations using a triangular coefficient matrix.\nclass MPSMatrixUnaryKernel\nA kernel that consumes one matrix and produces one matrix.\nclass MPSMatrixBinaryKernel\nA kernel that consumes two matrices and produces one matrix.\nenum MPSMatrixDecompositionStatus"
  },
  {
    "title": "MPSMatrixSolveCholesky | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixsolvecholesky",
    "html": "Overview\n\nThis kernel finds the solution matrix to the system AX=B, where:\n\nA is a symmetric positive-definite matrix\n\nX is the resulting matrix of solutions\n\nB is the array of right-hand-sides for which the equations are to be solved\n\nTopics\nInitializers\ninit(device: MTLDevice, upper: Bool, order: Int, numberOfRightHandSides: Int)\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceMatrix: MPSMatrix, rightHandSideMatrix: MPSMatrix, solutionMatrix: MPSMatrix)\nRelationships\nInherits From\nMPSMatrixBinaryKernel\nSee Also\nClasses for Decomposition and Solving\nclass MPSMatrixDecompositionCholesky\nA kernel for computing the Cholesky factorization of a matrix.\nclass MPSMatrixDecompositionLU\nA kernel for computing the LU factorization of a matrix using partial pivoting with row interchanges.\nclass MPSMatrixSolveLU\nA kernel for computing the solution of a linear system of equations using an LU factorization.\nclass MPSMatrixSolveTriangular\nA kernel for computing the solution of a linear system of equations using a triangular coefficient matrix.\nclass MPSMatrixUnaryKernel\nA kernel that consumes one matrix and produces one matrix.\nclass MPSMatrixBinaryKernel\nA kernel that consumes two matrices and produces one matrix.\nenum MPSMatrixDecompositionStatus"
  },
  {
    "title": "MPSMatrixDecompositionCholesky | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdecompositioncholesky",
    "html": "Overview\n\nThis kernel computes one of the following factorizations of a matrix A:\n\nA = LLᵀ\n\nA = UᵀU\n\nwhere:\n\nA is a symmetric positive-definite matrix for which the factorization is to be computed\n\nL is the lower triangular matrix\n\nU is the upper triangular matrix\n\nTopics\nInitializers\ninit(device: MTLDevice, lower: Bool, order: Int)\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceMatrix: MPSMatrix, resultMatrix: MPSMatrix, status: MTLBuffer?)\nRelationships\nInherits From\nMPSMatrixUnaryKernel\nSee Also\nClasses for Decomposition and Solving\nclass MPSMatrixSolveCholesky\nA kernel for computing the solution of a linear system of equations using a Cholesky factorization.\nclass MPSMatrixDecompositionLU\nA kernel for computing the LU factorization of a matrix using partial pivoting with row interchanges.\nclass MPSMatrixSolveLU\nA kernel for computing the solution of a linear system of equations using an LU factorization.\nclass MPSMatrixSolveTriangular\nA kernel for computing the solution of a linear system of equations using a triangular coefficient matrix.\nclass MPSMatrixUnaryKernel\nA kernel that consumes one matrix and produces one matrix.\nclass MPSMatrixBinaryKernel\nA kernel that consumes two matrices and produces one matrix.\nenum MPSMatrixDecompositionStatus"
  },
  {
    "title": "MPSMatrix | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrix",
    "html": "Overview\n\nMPSMatrix objects serve as inputs and outputs of MPSMatrixMultiplication objects. Matrix data is assumed to be stored in row-major order.\n\nNote\n\nAn MPSMatrix object maintains its internal storage using a MTLBuffer object. Thus, the same rules for maintaining coherency of the buffer’s data between CPU memory and GPU memory also apply to an MPSMatrix object.\n\nTopics\nMethods\ninit(buffer: MTLBuffer, descriptor: MPSMatrixDescriptor)\nInitializes a matrix with a buffer.\nProperties\nvar device: MTLDevice\nThe device on which the matrix will be used.\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar data: MTLBuffer\nThe buffer that stores the matrix data.\nvar matrices: Int\nvar matrixBytes: Int\nInitializers\ninit(buffer: MTLBuffer, offset: Int, descriptor: MPSMatrixDescriptor)\ninit(device: MTLDevice, descriptor: MPSMatrixDescriptor)\nInstance Properties\nvar offset: Int\nInstance Methods\nfunc resourceSize() -> Int\nfunc synchronize(on: MTLCommandBuffer)\nRelationships\nInherits From\nNSObject\nSee Also\nMatrices\nclass MPSMatrixDescriptor\nA description of attributes used to create an MPS matrix.\nclass MPSTemporaryMatrix\nA matrix allocated on GPU private memory."
  },
  {
    "title": "MPSTemporaryMatrix | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporarymatrix",
    "html": "Topics\nInitializers\ninit(commandBuffer: MTLCommandBuffer, matrixDescriptor: MPSMatrixDescriptor)\nInstance Properties\nvar readCount: Int\nType Methods\nclass func prefetchStorage(with: MTLCommandBuffer, matrixDescriptorList: [MPSMatrixDescriptor])\nRelationships\nInherits From\nMPSMatrix\nSee Also\nMatrices\nclass MPSMatrix\nA 2D array of data that stores the data's values.\nclass MPSMatrixDescriptor\nA description of attributes used to create an MPS matrix."
  },
  {
    "title": "MPSVectorDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsvectordescriptor",
    "html": "Topics\nInitializers\ninit(length: Int, dataType: MPSDataType)\ninit(length: Int, vectors: Int, vectorBytes: Int, dataType: MPSDataType)\nInstance Properties\nvar dataType: MPSDataType\nvar length: Int\nvar vectorBytes: Int\nvar vectors: Int\nType Methods\nclass func vectorBytes(forLength: Int, dataType: MPSDataType) -> Int\nRelationships\nInherits From\nNSObject\nSee Also\nVectors\nclass MPSVector\nA 1D array of data that stores the data's values.\nclass MPSTemporaryVector\nA vector allocated on GPU private memory."
  },
  {
    "title": "MPSVector | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsvector",
    "html": "Topics\nInitializers\ninit(buffer: MTLBuffer, descriptor: MPSVectorDescriptor)\ninit(buffer: MTLBuffer, offset: Int, descriptor: MPSVectorDescriptor)\ninit(device: MTLDevice, descriptor: MPSVectorDescriptor)\nInstance Properties\nvar data: MTLBuffer\nvar dataType: MPSDataType\nvar device: MTLDevice\nvar length: Int\nvar vectorBytes: Int\nvar vectors: Int\nvar offset: Int\nInstance Methods\nfunc resourceSize() -> Int\nfunc synchronize(on: MTLCommandBuffer)\nRelationships\nInherits From\nNSObject\nSee Also\nVectors\nclass MPSVectorDescriptor\nA description of the length and data type of a vector.\nclass MPSTemporaryVector\nA vector allocated on GPU private memory."
  },
  {
    "title": "MPSNNOptimizerDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnoptimizerdescriptor",
    "html": "Topics\nInitializers\ninit(learningRate: Float, gradientRescale: Float, applyGradientClipping: Bool, gradientClipMax: Float, gradientClipMin: Float, regularizationType: MPSNNRegularizationType, regularizationScale: Float)\ninit(learningRate: Float, gradientRescale: Float, regularizationType: MPSNNRegularizationType, regularizationScale: Float)\nInstance Properties\nvar applyGradientClipping: Bool\nvar gradientClipMax: Float\nvar gradientClipMin: Float\nvar gradientRescale: Float\nvar learningRate: Float\nvar regularizationScale: Float\nvar regularizationType: MPSNNRegularizationType\nRelationships\nInherits From\nNSObject\nSee Also\nOptimization Layers\nclass MPSNNOptimizerAdam\nAn optimization layer that performs an Adam pdate.\nclass MPSNNOptimizerRMSProp\nAn optimization layer that performs a root mean square propagation update.\nclass MPSNNOptimizerStochasticGradientDescent\nAn optimization layer that performs a gradient descent with an optional momentum update.\nclass MPSNNOptimizer\nThe base class for optimization layers."
  },
  {
    "title": "MPSNNOptimizerStochasticGradientDescent | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnoptimizerstochasticgradientdescent",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, learningRate: Float)\ninit(device: MTLDevice, momentumScale: Float, useNesterovMomentum: Bool, optimizerDescriptor: MPSNNOptimizerDescriptor)\ninit(device: MTLDevice, momentumScale: Float, useNestrovMomentum: Bool, optimizerDescriptor: MPSNNOptimizerDescriptor)\nInstance Properties\nvar momentumScale: Float\nvar useNesterovMomentum: Bool\nvar useNestrovMomentum: Bool\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, batchNormalizationGradientState: MPSCNNBatchNormalizationState, batchNormalizationSourceState: MPSCNNBatchNormalizationState, inputMomentumVectors: [MPSVector]?, resultState: MPSCNNNormalizationGammaAndBetaState)\nfunc encode(commandBuffer: MTLCommandBuffer, batchNormalizationState: MPSCNNBatchNormalizationState, inputMomentumVectors: [MPSVector]?, resultState: MPSCNNNormalizationGammaAndBetaState)\nfunc encode(commandBuffer: MTLCommandBuffer, convolutionGradientState: MPSCNNConvolutionGradientState, convolutionSourceState: MPSCNNConvolutionWeightsAndBiasesState, inputMomentumVectors: [MPSVector]?, resultState: MPSCNNConvolutionWeightsAndBiasesState)\nfunc encode(commandBuffer: MTLCommandBuffer, inputGradientMatrix: MPSMatrix, inputValuesMatrix: MPSMatrix, inputMomentumMatrix: MPSMatrix?, resultValuesMatrix: MPSMatrix)\nfunc encode(commandBuffer: MTLCommandBuffer, inputGradientVector: MPSVector, inputValuesVector: MPSVector, inputMomentumVector: MPSVector?, resultValuesVector: MPSVector)\nRelationships\nInherits From\nMPSNNOptimizer\nSee Also\nOptimization Layers\nclass MPSNNOptimizerAdam\nAn optimization layer that performs an Adam pdate.\nclass MPSNNOptimizerRMSProp\nAn optimization layer that performs a root mean square propagation update.\nclass MPSNNOptimizer\nThe base class for optimization layers.\nclass MPSNNOptimizerDescriptor\nAn object that specifies properties used by an optimizer kernel."
  },
  {
    "title": "MPSNNReduceFeatureChannelsMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducefeaturechannelsmax",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNSlice | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnslice",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNKernel"
  },
  {
    "title": "MPSNNReduceFeatureChannelsArgumentMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducefeaturechannelsargumentmax",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceBinary | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducebinary",
    "html": "Topics\nInstance Properties\nvar primaryOffset: MPSOffset\nDeprecated\nvar primarySourceClipRect: MTLRegion\nvar secondaryOffset: MPSOffset\nDeprecated\nvar secondarySourceClipRect: MTLRegion\nRelationships\nInherits From\nMPSCNNBinaryKernel\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters."
  },
  {
    "title": "MPSCNNYOLOLossDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnyololossdescriptor",
    "html": "Topics\nInstance Properties\nvar anchorBoxes: Data\nvar classesLossDescriptor: MPSCNNLossDescriptor\nvar confidenceLossDescriptor: MPSCNNLossDescriptor\nvar maxIOUForObjectAbsence: Float\nvar minIOUForObjectPresence: Float\nvar numberOfAnchorBoxes: Int\nvar reduceAcrossBatch: Bool\nvar reductionType: MPSCNNReductionType\nvar rescore: Bool\nvar scaleClass: Float\nvar scaleNoObject: Float\nvar scaleObject: Float\nvar scaleWH: Float\nvar scaleXY: Float\nvar whLossDescriptor: MPSCNNLossDescriptor\nvar xyLossDescriptor: MPSCNNLossDescriptor\nType Methods\nclass func cnnLossDescriptor(withXYLossType: MPSCNNLossType, whLossType: MPSCNNLossType, confidenceLossType: MPSCNNLossType, classesLossType: MPSCNNLossType, reductionType: MPSCNNReductionType, anchorBoxes: Data, numberOfAnchorBoxes: Int) -> MPSCNNYOLOLossDescriptor\nRelationships\nInherits From\nNSObject\nConforms To\nNSCopying\nSee Also\nLoss Layers\nclass MPSCNNLoss\nA kernel that computes the loss and loss gradient between specified predictions and labels.\nclass MPSCNNLossDataDescriptor\nAn object that specifies properties used by a loss data descriptor.\nclass MPSCNNLossDescriptor\nAn object that specifies properties used by a loss kernel.\nclass MPSCNNLossLabels\nA class that stores the per-element weight buffer used by loss and gradient loss kernels.\nclass MPSCNNYOLOLoss\nA kernel that computes the YOLO loss and loss gradient between specified predictions and labels."
  },
  {
    "title": "MPSNNReduceColumnMean | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducecolumnmean",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSCNNYOLOLoss | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnyololoss",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, lossDescriptor: MPSCNNYOLOLossDescriptor)\nInstance Properties\nvar anchorBoxes: Data\nvar lossClasses: MPSCNNLoss\nvar lossConfidence: MPSCNNLoss\nvar lossWH: MPSCNNLoss\nvar lossXY: MPSCNNLoss\nvar maxIOUForObjectAbsence: Float\nvar minIOUForObjectPresence: Float\nvar numberOfAnchorBoxes: Int\nvar reduceAcrossBatch: Bool\nvar reductionType: MPSCNNReductionType\nvar scaleClass: Float\nvar scaleNoObject: Float\nvar scaleObject: Float\nvar scaleWH: Float\nvar scaleXY: Float\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, labels: MPSCNNLossLabels) -> MPSImage\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, labels: MPSCNNLossLabels, destinationImage: MPSImage)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], labels: [MPSCNNLossLabels]) -> [MPSImage]\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], labels: [MPSCNNLossLabels], destinationImages: [MPSImage])\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nLoss Layers\nclass MPSCNNLoss\nA kernel that computes the loss and loss gradient between specified predictions and labels.\nclass MPSCNNLossDataDescriptor\nAn object that specifies properties used by a loss data descriptor.\nclass MPSCNNLossDescriptor\nAn object that specifies properties used by a loss kernel.\nclass MPSCNNLossLabels\nA class that stores the per-element weight buffer used by loss and gradient loss kernels.\nclass MPSCNNYOLOLossDescriptor\nAn object that specifies properties used by a YOLO loss kernel."
  },
  {
    "title": "MPSNNReduceFeatureChannelsAndWeightsSum | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducefeaturechannelsandweightssum",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\ninit(device: MTLDevice, doWeightedSumByNonZeroWeights: Bool)\nInstance Properties\nvar doWeightedSumByNonZeroWeights: Bool\nRelationships\nInherits From\nMPSNNReduceBinary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceFeatureChannelsSum | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducefeaturechannelssum",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar weight: Float\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceFeatureChannelsArgumentMin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducefeaturechannelsargumentmin",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceRowMin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducerowmin",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceColumnSum | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducecolumnsum",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceColumnMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducecolumnmax",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceRowMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducerowmax",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceUnary | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreduceunary",
    "html": "Topics\nInstance Properties\nvar clipRectSource: MTLRegion\nvar offset: MPSOffset\nDeprecated\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSMatrixBatchNormalization | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixbatchnormalization",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar computeStatistics: Bool\nvar epsilon: Float\nvar sourceInputFeatureChannels: Int\nvar sourceNumberOfFeatureVectors: Int\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(commandBuffer: MTLCommandBuffer, inputMatrix: MPSMatrix, meanVector: MPSVector, varianceVector: MPSVector, gammaVector: MPSVector?, betaVector: MPSVector?, resultMatrix: MPSMatrix)\nfunc neuronParameterA() -> Float\nfunc neuronParameterB() -> Float\nfunc neuronParameterC() -> Float\nfunc neuronType() -> MPSCNNNeuronType\nfunc setNeuronType(MPSCNNNeuronType, parameterA: Float, parameterB: Float, parameterC: Float)\nRelationships\nInherits From\nMPSMatrixUnaryKernel\nSee Also\nMatrix Normalization Operations\nclass MPSMatrixBatchNormalizationGradient\nA batch normalization gradient kernel that operates on matrices."
  },
  {
    "title": "MPSRNNMatrixTrainingLayer | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnmatrixtraininglayer",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, rnnDescriptor: MPSRNNDescriptor, trainableWeights: NSMutableArray)\nInstance Properties\nvar accumulateWeightGradients: Bool\nvar inputFeatureChannels: Int\nvar outputFeatureChannels: Int\nvar recurrentOutputIsTemporary: Bool\nvar storeAllIntermediateStates: Bool\nvar trainingStateIsTemporary: Bool\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc createTemporaryWeightGradientMatrices(NSMutableArray, dataType: MPSDataType, commandBuffer: MTLCommandBuffer)\nfunc createWeightGradientMatrices(NSMutableArray, dataType: MPSDataType)\nfunc createWeightMatrices(NSMutableArray)\nfunc encodeCopyWeights(commandBuffer: MTLCommandBuffer, weights: [MPSMatrix], matrixId: MPSRNNMatrixId, matrix: MPSMatrix, copyFromWeightsToMatrix: Bool, matrixOffset: MTLOrigin)\nfunc encodeForwardSequence(commandBuffer: MTLCommandBuffer, sourceMatrices: [MPSMatrix], destinationMatrices: [MPSMatrix], trainingStates: NSMutableArray, weights: [MPSMatrix])\nfunc encodeForwardSequence(commandBuffer: MTLCommandBuffer, sourceMatrices: [MPSMatrix], sourceOffsets: UnsafeMutablePointer<Int>?, destinationMatrices: [MPSMatrix], destinationOffsets: UnsafeMutablePointer<Int>?, trainingStates: NSMutableArray, recurrentInputState: MPSRNNRecurrentMatrixState?, recurrentOutputStates: NSMutableArray?, weights: [MPSMatrix])\nfunc encodeGradientSequence(commandBuffer: MTLCommandBuffer, forwardSources: [MPSMatrix], forwardSourceOffsets: UnsafeMutablePointer<Int>?, sourceGradients: [MPSMatrix], sourceOffsets: UnsafeMutablePointer<Int>?, destinationGradients: [MPSMatrix]?, destinationOffsets: UnsafeMutablePointer<Int>?, weightGradients: [MPSMatrix]?, trainingStates: [MPSRNNMatrixTrainingState], recurrentInputState: MPSRNNRecurrentMatrixState?, recurrentOutputStates: NSMutableArray?, weights: [MPSMatrix])\nfunc encodeGradientSequence(commandBuffer: MTLCommandBuffer, forwardSources: [MPSMatrix], sourceGradients: [MPSMatrix], destinationGradients: [MPSMatrix]?, weightGradients: [MPSMatrix]?, trainingStates: [MPSRNNMatrixTrainingState], weights: [MPSMatrix])\nRelationships\nInherits From\nMPSKernel\nSee Also\nRecurrent Neural Networks\nclass MPSRNNImageInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders images.\nclass MPSRNNMatrixInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders matrices.\nclass MPSRNNSingleGateDescriptor\nA description of a simple recurrent block or layer.\nclass MPSGRUDescriptor\nA description of a gated recurrent unit block or layer.\nclass MPSLSTMDescriptor\nA description of a long short-term memory block or layer.\nenum MPSRNNSequenceDirection\nDirections that a sequence of inputs can be processed by a recurrent neural network layer.\nclass MPSRNNMatrixTrainingState\nA class that holds data from a forward pass to be used in a backward pass."
  },
  {
    "title": "MPSCNNNeuronHardSigmoid | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronhardsigmoid",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nTopics\nInitializers\ninit(device: MTLDevice, a: Float, b: Float)\nInitializes a hard sigmoid neuron filter.\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSRNNMatrixTrainingState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrnnmatrixtrainingstate",
    "html": "Relationships\nInherits From\nMPSState\nSee Also\nRecurrent Neural Networks\nclass MPSRNNImageInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders images.\nclass MPSRNNMatrixInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders matrices.\nclass MPSRNNSingleGateDescriptor\nA description of a simple recurrent block or layer.\nclass MPSGRUDescriptor\nA description of a gated recurrent unit block or layer.\nclass MPSLSTMDescriptor\nA description of a long short-term memory block or layer.\nenum MPSRNNSequenceDirection\nDirections that a sequence of inputs can be processed by a recurrent neural network layer.\nclass MPSRNNMatrixTrainingLayer\nA layer for training recurrent neural networks on Metal Performance Shaders matrices."
  },
  {
    "title": "MPSImageReduceRowMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereducerowmax",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageReduceUnary\nSee Also\nImage Reduction Filters\nclass MPSImageReduceRowMin\nA filter that returns the minimum value for each row in an image.\nclass MPSImageReduceRowSum\nA filter that returns the sum of all values for a row in an image.\nclass MPSImageReduceRowMean\nA filter that returns the mean value for each row in an image.\nclass MPSImageReduceColumnMax\nA filter that returns the maximum value for each column in an image.\nclass MPSImageReduceColumnMin\nA filter that returns the minimum value for each column in an image.\nclass MPSImageReduceColumnSum\nA filter that returns the sum of all values for a column in an image.\nclass MPSImageReduceColumnMean\nA filter that returns the mean value for each column in an image.\nclass MPSImageReduceUnary\nThe base class for reduction filters that take a single source as input."
  },
  {
    "title": "MPSImageReduceRowSum | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereducerowsum",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageReduceUnary\nSee Also\nImage Reduction Filters\nclass MPSImageReduceRowMax\nA filter that returns the maximum value for each row in an image.\nclass MPSImageReduceRowMin\nA filter that returns the minimum value for each row in an image.\nclass MPSImageReduceRowMean\nA filter that returns the mean value for each row in an image.\nclass MPSImageReduceColumnMax\nA filter that returns the maximum value for each column in an image.\nclass MPSImageReduceColumnMin\nA filter that returns the minimum value for each column in an image.\nclass MPSImageReduceColumnSum\nA filter that returns the sum of all values for a column in an image.\nclass MPSImageReduceColumnMean\nA filter that returns the mean value for each column in an image.\nclass MPSImageReduceUnary\nThe base class for reduction filters that take a single source as input."
  },
  {
    "title": "MPSImageStatisticsMeanAndVariance | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagestatisticsmeanandvariance",
    "html": "Overview\n\nThe mean and variance values are written to the destination image at the following pixel locations:\n\nMean value is written at pixel location (0, 0)\n\nVariance value is written at pixel location (1, 0)\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar clipRectSource: MTLRegion\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Statistics Filters\nclass MPSImageStatisticsMean\nA kernel that computes the mean for a given region of an image.\nclass MPSImageStatisticsMinAndMax\nA kernel that computes the minimum and maximum pixel values for a given region of an image."
  },
  {
    "title": "MPSCNNArithmetic | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnarithmetic",
    "html": "Topics\nInstance Properties\nvar bias: Float\nvar maximumValue: Float\nvar minimumValue: Float\nvar primaryScale: Float\nvar primaryStrideInFeatureChannels: Int\nvar secondaryScale: Float\nvar secondaryStrideInFeatureChannels: Int\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, destinationState: MPSCNNArithmeticGradientState, destinationImage: MPSImage)\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, primaryImages: [MPSImage], secondaryImages: [MPSImage], destinationStates: [MPSCNNArithmeticGradientState], destinationImages: [MPSImage])\nRelationships\nInherits From\nMPSCNNBinaryKernel\nSee Also\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSCNNDropout | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndropout",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, keepProbability: Float, seed: Int, maskStrideInPixels: MTLSize)\nInstance Properties\nvar keepProbability: Float\nvar maskStrideInPixels: MTLSize\nvar seed: Int\nInstance Methods\nfunc resultState(sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNDropoutGradientState?\nfunc resultStateBatch(sourceImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> MPSCNNDropoutGradientState?\nfunc temporaryResultState(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNDropoutGradientState?\nfunc temporaryResultStateBatch(commandBuffer: MTLCommandBuffer, sourceImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> [MPSCNNDropoutGradientState]?\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nDropout Layers\nclass MPSCNNDropoutGradient\nA gradient dropout filter.\nclass MPSCNNDropoutGradientState\nA class that stores the mask used by dropout and gradient dropout filters."
  },
  {
    "title": "MPSCNNUpsamplingGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsamplinggradient",
    "html": "Topics\nInstance Properties\nvar scaleFactorX: Double\nvar scaleFactorY: Double\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nUpsampling Layers\nclass MPSCNNUpsampling\nA filter that resamples an existing MPS image.\nclass MPSCNNUpsamplingBilinear\nA bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearest\nA nearest spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradient\nA gradient bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearestGradient\nA gradient upsampling filter that samples the pixel nearest to the source when upsampling to the destination pixel."
  },
  {
    "title": "MPSCNNLoss | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnloss",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, lossDescriptor: MPSCNNLossDescriptor)\nInstance Properties\nvar delta: Float\nvar epsilon: Float\nvar labelSmoothing: Float\nvar lossType: MPSCNNLossType\nvar numberOfClasses: Int\nvar reduceAcrossBatch: Bool\nvar reductionType: MPSCNNReductionType\nvar weight: Float\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, labels: MPSCNNLossLabels) -> MPSImage\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, labels: MPSCNNLossLabels, destinationImage: MPSImage)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], labels: [MPSCNNLossLabels]) -> [MPSImage]\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], labels: [MPSCNNLossLabels], destinationImages: [MPSImage])\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nLoss Layers\nclass MPSCNNLossDataDescriptor\nAn object that specifies properties used by a loss data descriptor.\nclass MPSCNNLossDescriptor\nAn object that specifies properties used by a loss kernel.\nclass MPSCNNLossLabels\nA class that stores the per-element weight buffer used by loss and gradient loss kernels.\nclass MPSCNNYOLOLoss\nA kernel that computes the YOLO loss and loss gradient between specified predictions and labels.\nclass MPSCNNYOLOLossDescriptor\nAn object that specifies properties used by a YOLO loss kernel."
  },
  {
    "title": "MPSImageGuidedFilter | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageguidedfilter",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, kernelDiameter: Int)\nInstance Properties\nvar epsilon: Float\nvar kernelDiameter: Int\nvar reconstructOffset: Float\nvar reconstructScale: Float\nInstance Methods\nfunc encodeReconstruction(commandBuffer: MTLCommandBuffer, guidance: MTLTexture, coefficientsA: MTLTexture, coefficientsB: MTLTexture, destination: MTLTexture)\nfunc encodeReconstruction(to: MTLCommandBuffer, guidanceTexture: MTLTexture, coefficientsTexture: MTLTexture, destinationTexture: MTLTexture)\nfunc encodeRegression(commandBuffer: MTLCommandBuffer, source: MTLTexture, guidance: MTLTexture, weights: MTLTexture?, destinationCoefficientsA: MTLTexture, destinationCoefficientsB: MTLTexture)\nfunc encodeRegression(to: MTLCommandBuffer, sourceTexture: MTLTexture, guidanceTexture: MTLTexture, weightsTexture: MTLTexture?, destinationCoefficientsTexture: MTLTexture)\nRelationships\nInherits From\nMPSKernel"
  },
  {
    "title": "MPSCNNLossDataDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlossdatadescriptor",
    "html": "Topics\nInitializers\ninit?(data: Data, layout: MPSDataLayout, size: MTLSize)\nInstance Properties\nvar bytesPerImage: Int\nvar bytesPerRow: Int\nvar layout: MPSDataLayout\nvar size: MTLSize\nRelationships\nInherits From\nNSObject\nConforms To\nNSCopying\nSee Also\nLoss Layers\nclass MPSCNNLoss\nA kernel that computes the loss and loss gradient between specified predictions and labels.\nclass MPSCNNLossDescriptor\nAn object that specifies properties used by a loss kernel.\nclass MPSCNNLossLabels\nA class that stores the per-element weight buffer used by loss and gradient loss kernels.\nclass MPSCNNYOLOLoss\nA kernel that computes the YOLO loss and loss gradient between specified predictions and labels.\nclass MPSCNNYOLOLossDescriptor\nAn object that specifies properties used by a YOLO loss kernel."
  },
  {
    "title": "MPSCNNDropoutGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndropoutgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, keepProbability: Float, seed: Int, maskStrideInPixels: MTLSize)\nInstance Properties\nvar keepProbability: Float\nvar maskStrideInPixels: MTLSize\nvar seed: Int\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nDropout Layers\nclass MPSCNNDropout\nA dropout filter.\nclass MPSCNNDropoutGradientState\nA class that stores the mask used by dropout and gradient dropout filters."
  },
  {
    "title": "MPSCNNDropoutGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndropoutgradientstate",
    "html": "Topics\nInstance Methods\nfunc maskData() -> Data\nRelationships\nInherits From\nMPSNNGradientState\nSee Also\nDropout Layers\nclass MPSCNNDropout\nA dropout filter.\nclass MPSCNNDropoutGradient\nA gradient dropout filter."
  },
  {
    "title": "MPSCNNNormalizationGammaAndBetaState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnnormalizationgammaandbetastate",
    "html": "Topics\nInitializers\ninit(gamma: MTLBuffer, beta: MTLBuffer)\nInstance Properties\nvar beta: MTLBuffer\nvar gamma: MTLBuffer\nType Methods\nclass func temporaryState(with: MTLCommandBuffer, numberOfFeatureChannels: Int) -> Self\nRelationships\nInherits From\nMPSState\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization."
  },
  {
    "title": "MPSCNNUpsamplingNearestGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsamplingnearestgradient",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, integerScaleFactorX: Int, integerScaleFactorY: Int)\nRelationships\nInherits From\nMPSCNNUpsamplingGradient\nSee Also\nUpsampling Layers\nclass MPSCNNUpsampling\nA filter that resamples an existing MPS image.\nclass MPSCNNUpsamplingBilinear\nA bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearest\nA nearest spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradient\nA gradient bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingGradient\nA gradient filter that upsamples an existing Metal Performance Shaders image."
  },
  {
    "title": "MPSCNNUpsamplingNearest | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsamplingnearest",
    "html": "Overview\n\nThis filter can be used to resample an existing MPSImage using a different sampling frequency for the x and y dimensions with the purpose of enlarging the size of an image.\n\nThe number of output feature channels remains the same as the number of input feature channels.\n\nThe scaleFactor must be an integer value >= 1. The default value is 1.\n\nTopics\nInitializers\ninit(device: MTLDevice, integerScaleFactorX: Int, integerScaleFactorY: Int)\nInitializes a nearest spatial upsampling filter.\nRelationships\nInherits From\nMPSCNNUpsampling\nSee Also\nUpsampling Layers\nclass MPSCNNUpsampling\nA filter that resamples an existing MPS image.\nclass MPSCNNUpsamplingBilinear\nA bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradient\nA gradient bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingGradient\nA gradient filter that upsamples an existing Metal Performance Shaders image.\nclass MPSCNNUpsamplingNearestGradient\nA gradient upsampling filter that samples the pixel nearest to the source when upsampling to the destination pixel."
  },
  {
    "title": "MPSCNNUpsamplingBilinearGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsamplingbilineargradient",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, integerScaleFactorX: Int, integerScaleFactorY: Int)\nRelationships\nInherits From\nMPSCNNUpsamplingGradient\nSee Also\nUpsampling Layers\nclass MPSCNNUpsampling\nA filter that resamples an existing MPS image.\nclass MPSCNNUpsamplingBilinear\nA bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearest\nA nearest spatial upsampling filter.\nclass MPSCNNUpsamplingGradient\nA gradient filter that upsamples an existing Metal Performance Shaders image.\nclass MPSCNNUpsamplingNearestGradient\nA gradient upsampling filter that samples the pixel nearest to the source when upsampling to the destination pixel."
  },
  {
    "title": "MPSCNNUpsamplingBilinear | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsamplingbilinear",
    "html": "Overview\n\nThis filter can be used to resample an existing MPSImage using a different sampling frequency for the x and y dimensions with the purpose of enlarging the size of an image.\n\nThe number of output feature channels remains the same as the number of input feature channels.\n\nThe scaleFactor must be an integer value >= 1. The default value is 1.\n\nTopics\nInitializers\ninit(device: MTLDevice, integerScaleFactorX: Int, integerScaleFactorY: Int)\nInitializes a bilinear spatial upsampling filter.\ninit(device: MTLDevice, integerScaleFactorX: Int, integerScaleFactorY: Int, alignCorners: Bool)\nRelationships\nInherits From\nMPSCNNUpsampling\nSee Also\nUpsampling Layers\nclass MPSCNNUpsampling\nA filter that resamples an existing MPS image.\nclass MPSCNNUpsamplingNearest\nA nearest spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradient\nA gradient bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingGradient\nA gradient filter that upsamples an existing Metal Performance Shaders image.\nclass MPSCNNUpsamplingNearestGradient\nA gradient upsampling filter that samples the pixel nearest to the source when upsampling to the destination pixel."
  },
  {
    "title": "MPSCNNUpsampling | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsampling",
    "html": "Overview\n\nThis filter can be used to resample an existing MPSImage using a different sampling frequency for the x and y dimensions with the purpose of enlarging the size of an image.\n\nThe number of output feature channels remains the same as the number of input feature channels.\n\nThe scaleFactor must be an integer value >= 1. The default value is 1.\n\nNearest and bilinear variants are supported.\n\nTopics\nInstance Properties\nvar scaleFactorX: Double\nvar scaleFactorY: Double\nvar alignCorners: Bool\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nUpsampling Layers\nclass MPSCNNUpsamplingBilinear\nA bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearest\nA nearest spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradient\nA gradient bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingGradient\nA gradient filter that upsamples an existing Metal Performance Shaders image.\nclass MPSCNNUpsamplingNearestGradient\nA gradient upsampling filter that samples the pixel nearest to the source when upsampling to the destination pixel."
  },
  {
    "title": "MPSCNNInstanceNormalization | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalization",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, dataSource: MPSCNNInstanceNormalizationDataSource)\nInstance Properties\nvar dataSource: MPSCNNInstanceNormalizationDataSource\nvar epsilon: Float\nInstance Methods\nfunc reloadDataSource(MPSCNNInstanceNormalizationDataSource)\nDeprecated\nfunc reloadGammaAndBeta(with: MTLCommandBuffer, gammaAndBetaState: MPSCNNNormalizationGammaAndBetaState)\nfunc reloadGammaAndBetaFromDataSource()\nfunc resultState(sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNInstanceNormalizationGradientState?\nfunc temporaryResultState(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNInstanceNormalizationGradientState?\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNNeuronExponential | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronexponential",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, a: Float, b: Float, c: Float)\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSCNNNeuronSoftSign | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronsoftsign",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nTopics\nInitializers\ninit(device: MTLDevice)\nInitializes a softsign neuron filter.\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSCNNNeuronSoftPlus | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronsoftplus",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nTopics\nInitializers\ninit(device: MTLDevice, a: Float, b: Float)\nInitializes a parametric softplus neuron filter.\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSCNNNeuronReLU | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronrelu",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nThis filter is called leaky ReLU in CNN literature. Some CNN literature defines classical ReLU as max(0, x). If you want this behavior, simply set the a property to 0.\n\nTopics\nInitializers\ninit(device: MTLDevice, a: Float)\nInitializes a ReLU neuron filter.\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSMatrixMultiplication | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixmultiplication",
    "html": "Overview\n\nAn MPSMatrixMultiplication object computes the following operation:\n\nC = alpha * op(A) * op(B) + beta * C\n\nWhere A, B, and C are matrices represented by MPSMatrix objects, and alpha and beta are scalar values of the same data type as the values of C. A and B may each have an optional transposition operation applied.\n\nMatrices A, B, and C are also referred to as the left input matrix, the right input matrix, and the result matrix respectively.\n\nTopics\nMethods\ninit(device: MTLDevice, transposeLeft: Bool, transposeRight: Bool, resultRows: Int, resultColumns: Int, interiorColumns: Int, alpha: Double, beta: Double)\nInitializes a matrix multiplication kernel.\nfunc encode(commandBuffer: MTLCommandBuffer, leftMatrix: MPSMatrix, rightMatrix: MPSMatrix, resultMatrix: MPSMatrix)\nEncodes a matrix multiplication kernel to a command buffer.\nProperties\nvar leftMatrixOrigin: MTLOrigin\nThe origin of the left input matrix.\nvar rightMatrixOrigin: MTLOrigin\nThe origin of the right input matrix.\nvar resultMatrixOrigin: MTLOrigin\nThe origin of the result matrix.\nvar batchSize: Int\nvar batchStart: Int\nInitializers\ninit(device: MTLDevice, resultRows: Int, resultColumns: Int, interiorColumns: Int)\nRelationships\nInherits From\nMPSKernel\nSee Also\nMatrix Arithmetic Operations\nclass MPSMatrixSum\nA kernel for performing a pointwise summation of a matrix.\nclass MPSMatrixVectorMultiplication\nA matrix-vector multiplication kernel\nclass MPSMatrixFindTopK\nA kernel for computing the top-K values and their corresponding indices in a matrix."
  },
  {
    "title": "MPSTemporaryVector | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporaryvector",
    "html": "Topics\nInitializers\ninit(commandBuffer: MTLCommandBuffer, descriptor: MPSVectorDescriptor)\nInstance Properties\nvar readCount: Int\nType Methods\nclass func prefetchStorage(with: MTLCommandBuffer, descriptorList: [MPSVectorDescriptor])\nRelationships\nInherits From\nMPSVector\nSee Also\nVectors\nclass MPSVector\nA 1D array of data that stores the data's values.\nclass MPSVectorDescriptor\nA description of the length and data type of a vector."
  },
  {
    "title": "MPSCNNBinaryKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbinarykernel",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar clipRect: MTLRegion\nvar destinationFeatureChannelOffset: Int\nvar destinationImageAllocator: MPSImageAllocator\nvar isBackwards: Bool\nvar padding: MPSNNPadding\nvar primaryEdgeMode: MPSImageEdgeMode\nvar primaryOffset: MPSOffset\nvar primaryStrideInPixelsX: Int\nvar primaryStrideInPixelsY: Int\nvar secondaryEdgeMode: MPSImageEdgeMode\nvar secondaryOffset: MPSOffset\nvar secondaryStrideInPixelsX: Int\nvar secondaryStrideInPixelsY: Int\nvar isStateModified: Bool\nvar primaryDilationRateX: Int\nvar primaryDilationRateY: Int\nvar primaryKernelHeight: Int\nvar primaryKernelWidth: Int\nvar primarySourceFeatureChannelMaxCount: Int\nvar primarySourceFeatureChannelOffset: Int\nvar secondaryDilationRateX: Int\nvar secondaryDilationRateY: Int\nvar secondaryKernelHeight: Int\nvar secondaryKernelWidth: Int\nvar secondarySourceFeatureChannelMaxCount: Int\nvar secondarySourceFeatureChannelOffset: Int\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage) -> MPSImage\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, destinationImage: MPSImage)\nfunc appendBatchBarrier() -> Bool\nfunc batchEncodingStorageSize(primaryImage: [MPSImage], secondaryImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]?) -> Int\nfunc destinationImageDescriptor(forSourceImages: [MPSImage], sourceStates: [MPSState]?) -> MPSImageDescriptor\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, destinationState: AutoreleasingUnsafeMutablePointer<MPSState?>, destinationStateIsTemporary: Bool) -> MPSImage\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, primaryImages: [MPSImage], secondaryImages: [MPSImage]) -> [MPSImage]\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, primaryImages: [MPSImage], secondaryImages: [MPSImage], destinationImages: [MPSImage])\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, primaryImages: [MPSImage], secondaryImages: [MPSImage], destinationStates: AutoreleasingUnsafeMutablePointer<NSArray?>, destinationStateIsTemporary: Bool) -> [MPSImage]\nfunc encodingStorageSize(primaryImage: MPSImage, secondaryImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage?) -> Int\nfunc isResultStateReusedAcrossBatch() -> Bool\nfunc resultState(primaryImage: MPSImage, secondaryImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSState?\nfunc resultStateBatch(primaryImage: [MPSImage], secondaryImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> [MPSState]?\nfunc temporaryResultState(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSState?\nfunc temporaryResultStateBatch(commandBuffer: MTLCommandBuffer, primaryImage: [MPSImage], secondaryImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> [MPSState]?\nRelationships\nInherits From\nMPSKernel\nSee Also\nLayer Base Classes\nclass MPSCNNKernel\nBase class for neural network layers.\nclass MPSCNNGradientKernel\nThe base class for gradient layers."
  },
  {
    "title": "MPSNNOptimizer | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnoptimizer",
    "html": "Topics\nInstance Properties\nvar applyGradientClipping: Bool\nvar gradientClipMax: Float\nvar gradientClipMin: Float\nvar gradientRescale: Float\nvar learningRate: Float\nvar regularizationScale: Float\nvar regularizationType: MPSNNRegularizationType\nInstance Methods\nfunc setLearningRate(Float)\nRelationships\nInherits From\nMPSKernel\nSee Also\nOptimization Layers\nclass MPSNNOptimizerAdam\nAn optimization layer that performs an Adam pdate.\nclass MPSNNOptimizerRMSProp\nAn optimization layer that performs a root mean square propagation update.\nclass MPSNNOptimizerStochasticGradientDescent\nAn optimization layer that performs a gradient descent with an optional momentum update.\nclass MPSNNOptimizerDescriptor\nAn object that specifies properties used by an optimizer kernel."
  },
  {
    "title": "MPSNNOptimizerAdam | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnoptimizeradam",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, beta1: Double, beta2: Double, epsilon: Float, timeStep: Int, optimizerDescriptor: MPSNNOptimizerDescriptor)\ninit(device: MTLDevice, learningRate: Float)\nInstance Properties\nvar beta1: Double\nvar beta2: Double\nvar epsilon: Float\nvar timeStep: Int\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, batchNormalizationGradientState: MPSCNNBatchNormalizationState, batchNormalizationSourceState: MPSCNNBatchNormalizationState, inputMomentumVectors: [MPSVector], inputVelocityVectors: [MPSVector], maximumVelocityVectors: [MPSVector]?, resultState: MPSCNNNormalizationGammaAndBetaState)\nfunc encode(commandBuffer: MTLCommandBuffer, batchNormalizationGradientState: MPSCNNBatchNormalizationState, batchNormalizationSourceState: MPSCNNBatchNormalizationState, inputMomentumVectors: [MPSVector]?, inputVelocityVectors: [MPSVector]?, resultState: MPSCNNNormalizationGammaAndBetaState)\nfunc encode(commandBuffer: MTLCommandBuffer, batchNormalizationState: MPSCNNBatchNormalizationState, inputMomentumVectors: [MPSVector], inputVelocityVectors: [MPSVector], maximumVelocityVectors: [MPSVector]?, resultState: MPSCNNNormalizationGammaAndBetaState)\nfunc encode(commandBuffer: MTLCommandBuffer, batchNormalizationState: MPSCNNBatchNormalizationState, inputMomentumVectors: [MPSVector]?, inputVelocityVectors: [MPSVector]?, resultState: MPSCNNNormalizationGammaAndBetaState)\nfunc encode(commandBuffer: MTLCommandBuffer, convolutionGradientState: MPSCNNConvolutionGradientState, convolutionSourceState: MPSCNNConvolutionWeightsAndBiasesState, inputMomentumVectors: [MPSVector], inputVelocityVectors: [MPSVector], maximumVelocityVectors: [MPSVector]?, resultState: MPSCNNConvolutionWeightsAndBiasesState)\nfunc encode(commandBuffer: MTLCommandBuffer, convolutionGradientState: MPSCNNConvolutionGradientState, convolutionSourceState: MPSCNNConvolutionWeightsAndBiasesState, inputMomentumVectors: [MPSVector]?, inputVelocityVectors: [MPSVector]?, resultState: MPSCNNConvolutionWeightsAndBiasesState)\nfunc encode(commandBuffer: MTLCommandBuffer, inputGradientMatrix: MPSMatrix, inputValuesMatrix: MPSMatrix, inputMomentumMatrix: MPSMatrix, inputVelocityMatrix: MPSMatrix, maximumVelocityMatrix: MPSMatrix?, resultValuesMatrix: MPSMatrix)\nfunc encode(commandBuffer: MTLCommandBuffer, inputGradientMatrix: MPSMatrix, inputValuesMatrix: MPSMatrix, inputMomentumMatrix: MPSMatrix, inputVelocityMatrix: MPSMatrix, resultValuesMatrix: MPSMatrix)\nfunc encode(commandBuffer: MTLCommandBuffer, inputGradientVector: MPSVector, inputValuesVector: MPSVector, inputMomentumVector: MPSVector, inputVelocityVector: MPSVector, maximumVelocityVector: MPSVector?, resultValuesVector: MPSVector)\nfunc encode(commandBuffer: MTLCommandBuffer, inputGradientVector: MPSVector, inputValuesVector: MPSVector, inputMomentumVector: MPSVector, inputVelocityVector: MPSVector, resultValuesVector: MPSVector)\nRelationships\nInherits From\nMPSNNOptimizer\nSee Also\nOptimization Layers\nclass MPSNNOptimizerRMSProp\nAn optimization layer that performs a root mean square propagation update.\nclass MPSNNOptimizerStochasticGradientDescent\nAn optimization layer that performs a gradient descent with an optional momentum update.\nclass MPSNNOptimizer\nThe base class for optimization layers.\nclass MPSNNOptimizerDescriptor\nAn object that specifies properties used by an optimizer kernel."
  },
  {
    "title": "MPSNNReduceFeatureChannelsMin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducefeaturechannelsmin",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceFeatureChannelsMean | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducefeaturechannelsmean",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNOptimizerRMSProp | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnoptimizerrmsprop",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, decay: Double, epsilon: Float, optimizerDescriptor: MPSNNOptimizerDescriptor)\ninit(device: MTLDevice, learningRate: Float)\nInstance Properties\nvar decay: Double\nvar epsilon: Float\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, batchNormalizationGradientState: MPSCNNBatchNormalizationState, batchNormalizationSourceState: MPSCNNBatchNormalizationState, inputSumOfSquaresVectors: [MPSVector]?, resultState: MPSCNNNormalizationGammaAndBetaState)\nfunc encode(commandBuffer: MTLCommandBuffer, batchNormalizationState: MPSCNNBatchNormalizationState, inputSumOfSquaresVectors: [MPSVector]?, resultState: MPSCNNNormalizationGammaAndBetaState)\nfunc encode(commandBuffer: MTLCommandBuffer, convolutionGradientState: MPSCNNConvolutionGradientState, convolutionSourceState: MPSCNNConvolutionWeightsAndBiasesState, inputSumOfSquaresVectors: [MPSVector]?, resultState: MPSCNNConvolutionWeightsAndBiasesState)\nfunc encode(commandBuffer: MTLCommandBuffer, inputGradientMatrix: MPSMatrix, inputValuesMatrix: MPSMatrix, inputSumOfSquaresMatrix: MPSMatrix, resultValuesMatrix: MPSMatrix)\nfunc encode(commandBuffer: MTLCommandBuffer, inputGradientVector: MPSVector, inputValuesVector: MPSVector, inputSumOfSquaresVector: MPSVector, resultValuesVector: MPSVector)\nRelationships\nInherits From\nMPSNNOptimizer\nSee Also\nOptimization Layers\nclass MPSNNOptimizerAdam\nAn optimization layer that performs an Adam pdate.\nclass MPSNNOptimizerStochasticGradientDescent\nAn optimization layer that performs a gradient descent with an optional momentum update.\nclass MPSNNOptimizer\nThe base class for optimization layers.\nclass MPSNNOptimizerDescriptor\nAn object that specifies properties used by an optimizer kernel."
  },
  {
    "title": "MPSNNReduceColumnMin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducecolumnmin",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceRowMean | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducerowmean",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSNNReduceRowSum | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducerowsum",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceUnary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSMatrixDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixdescriptor",
    "html": "Overview\n\nMatrix data is assumed to be stored in row-major order.\n\nTopics\nInitializers\ninit(rows: Int, columns: Int, matrices: Int, rowBytes: Int, matrixBytes: Int, dataType: MPSDataType)\ninit(rows: Int, columns: Int, rowBytes: Int, dataType: MPSDataType)\nMethods\ninit(dimensions: Int, columns: Int, rowBytes: Int, dataType: MPSDataType)\nCreates a matrix descriptor with the specified dimensions and data type.\nclass func rowBytes(fromColumns: Int, dataType: MPSDataType) -> Int\nDetermines the recommended matrix row stride, in bytes, for a given number of columns.\nclass func rowBytes(forColumns: Int, dataType: MPSDataType) -> Int\nProperties\nvar rows: Int\nThe number of rows in the matrix.\nvar columns: Int\nThe number of columns in the matrix.\nvar dataType: MPSDataType\nThe type of the values in the matrix.\nenum MPSDataType\nA value to specify a type of data.\nvar rowBytes: Int\nThe stride, in bytes, between corresponding elements of consecutive rows in the matrix.\nvar matrices: Int\nvar matrixBytes: Int\nRelationships\nInherits From\nNSObject\nSee Also\nMatrices\nclass MPSMatrix\nA 2D array of data that stores the data's values.\nclass MPSTemporaryMatrix\nA matrix allocated on GPU private memory."
  },
  {
    "title": "MPSNNReduceFeatureChannelsAndWeightsMean | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreducefeaturechannelsandweightsmean",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSNNReduceBinary\nSee Also\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters."
  },
  {
    "title": "MPSCNNLossDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlossdescriptor",
    "html": "Topics\nInitializers\ninit(type: MPSCNNLossType, reductionType: MPSCNNReductionType)\nInstance Properties\nvar delta: Float\nvar epsilon: Float\nvar labelSmoothing: Float\nvar lossType: MPSCNNLossType\nvar numberOfClasses: Int\nvar reduceAcrossBatch: Bool\nvar reductionType: MPSCNNReductionType\nvar weight: Float\nRelationships\nInherits From\nNSObject\nConforms To\nNSCopying\nSee Also\nLoss Layers\nclass MPSCNNLoss\nA kernel that computes the loss and loss gradient between specified predictions and labels.\nclass MPSCNNLossDataDescriptor\nAn object that specifies properties used by a loss data descriptor.\nclass MPSCNNLossLabels\nA class that stores the per-element weight buffer used by loss and gradient loss kernels.\nclass MPSCNNYOLOLoss\nA kernel that computes the YOLO loss and loss gradient between specified predictions and labels.\nclass MPSCNNYOLOLossDescriptor\nAn object that specifies properties used by a YOLO loss kernel."
  },
  {
    "title": "MPSCNNLossLabels | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlosslabels",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, labelsDescriptor: MPSCNNLossDataDescriptor)\ninit(device: MTLDevice, lossImageSize: MTLSize, labelsDescriptor: MPSCNNLossDataDescriptor, weightsDescriptor: MPSCNNLossDataDescriptor?)\ninit(device: MTLDevice, lossImageSize: MTLSize, labelsImage: MPSImage, weightsImage: MPSImage?)\nInstance Methods\nfunc labelsImage() -> MPSImage\nfunc lossImage() -> MPSImage\nfunc weightsImage() -> MPSImage\nRelationships\nInherits From\nMPSState\nSee Also\nLoss Layers\nclass MPSCNNLoss\nA kernel that computes the loss and loss gradient between specified predictions and labels.\nclass MPSCNNLossDataDescriptor\nAn object that specifies properties used by a loss data descriptor.\nclass MPSCNNLossDescriptor\nAn object that specifies properties used by a loss kernel.\nclass MPSCNNYOLOLoss\nA kernel that computes the YOLO loss and loss gradient between specified predictions and labels.\nclass MPSCNNYOLOLossDescriptor\nAn object that specifies properties used by a YOLO loss kernel."
  },
  {
    "title": "MPSImageReduceColumnMean | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereducecolumnmean",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageReduceUnary\nSee Also\nImage Reduction Filters\nclass MPSImageReduceRowMax\nA filter that returns the maximum value for each row in an image.\nclass MPSImageReduceRowMin\nA filter that returns the minimum value for each row in an image.\nclass MPSImageReduceRowSum\nA filter that returns the sum of all values for a row in an image.\nclass MPSImageReduceRowMean\nA filter that returns the mean value for each row in an image.\nclass MPSImageReduceColumnMax\nA filter that returns the maximum value for each column in an image.\nclass MPSImageReduceColumnMin\nA filter that returns the minimum value for each column in an image.\nclass MPSImageReduceColumnSum\nA filter that returns the sum of all values for a column in an image.\nclass MPSImageReduceUnary\nThe base class for reduction filters that take a single source as input."
  },
  {
    "title": "MPSImageReduceRowMin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereducerowmin",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageReduceUnary\nSee Also\nImage Reduction Filters\nclass MPSImageReduceRowMax\nA filter that returns the maximum value for each row in an image.\nclass MPSImageReduceRowSum\nA filter that returns the sum of all values for a row in an image.\nclass MPSImageReduceRowMean\nA filter that returns the mean value for each row in an image.\nclass MPSImageReduceColumnMax\nA filter that returns the maximum value for each column in an image.\nclass MPSImageReduceColumnMin\nA filter that returns the minimum value for each column in an image.\nclass MPSImageReduceColumnSum\nA filter that returns the sum of all values for a column in an image.\nclass MPSImageReduceColumnMean\nA filter that returns the mean value for each column in an image.\nclass MPSImageReduceUnary\nThe base class for reduction filters that take a single source as input."
  },
  {
    "title": "MPSImageMultiply | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagemultiply",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageArithmetic\nSee Also\nImage Arithmetic Filters\nclass MPSImageAdd\nA filter that returns the element-wise sum of its two input images.\nclass MPSImageSubtract\nA filter that returns the element-wise difference of its two input images.\nclass MPSImageDivide\nA filter that returns the element-wise quotient of its two input images.\nclass MPSImageArithmetic\nBase class for basic arithmetic nodes"
  },
  {
    "title": "MPSImageSubtract | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagesubtract",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageArithmetic\nSee Also\nImage Arithmetic Filters\nclass MPSImageAdd\nA filter that returns the element-wise sum of its two input images.\nclass MPSImageMultiply\nA filter that returns the element-wise product of its two input images.\nclass MPSImageDivide\nA filter that returns the element-wise quotient of its two input images.\nclass MPSImageArithmetic\nBase class for basic arithmetic nodes"
  },
  {
    "title": "MPSImageBilinearScale | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagebilinearscale",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageScale\nSee Also\nImage Manipulation Filters\nclass MPSImageConversion\nA filter that performs a conversion of color space, alpha, or pixel format.\nclass MPSImageScale\nA filter that resizes and changes the aspect ratio of an image.\nclass MPSImageLanczosScale\nA filter that resizes and changes the aspect ratio of an image using Lanczos resampling.\nclass MPSImageTranspose\nA filter that transposes an image."
  },
  {
    "title": "MPSImageArithmetic | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagearithmetic",
    "html": "Topics\nInstance Properties\nvar bias: Float\nvar primaryScale: Float\nvar primaryStrideInPixels: MTLSize\nvar secondaryScale: Float\nvar secondaryStrideInPixels: MTLSize\nvar maximumValue: Float\nvar minimumValue: Float\nRelationships\nInherits From\nMPSBinaryImageKernel\nSee Also\nImage Arithmetic Filters\nclass MPSImageAdd\nA filter that returns the element-wise sum of its two input images.\nclass MPSImageSubtract\nA filter that returns the element-wise difference of its two input images.\nclass MPSImageMultiply\nA filter that returns the element-wise product of its two input images.\nclass MPSImageDivide\nA filter that returns the element-wise quotient of its two input images."
  },
  {
    "title": "MPSImageReduceColumnMin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereducecolumnmin",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageReduceUnary\nSee Also\nImage Reduction Filters\nclass MPSImageReduceRowMax\nA filter that returns the maximum value for each row in an image.\nclass MPSImageReduceRowMin\nA filter that returns the minimum value for each row in an image.\nclass MPSImageReduceRowSum\nA filter that returns the sum of all values for a row in an image.\nclass MPSImageReduceRowMean\nA filter that returns the mean value for each row in an image.\nclass MPSImageReduceColumnMax\nA filter that returns the maximum value for each column in an image.\nclass MPSImageReduceColumnSum\nA filter that returns the sum of all values for a column in an image.\nclass MPSImageReduceColumnMean\nA filter that returns the mean value for each column in an image.\nclass MPSImageReduceUnary\nThe base class for reduction filters that take a single source as input."
  },
  {
    "title": "MPSImageReduceColumnSum | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereducecolumnsum",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageReduceUnary\nSee Also\nImage Reduction Filters\nclass MPSImageReduceRowMax\nA filter that returns the maximum value for each row in an image.\nclass MPSImageReduceRowMin\nA filter that returns the minimum value for each row in an image.\nclass MPSImageReduceRowSum\nA filter that returns the sum of all values for a row in an image.\nclass MPSImageReduceRowMean\nA filter that returns the mean value for each row in an image.\nclass MPSImageReduceColumnMax\nA filter that returns the maximum value for each column in an image.\nclass MPSImageReduceColumnMin\nA filter that returns the minimum value for each column in an image.\nclass MPSImageReduceColumnMean\nA filter that returns the mean value for each column in an image.\nclass MPSImageReduceUnary\nThe base class for reduction filters that take a single source as input."
  },
  {
    "title": "MPSImageDivide | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedivide",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageArithmetic\nSee Also\nImage Arithmetic Filters\nclass MPSImageAdd\nA filter that returns the element-wise sum of its two input images.\nclass MPSImageSubtract\nA filter that returns the element-wise difference of its two input images.\nclass MPSImageMultiply\nA filter that returns the element-wise product of its two input images.\nclass MPSImageArithmetic\nBase class for basic arithmetic nodes"
  },
  {
    "title": "MPSImageReduceUnary | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereduceunary",
    "html": "Topics\nInstance Properties\nvar clipRectSource: MTLRegion\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Reduction Filters\nclass MPSImageReduceRowMax\nA filter that returns the maximum value for each row in an image.\nclass MPSImageReduceRowMin\nA filter that returns the minimum value for each row in an image.\nclass MPSImageReduceRowSum\nA filter that returns the sum of all values for a row in an image.\nclass MPSImageReduceRowMean\nA filter that returns the mean value for each row in an image.\nclass MPSImageReduceColumnMax\nA filter that returns the maximum value for each column in an image.\nclass MPSImageReduceColumnMin\nA filter that returns the minimum value for each column in an image.\nclass MPSImageReduceColumnSum\nA filter that returns the sum of all values for a column in an image.\nclass MPSImageReduceColumnMean\nA filter that returns the mean value for each column in an image."
  },
  {
    "title": "MPSImageReduceRowMean | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereducerowmean",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageReduceUnary\nSee Also\nImage Reduction Filters\nclass MPSImageReduceRowMax\nA filter that returns the maximum value for each row in an image.\nclass MPSImageReduceRowMin\nA filter that returns the minimum value for each row in an image.\nclass MPSImageReduceRowSum\nA filter that returns the sum of all values for a row in an image.\nclass MPSImageReduceColumnMax\nA filter that returns the maximum value for each column in an image.\nclass MPSImageReduceColumnMin\nA filter that returns the minimum value for each column in an image.\nclass MPSImageReduceColumnSum\nA filter that returns the sum of all values for a column in an image.\nclass MPSImageReduceColumnMean\nA filter that returns the mean value for each column in an image.\nclass MPSImageReduceUnary\nThe base class for reduction filters that take a single source as input."
  },
  {
    "title": "MPSImageStatisticsMean | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagestatisticsmean",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar clipRectSource: MTLRegion\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Statistics Filters\nclass MPSImageStatisticsMeanAndVariance\nA kernel that computes the mean and variance for a given region of an image.\nclass MPSImageStatisticsMinAndMax\nA kernel that computes the minimum and maximum pixel values for a given region of an image."
  },
  {
    "title": "MPSImageStatisticsMinAndMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagestatisticsminandmax",
    "html": "Overview\n\nThe minimum and maximum values are written to the destination image at the following pixel locations:\n\nMinimum value is written at pixel location (0, 0)\n\nMaximum value is written at pixel location (1, 0)\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar clipRectSource: MTLRegion\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Statistics Filters\nclass MPSImageStatisticsMean\nA kernel that computes the mean for a given region of an image.\nclass MPSImageStatisticsMeanAndVariance\nA kernel that computes the mean and variance for a given region of an image."
  },
  {
    "title": "MPSCNNPoolingL2NormGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingl2normgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nRelationships\nInherits From\nMPSCNNPoolingGradient\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter."
  },
  {
    "title": "MPSCNNNeuronELU | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronelu",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nTopics\nInitializers\ninit(device: MTLDevice, a: Float)\nInitializes a parametric ELU neuron filter.\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSCNNNeuronAbsolute | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronabsolute",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nTopics\nInitializers\ninit(device: MTLDevice)\nInitializes an absolute neuron filter.\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSCNNFullyConnectedGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnfullyconnectedgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, weights: MPSCNNConvolutionDataSource)\nRelationships\nInherits From\nMPSCNNConvolutionGradient\nSee Also\nFully Connected Layers\nclass MPSCNNBinaryFullyConnected\nA fully connected convolution layer with binary weights and optionally binarized input image.\nclass MPSCNNFullyConnected\nA fully connected convolution layer, also known as an inner product layer."
  },
  {
    "title": "MPSCNNFullyConnected | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnfullyconnected",
    "html": "Overview\n\nA fully connected layer in a Convolutional Neural Network (CNN) is one where every input channel is connected to every output channel. The kernel width is equal to the width of the source image, and the kernel height is equal to the height of the source image. The width and height of the output is 1 x 1.\n\nA fully connected layer takes an MPSImage object with dimensions source.width x source.height x Ni, convolves it with Weights[No][source.width][source.height][Ni],and produces a 1 x 1 x No output.\n\nThus, the following conditions must be true:\n\nkernelWidth == source.width\n\nkernelHeight == source.height\n\nclipRect.size.width == 1\n\nclipRect.size.height == 1\n\nYou can think of a fully connected layer as a matrix multiplication where the image is flattened into a vector of length source.width*source.height*Ni, and the weights are arranged in a matrix of dimension No x (source.width*source.height*Ni) to produce an output vector of length No.\n\nThe value of the strideInPixelsX, strideInPixelsY, and groups properties must be 1. The offset property is not applicable and it is ignored. Because the clip rectangle is clamped to the destination image bounds, if the destination is 1 x 1, you do not need to set the clipRect property.\n\nNote\n\nYou can implement a fully connected convolution layer using an MPSCNNConvolution object by setting the following property values:\n\noffset = (kernelWidth/2,kernelHeight/2)\n\nclipRect.origin = (ox,oy)\n\nclipRect.size = (1,1)\n\nstrideInPixelsX = strideInPixelsY = groups = 1\n\nHowever, using an MPSCNNFullyConnected object directly is better for performance as it lets the Metal Performance Shaders framework choose the most performant implementation method, which may not be possible when you use a general convolution. For example, the framework may internally use matrix multiplication or special reduction kernels for a specific Metal feature set.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes a fully connected convolution layer.\ninit(device: MTLDevice, weights: MPSCNNConvolutionDataSource)\nInitializes a fully connected convolution layer.\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\ninit(device: MTLDevice, convolutionDescriptor: MPSCNNConvolutionDescriptor, kernelWeights: UnsafePointer<Float>, biasTerms: UnsafePointer<Float>?, flags: MPSCNNConvolutionFlags)\nInitializes a fully connected convolution layer.\nDeprecated\nclass MPSCNNConvolutionDescriptor\nA description of the attributes of a convolution kernel.\nenum MPSCNNConvolutionFlags\nOptions used to control how kernel weights are stored and used in the CNN kernels\nRelationships\nInherits From\nMPSCNNConvolution\nSee Also\nFully Connected Layers\nclass MPSCNNBinaryFullyConnected\nA fully connected convolution layer with binary weights and optionally binarized input image.\nclass MPSCNNFullyConnectedGradient\nA gradient fully connected convolution layer."
  },
  {
    "title": "MPSCNNPoolingMaxGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingmaxgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nRelationships\nInherits From\nMPSCNNPoolingGradient\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter."
  },
  {
    "title": "MPSCNNBinaryFullyConnected | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbinaryfullyconnected",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes a fully connected convolution layer with binary weights.\ninit(device: MTLDevice, convolutionData: MPSCNNConvolutionDataSource, outputBiasTerms: UnsafePointer<Float>?, outputScaleTerms: UnsafePointer<Float>?, inputBiasTerms: UnsafePointer<Float>?, inputScaleTerms: UnsafePointer<Float>?, type: MPSCNNBinaryConvolutionType, flags: MPSCNNBinaryConvolutionFlags)\nInitializes a fully connected convolution layer with binary weights.\ninit(device: MTLDevice, convolutionData: MPSCNNConvolutionDataSource, scaleValue: Float, type: MPSCNNBinaryConvolutionType, flags: MPSCNNBinaryConvolutionFlags)\nInitializes a fully connected convolution layer with binary weights.\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\nenum MPSCNNBinaryConvolutionType\nOptions that defines what operations are used to perform binary convolution.\nenum MPSCNNBinaryConvolutionFlags\nOptions used to control binary convolution kernels.\nRelationships\nInherits From\nMPSCNNBinaryConvolution\nSee Also\nFully Connected Layers\nclass MPSCNNFullyConnected\nA fully connected convolution layer, also known as an inner product layer.\nclass MPSCNNFullyConnectedGradient\nA gradient fully connected convolution layer."
  },
  {
    "title": "MPSCNNDilatedPoolingMaxGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndilatedpoolingmaxgradient",
    "html": "Overview\n\nA gradient max pooling filter but the pixels selected in each “application” of the max pooling operation are exactly the same pixels that would be selected with dilated convolution\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, dilationRateX: Int, dilationRateY: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nRelationships\nInherits From\nMPSCNNPoolingGradient\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter."
  },
  {
    "title": "MPSCNNPoolingGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolinggradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int)\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nInstance Properties\nvar sourceSize: MTLSize\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter."
  },
  {
    "title": "MPSCNNPooling | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpooling",
    "html": "Overview\n\nPooling is a form of non-linear sub-sampling. Pooling partitions the input image into a set of rectangles (overlapping or non-overlapping) and, for each such sub-region, outputs a value. The pooling operation is used in computer vision to reduce the dimensionality of intermediate representations.\n\nThe encode methods in the MPSCNNKernel class can be used to encode an MPSCNNPooling object to a MTLCommandBuffer object. The exact location of the pooling window for each output value is determined as follows:\n\nThe pooling window center for the first (top left) output pixel of the clip rectangle is at spatial coordinates (offset.x, offset.y) in the input image.\n\nFrom this, the top left corner of the pooling window is at (offset.x - floor(kernelWidth/2), offset.y - floor(kernelHeight/2)) and extends (kernelWidth, kernelHeight) pixels to the right and down direction, which means that the last pixel to be included into the pooling window is at (offset.x + floor((kernelWidth-1)/2), offset.y + floor((kernelHeight-1)/2)), so that for even kernel sizes the pooling window extends one pixel more into the left and up direction.\n\nThe following pooling windows can be then easily deduced from the first one by simple shifting the source coordinates according to the values of the strideInPixelsX and strideInPixelsY properties.\n\nFor example, the pooling window center w(x,y) for the output value at coordinate (x,y) of the destination clip rectangle ((x,y) computed with regard to clipping rectangle origin) is at w(x,y) = (offset.x + strideInPixelsX * x , offset.y + strideInPixelsY * y).\n\nQuite often it is desirable to distribute the pooling windows as evenly as possible in the input image. As explained above, if the offset is zero, then the center of the first pooling window is at the top left corner of the input image, which means that the left and top stripes of the pooling window are read from outside the input image boundaries (when filter size is larger than unity). Also it may mean that some values from the bottom and right stripes are not included at all in the pooling, resulting in loss of valuable information.\n\nA scheme used in some common libraries is to shift the source offset according to the following formula:\n\noffset.xy += {(int)ceil(((L.xy - 1) % s.xy) / 2)}, for odd f.xy\n\noffset.xy += {(int)floor(((L.xy - 1) % s.xy) / 2) + 1}, for even f.xy\n\nWhere L is the size of the input image (or more accurately the size corresponding to the scaled clipRect value in source coordinates, which commonly coincides with the source image itself), s.xy is (strideInPixelsX, strideInPixelsY) and f.xy is (kernelWidth, kernelHeight).\n\nThis offset distributes the pooling window centers evenly in the effective source clipRect, when the output size is rounded up with regards to stride (output size = ceil(input size / stride)) and is commonly used in CNN libraries (for example TensorFlow uses this offset scheme in its maximum pooling implementation tf.nn.max_pool with 'SAME' - padding, for 'VALID' padding one can simply set offset.xy += floor(f.xy/2) to get the first pooling window inside the source image completely).\n\nFor an MPSCNNPoolingMax object, the way the input image borders are handled can become important: if there are negative values in the source image near the borders of the image and the pooling window crosses the borders, then using a MPSImageEdgeMode.zero edge modemay cause the maximum pooling operation to override the negative input data values with zeros coming from outside the source image borders, resulting in large boundary effects. A simple way to avoid this is to use a MPSImageEdgeMode.clamp edge mode, which for an MPSCNNPoolingMax object effectively causes all pooling windows to remain within the source image.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes a pooling filter.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int)\nInitializes a pooling filter.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nInitializes a pooling filter.\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter."
  },
  {
    "title": "MPSCNNPoolingMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingmax",
    "html": "Overview\n\nFor each pixel in an image, the filter returns the maximum value of the pixels in the filter region defined by kernelWidth x kernelHeight.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes a max pooling filter.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nInitializes a max pooling filter.\nRelationships\nInherits From\nMPSCNNPooling\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter."
  },
  {
    "title": "MPSCNNDilatedPoolingMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndilatedpoolingmax",
    "html": "Overview\n\nFor each pixel, returns the maximum value of pixels in the kernelWidth * kernelHeight filter region by step size dilationFactorX * dilationFactorY.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes a dilated max pooling filter.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, dilationRateX: Int, dilationRateY: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nInitializes a dilated max pooling filter.\nInstance Properties\nvar dilationRateX: Int\nvar dilationRateY: Int\nRelationships\nInherits From\nMPSCNNPooling\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter."
  },
  {
    "title": "MPSCNNPoolingL2Norm | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingl2norm",
    "html": "Overview\n\nFor each pixel, returns L2-Norm of pixels in the kernelWidth * kernelHeight filter region:\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes an L2-norm pooling filter.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nInitializes an L2-norm pooling filter.\nRelationships\nInherits From\nMPSCNNPooling\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter."
  },
  {
    "title": "MPSCNNPoolingAverageGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingaveragegradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nInstance Properties\nvar zeroPadSizeX: Int\nvar zeroPadSizeY: Int\nRelationships\nInherits From\nMPSCNNPoolingGradient\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter."
  },
  {
    "title": "MPSCNNPoolingAverage | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingaverage",
    "html": "Overview\n\nFor each pixel in an image, the filter returns the average value of the pixels in the filter region defined by kernelWidth x kernelHeight.\n\nWhen the value of the edgeMode property is set to MPSImageEdgeMode.clamp, the filtering window is shrunk to remain within the source image borders. For pixels close to the image borders, the filtering window will be smaller in order to fit inside the source image and less values will be used to compute the average value. In case the filtering window is entirely outside the source image border, the output value will be 0.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes an average pooling filter.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nInitializes an average pooling filter.\nInstance Properties\nvar zeroPadSizeX: Int\nvar zeroPadSizeY: Int\nRelationships\nInherits From\nMPSCNNPooling\nSee Also\nPooling Layers\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter."
  },
  {
    "title": "MPSCNNConvolutionGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiongradientstate",
    "html": "Topics\nInstance Properties\nvar convolution: MPSCNNConvolution\nvar gradientForBiases: MTLBuffer\nvar gradientForWeights: MTLBuffer\nvar gradientForWeightsLayout: MPSCNNConvolutionWeightsLayout\nRelationships\nInherits From\nMPSNNGradientState\nConforms To\nMPSImageSizeEncodingState\nSee Also\nConvolution Layers\nclass MPSCNNBinaryConvolution\nA convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolution\nA convolution kernel that convolves the input image with a set of filters, with each producing one feature map in the output image.\nclass MPSCNNDepthWiseConvolutionDescriptor\nA description of a convolution object that does depthwise convolution.\nclass MPSCNNSubPixelConvolutionDescriptor\nA description of a convolution object that does subpixel upsampling and reshaping.\nclass MPSCNNConvolutionTranspose\nA transposed convolution kernel.\nclass MPSCNNConvolutionGradient\nA gradient convolution kernel.\nprotocol MPSImageSizeEncodingState\nA protocol for objects that contain information about an image size elsewhere in the graph.\nclass MPSCNNConvolutionWeightsAndBiasesState\nA class that stores weights and biases."
  },
  {
    "title": "MPSCNNConvolutionWeightsAndBiasesState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutionweightsandbiasesstate",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, cnnConvolutionDescriptor: MPSCNNConvolutionDescriptor)\ninit(weights: MTLBuffer, biases: MTLBuffer?)\ninit(weights: MTLBuffer, weightsOffset: Int, biases: MTLBuffer?, biasesOffset: Int, cnnConvolutionDescriptor: MPSCNNConvolutionDescriptor)\nInstance Properties\nvar biases: MTLBuffer?\nvar biasesOffset: Int\nvar weights: MTLBuffer\nvar weightsOffset: Int\nType Methods\nclass func temporaryCNNConvolutionWeightsAndBiasesState(with: MTLCommandBuffer, cnnConvolutionDescriptor: MPSCNNConvolutionDescriptor) -> Self\nRelationships\nInherits From\nMPSState\nSee Also\nConvolution Layers\nclass MPSCNNBinaryConvolution\nA convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolution\nA convolution kernel that convolves the input image with a set of filters, with each producing one feature map in the output image.\nclass MPSCNNDepthWiseConvolutionDescriptor\nA description of a convolution object that does depthwise convolution.\nclass MPSCNNSubPixelConvolutionDescriptor\nA description of a convolution object that does subpixel upsampling and reshaping.\nclass MPSCNNConvolutionTranspose\nA transposed convolution kernel.\nclass MPSCNNConvolutionGradient\nA gradient convolution kernel.\nclass MPSCNNConvolutionGradientState\nAn object that exposes a gradient convolution kernel's gradient with respect to weights and biases.\nprotocol MPSImageSizeEncodingState\nA protocol for objects that contain information about an image size elsewhere in the graph."
  },
  {
    "title": "MPSCNNConvolutionTranspose | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiontranspose",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes a transposed convolution kernel.\ninit(device: MTLDevice, weights: MPSCNNConvolutionDataSource)\nInitializes a transposed convolution kernel.\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\nInstance Properties\nvar groups: Int\nvar inputFeatureChannels: Int\nvar kernelOffsetX: Int\nvar kernelOffsetY: Int\nvar outputFeatureChannels: Int\nvar accumulatorPrecisionOption: MPSNNConvolutionAccumulatorPrecisionOption\nvar dataSource: MPSCNNConvolutionDataSource\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, convolutionGradientState: MPSCNNConvolutionGradientState?) -> MPSImage\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, convolutionGradientState: MPSCNNConvolutionGradientState?, destinationImage: MPSImage)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, convolutionGradientState: MPSCNNConvolutionGradientState?, destinationState: AutoreleasingUnsafeMutablePointer<MPSCNNConvolutionTransposeGradientState?>, destinationStateIsTemporary: Bool) -> MPSImage\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], convolutionGradientStates: [MPSCNNConvolutionGradientState]?) -> [MPSImage]\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], convolutionGradientStates: [MPSCNNConvolutionGradientState]?, destinationImages: [MPSImage])\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], convolutionGradientStates: [MPSCNNConvolutionGradientState]?, destinationStates: AutoreleasingUnsafeMutablePointer<NSArray?>, destinationStateIsTemporary: Bool) -> [MPSImage]\nfunc exportWeightsAndBiases(with: MTLCommandBuffer, resultStateCanBeTemporary: Bool) -> MPSCNNConvolutionWeightsAndBiasesState\nfunc reloadWeightsAndBiases(with: MTLCommandBuffer, state: MPSCNNConvolutionWeightsAndBiasesState)\nfunc reloadWeightsAndBiasesFromDataSource()\nfunc resultState(sourceImage: MPSImage, sourceStates: [MPSCNNConvolutionGradientState]?, destinationImage: MPSImage) -> MPSCNNConvolutionTransposeGradientState?\nfunc resultStateBatch(sourceImage: [MPSImage], sourceStates: [[MPSCNNConvolutionGradientState]]?, destinationImage: [MPSImage]) -> [MPSCNNConvolutionTransposeGradientState]?\nfunc temporaryResultState(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, sourceStates: [MPSCNNConvolutionGradientState]?, destinationImage: MPSImage) -> MPSCNNConvolutionTransposeGradientState?\nfunc temporaryResultStateBatch(commandBuffer: MTLCommandBuffer, sourceImage: [MPSImage], sourceStates: [[MPSCNNConvolutionGradientState]]?, destinationImage: [MPSImage]) -> [MPSCNNConvolutionTransposeGradientState]?\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nConvolution Layers\nclass MPSCNNBinaryConvolution\nA convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolution\nA convolution kernel that convolves the input image with a set of filters, with each producing one feature map in the output image.\nclass MPSCNNDepthWiseConvolutionDescriptor\nA description of a convolution object that does depthwise convolution.\nclass MPSCNNSubPixelConvolutionDescriptor\nA description of a convolution object that does subpixel upsampling and reshaping.\nclass MPSCNNConvolutionGradient\nA gradient convolution kernel.\nclass MPSCNNConvolutionGradientState\nAn object that exposes a gradient convolution kernel's gradient with respect to weights and biases.\nprotocol MPSImageSizeEncodingState\nA protocol for objects that contain information about an image size elsewhere in the graph.\nclass MPSCNNConvolutionWeightsAndBiasesState\nA class that stores weights and biases."
  },
  {
    "title": "MPSCNNConvolutionGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiongradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, weights: MPSCNNConvolutionDataSource)\nInstance Properties\nvar channelMultiplier: Int\nvar dataSource: MPSCNNConvolutionDataSource\nvar gradientOption: MPSCNNConvolutionGradientOption\nvar groups: Int\nvar serializeWeightsAndBiases: Bool\nDeprecated\nvar sourceGradientFeatureChannels: Int\nvar sourceImageFeatureChannels: Int\nInstance Methods\nfunc reloadWeightsAndBiases(with: MTLCommandBuffer, state: MPSCNNConvolutionWeightsAndBiasesState)\nfunc reloadWeightsAndBiasesFromDataSource()\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nConvolution Layers\nclass MPSCNNBinaryConvolution\nA convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolution\nA convolution kernel that convolves the input image with a set of filters, with each producing one feature map in the output image.\nclass MPSCNNDepthWiseConvolutionDescriptor\nA description of a convolution object that does depthwise convolution.\nclass MPSCNNSubPixelConvolutionDescriptor\nA description of a convolution object that does subpixel upsampling and reshaping.\nclass MPSCNNConvolutionTranspose\nA transposed convolution kernel.\nclass MPSCNNConvolutionGradientState\nAn object that exposes a gradient convolution kernel's gradient with respect to weights and biases.\nprotocol MPSImageSizeEncodingState\nA protocol for objects that contain information about an image size elsewhere in the graph.\nclass MPSCNNConvolutionWeightsAndBiasesState\nA class that stores weights and biases."
  },
  {
    "title": "MPSImageSizeEncodingState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagesizeencodingstate",
    "html": "Topics\nInstance Properties\nvar sourceHeight: Int\n\nRequired\n\nvar sourceWidth: Int\n\nRequired\n\nRelationships\nInherits From\nNSObjectProtocol\nConforming Types\nMPSCNNConvolutionGradientState\nSee Also\nConvolution Layers\nclass MPSCNNBinaryConvolution\nA convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolution\nA convolution kernel that convolves the input image with a set of filters, with each producing one feature map in the output image.\nclass MPSCNNDepthWiseConvolutionDescriptor\nA description of a convolution object that does depthwise convolution.\nclass MPSCNNSubPixelConvolutionDescriptor\nA description of a convolution object that does subpixel upsampling and reshaping.\nclass MPSCNNConvolutionTranspose\nA transposed convolution kernel.\nclass MPSCNNConvolutionGradient\nA gradient convolution kernel.\nclass MPSCNNConvolutionGradientState\nAn object that exposes a gradient convolution kernel's gradient with respect to weights and biases.\nclass MPSCNNConvolutionWeightsAndBiasesState\nA class that stores weights and biases."
  },
  {
    "title": "MPSCNNDepthWiseConvolutionDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndepthwiseconvolutiondescriptor",
    "html": "Topics\nInstance Properties\nvar channelMultiplier: Int\nRelationships\nInherits From\nMPSCNNConvolutionDescriptor\nSee Also\nConvolution Layers\nclass MPSCNNBinaryConvolution\nA convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolution\nA convolution kernel that convolves the input image with a set of filters, with each producing one feature map in the output image.\nclass MPSCNNSubPixelConvolutionDescriptor\nA description of a convolution object that does subpixel upsampling and reshaping.\nclass MPSCNNConvolutionTranspose\nA transposed convolution kernel.\nclass MPSCNNConvolutionGradient\nA gradient convolution kernel.\nclass MPSCNNConvolutionGradientState\nAn object that exposes a gradient convolution kernel's gradient with respect to weights and biases.\nprotocol MPSImageSizeEncodingState\nA protocol for objects that contain information about an image size elsewhere in the graph.\nclass MPSCNNConvolutionWeightsAndBiasesState\nA class that stores weights and biases."
  },
  {
    "title": "MPSCNNSubPixelConvolutionDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnsubpixelconvolutiondescriptor",
    "html": "Topics\nInstance Properties\nvar subPixelScaleFactor: Int\nRelationships\nInherits From\nMPSCNNConvolutionDescriptor\nSee Also\nConvolution Layers\nclass MPSCNNBinaryConvolution\nA convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolution\nA convolution kernel that convolves the input image with a set of filters, with each producing one feature map in the output image.\nclass MPSCNNDepthWiseConvolutionDescriptor\nA description of a convolution object that does depthwise convolution.\nclass MPSCNNConvolutionTranspose\nA transposed convolution kernel.\nclass MPSCNNConvolutionGradient\nA gradient convolution kernel.\nclass MPSCNNConvolutionGradientState\nAn object that exposes a gradient convolution kernel's gradient with respect to weights and biases.\nprotocol MPSImageSizeEncodingState\nA protocol for objects that contain information about an image size elsewhere in the graph.\nclass MPSCNNConvolutionWeightsAndBiasesState\nA class that stores weights and biases."
  },
  {
    "title": "MPSImageKeypointRangeInfo | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagekeypointrangeinfo",
    "html": "Topics\nInitializers\ninit()\ninit(maximumKeypoints: Int, minimumThresholdValue: Float)\nInstance Properties\nvar maximumKeypoints: Int\nvar minimumThresholdValue: Float\nSee Also\nKeypoints\nclass MPSImageFindKeypoints\nA kernel that is used to find a list of keypoints.\nstruct MPSImageKeypointData\nA structure that specifies keypoint information."
  },
  {
    "title": "MPSCNNNeuronAbsoluteNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronabsolutenode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNConvolution | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolution",
    "html": "Overview\n\nThe attributes of a convolution operation are described by an MPSCNNConvolutionDescriptor object.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, convolutionDescriptor: MPSCNNConvolutionDescriptor, kernelWeights: UnsafePointer<Float>, biasTerms: UnsafePointer<Float>?, flags: MPSCNNConvolutionFlags)\nInitializes a convolution kernel.\nclass MPSCNNConvolutionDescriptor\nA description of the attributes of a convolution kernel.\nenum MPSCNNConvolutionFlags\nOptions used to control how kernel weights are stored and used in the CNN kernels\ninit(device: MTLDevice, weights: MPSCNNConvolutionDataSource)\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\nInstance Properties\nvar inputFeatureChannels: Int\nThe number of feature channels per pixel in the input image.\nvar outputFeatureChannels: Int\nThe number of feature channels per pixel in the output image.\nvar groups: Int\nThe number of groups that the input and output channels are divided into.\nvar subPixelScaleFactor: Int\nvar neuron: MPSCNNNeuron?\nThe neuron filter to be applied as part of the convolution operation.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nvar neuronType: MPSCNNNeuronType\nDeprecated\nenum MPSCNNNeuronType\nThe types of neuron filter to append to a convolution.\nvar neuronParameterA: Float\nDeprecated\nvar neuronParameterB: Float\nDeprecated\nvar accumulatorPrecisionOption: MPSNNConvolutionAccumulatorPrecisionOption\nvar channelMultiplier: Int\nvar dataSource: MPSCNNConvolutionDataSource\nvar fusedNeuronDescriptor: MPSNNNeuronDescriptor?\nvar neuronParameterC: Float\nDeprecated\nInstance Methods\nfunc exportWeightsAndBiases(with: MTLCommandBuffer, resultStateCanBeTemporary: Bool) -> MPSCNNConvolutionWeightsAndBiasesState\nfunc reloadWeightsAndBiases(with: MPSCNNConvolutionDataSource)\nDeprecated\nfunc reloadWeightsAndBiases(with: MTLCommandBuffer, state: MPSCNNConvolutionWeightsAndBiasesState)\nfunc reloadWeightsAndBiasesFromDataSource()\nfunc resultState(sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNConvolutionGradientState?\nfunc resultStateBatch(sourceImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> [MPSCNNConvolutionGradientState]?\nfunc temporaryResultState(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNConvolutionGradientState?\nfunc temporaryResultStateBatch(commandBuffer: MTLCommandBuffer, sourceImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> [MPSCNNConvolutionGradientState]?\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nConvolution Layers\nclass MPSCNNBinaryConvolution\nA convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNDepthWiseConvolutionDescriptor\nA description of a convolution object that does depthwise convolution.\nclass MPSCNNSubPixelConvolutionDescriptor\nA description of a convolution object that does subpixel upsampling and reshaping.\nclass MPSCNNConvolutionTranspose\nA transposed convolution kernel.\nclass MPSCNNConvolutionGradient\nA gradient convolution kernel.\nclass MPSCNNConvolutionGradientState\nAn object that exposes a gradient convolution kernel's gradient with respect to weights and biases.\nprotocol MPSImageSizeEncodingState\nA protocol for objects that contain information about an image size elsewhere in the graph.\nclass MPSCNNConvolutionWeightsAndBiasesState\nA class that stores weights and biases."
  },
  {
    "title": "MPSImageFindKeypoints | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagefindkeypoints",
    "html": "Overview\n\nThis kernel is used to find a list of keypoints whose values are greater than the minimumThresholdValue in MPSImageKeypointRangeInfo. The keypoints are generated for a specified region in the image. The pixel format of the source image must be MTLPixelFormat.r8Unorm.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, info: UnsafePointer<MPSImageKeypointRangeInfo>)\nInstance Properties\nvar keypointRangeInfo: MPSImageKeypointRangeInfo\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceTexture: MTLTexture, regions: UnsafePointer<MTLRegion>, numberOfRegions: Int, keypointCount: MTLBuffer, keypointCountBufferOffset: Int, keypointDataBuffer: MTLBuffer, keypointDataBufferOffset: Int)\nRelationships\nInherits From\nMPSKernel\nSee Also\nKeypoints\nstruct MPSImageKeypointData\nA structure that specifies keypoint information.\nstruct MPSImageKeypointRangeInfo\nA structure that specifies information to find the keypoints in an image."
  },
  {
    "title": "MPSImageKeypointData | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagekeypointdata",
    "html": "Topics\nInitializers\ninit()\ninit(keypointCoordinate: vector_ushort2, keypointColorValue: Float)\nInstance Properties\nvar keypointColorValue: Float\nvar keypointCoordinate: vector_ushort2\nSee Also\nKeypoints\nclass MPSImageFindKeypoints\nA kernel that is used to find a list of keypoints.\nstruct MPSImageKeypointRangeInfo\nA structure that specifies information to find the keypoints in an image."
  },
  {
    "title": "MPSRectNoClip | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/image_filters/mpsrectnoclip",
    "html": "Overview\n\nThis is a special constant to indicate no clipping is to be done, that is, the entire image will be used.\n\nTopics\nConstants\nlet MPSRectNoClip: MTLRegion"
  },
  {
    "title": "MPSCNNPoolingAverageGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingaveragegradientnode",
    "html": "Relationships\nInherits From\nMPSCNNPoolingGradientNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter."
  },
  {
    "title": "MPSCNNArithmeticGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnarithmeticgradient",
    "html": "Topics\nInstance Properties\nvar bias: Float\nvar isSecondarySourceFilter: Bool\nvar maximumValue: Float\nvar minimumValue: Float\nvar primaryScale: Float\nvar secondaryScale: Float\nvar secondaryStrideInFeatureChannels: Int\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSCNNArithmeticGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnarithmeticgradientstate",
    "html": "Relationships\nInherits From\nMPSNNBinaryGradientState\nSee Also\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators."
  },
  {
    "title": "MPSCNNAdd | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnadd",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNArithmetic\nSee Also\nArithmetic Layers\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSCNNMultiplyGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnmultiplygradient",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, isSecondarySourceFilter: Bool)\nRelationships\nInherits From\nMPSCNNArithmeticGradient\nSee Also\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSCNNMultiply | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnmultiply",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNArithmetic\nSee Also\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSCNNSubtractGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnsubtractgradient",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, isSecondarySourceFilter: Bool)\nRelationships\nInherits From\nMPSCNNArithmeticGradient\nSee Also\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSCNNSubtract | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnsubtract",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNArithmetic\nSee Also\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSCNNAddGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnaddgradient",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, isSecondarySourceFilter: Bool)\nRelationships\nInherits From\nMPSCNNArithmeticGradient\nSee Also\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSCNNLocalContrastNormalization | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalization",
    "html": "Overview\n\nThe local contrast normalization kernel is quite similar to the spatial normalization kernel, described in the MPSCNNSpatialNormalization class, in that it applies the kernel over local regions which extend spatially, but are in separate feature channels (i.e., they have the shape 1 x kernel width x kernel height). However, instead of dividing by the local \"energy\" of the feature, the denominator uses the local variance of the feature - effectively the mean value of the feature is subtracted from the signal. For each feature channel, the function computes the variance VAR(i,j) and mean M(i,j) of X(i,j) inside each rectangle around the spatial point (i,j). Then the result is computed for each element of X as follows:\n\nWhere kw and kh are the values of the kernelWidth and the kernelHeight properties, respectively, and the values of the pm, ps, and p0 properties can be used to offset and scale the result in various ways. For example setting pm=0, ps=1, p0=1, delta=0, alpha=1.0 and beta=0.5 scales input data so that the result has unit variance and zero mean, provided that input variance is positive.\n\nIt is your responsibility to ensure that the combination of the values of the delta and alpha properties does not result in a situation where the denominator becomes zero - in such situations the resulting pixel-value is undefined. A good way to guard against tiny variances is to regulate the expression with a small delta value, for example delta=1/1024.\n\nTip\n\nThe encoding methods in the MPSUnaryImageKernel class can be used to encode an MPSCNNLocalContrastNormalization object to a MTLCommandBuffer object.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes a local contrast normalization kernel.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int)\nInitializes a local contrast normalization kernel.\nInstance Properties\nvar alpha: Float\nThe \"alpha\" variable of the kernel function.\nvar beta: Float\nThe \"beta\" variable of the kernel function.\nvar delta: Float\nThe \"delta\" variable of the kernel function.\nvar p0: Float\nThe \"p0\" variable of the kernel function.\nvar pm: Float\nThe \"pm\" variable of the kernel function.\nvar ps: Float\nThe \"ps\" variable of the kernel function.\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNCrossChannelNormalization | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnncrosschannelnormalization",
    "html": "Overview\n\nThe normalization kernel applies the kernel to a local region across nearby feature channels, but with no spatial extent (i.e., they have the shape kernel size x 1 x 1). The normalized output is given by the function:\n\nWhere the normalizing factor is:\n\nWhere N is the kernel size. The window Q(k) itself is defined as:\n\nWhere k is the feature channel index (running from 0 to D-1) and D is the number of feature channels, and the values of alpha, beta, and delta are set via properties.\n\nIt is your responsibility to ensure that the combination of the values of the delta and alpha properties does not result in a situation where the denominator becomes zero - in such situations the resulting pixel-value is undefined.\n\nNote\n\nThe encoding methods in the MPSUnaryImageKernel class can be used to encode an MPSCNNCrossChannelNormalization object to a MTLCommandBuffer object.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes a normalization kernel in a channel.\ninit(device: MTLDevice, kernelSize: Int)\nInitializes a normalization kernel in a channel.\nInstance Properties\nvar alpha: Float\nThe \"alpha\" variable of the kernel function.\nvar beta: Float\nThe \"beta\" variable of the kernel function.\nvar delta: Float\nThe \"delta\" variable of the kernel function.\nvar kernelSize: Int\nThe size of the square kernel window.\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNBatchNormalizationGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, fusedNeuronDescriptor: MPSNNNeuronDescriptor?)\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceGradient: MPSImage, sourceImage: MPSImage, batchNormalizationState: MPSCNNBatchNormalizationState) -> MPSImage\nfunc encode(to: MTLCommandBuffer, sourceGradient: MPSImage, sourceImage: MPSImage, batchNormalizationState: MPSCNNBatchNormalizationState, destinationGradient: MPSImage)\nfunc encodeBatch(to: MTLCommandBuffer, sourceGradients: [MPSImage], sourceImages: [MPSImage], batchNormalizationState: MPSCNNBatchNormalizationState) -> [MPSImage]\nfunc encodeBatch(to: MTLCommandBuffer, sourceGradients: [MPSImage], sourceImages: [MPSImage], batchNormalizationState: MPSCNNBatchNormalizationState, destinationGradients: [MPSImage])\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNSpatialNormalizationGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnspatialnormalizationgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int)\nInstance Properties\nvar alpha: Float\nvar beta: Float\nvar delta: Float\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNBatchNormalizationStatistics | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationstatistics",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Methods\nfunc encodeBatch(to: MTLCommandBuffer, sourceImages: [MPSImage], batchNormalizationState: MPSCNNBatchNormalizationState)\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNNormalizationMeanAndVarianceState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnnormalizationmeanandvariancestate",
    "html": "Topics\nInitializers\ninit(mean: MTLBuffer, variance: MTLBuffer)\nInstance Properties\nvar mean: MTLBuffer\nvar variance: MTLBuffer\nType Methods\nclass func temporaryState(with: MTLCommandBuffer, numberOfFeatureChannels: Int) -> Self\nRelationships\nInherits From\nMPSState\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNBatchNormalization | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalization",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, dataSource: MPSCNNBatchNormalizationDataSource)\ninit(device: MTLDevice, dataSource: MPSCNNBatchNormalizationDataSource, fusedNeuronDescriptor: MPSNNNeuronDescriptor?)\nInstance Properties\nvar dataSource: MPSCNNBatchNormalizationDataSource\nvar epsilon: Float\nvar numberOfFeatureChannels: Int\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceImage: MPSImage, batchNormalizationState: MPSCNNBatchNormalizationState, destinationImage: MPSImage)\nfunc encodeBatch(to: MTLCommandBuffer, sourceImages: [MPSImage], batchNormalizationState: MPSCNNBatchNormalizationState, destinationImages: [MPSImage])\nfunc reloadDataSource(MPSCNNBatchNormalizationDataSource)\nDeprecated\nfunc reloadGammaAndBeta(with: MTLCommandBuffer, gammaAndBetaState: MPSCNNNormalizationGammaAndBetaState)\nfunc reloadGammaAndBetaFromDataSource()\nfunc reloadMeanAndVariance(with: MTLCommandBuffer, meanAndVarianceState: MPSCNNNormalizationMeanAndVarianceState)\nfunc reloadMeanAndVarianceFromDataSource()\nfunc resultState(sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNBatchNormalizationState?\nfunc temporaryResultState(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNBatchNormalizationState?\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNBatchNormalizationState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationstate",
    "html": "Topics\nInstance Properties\nvar batchNormalization: MPSCNNBatchNormalization\nInstance Methods\nfunc beta() -> MTLBuffer?\nfunc gamma() -> MTLBuffer?\nfunc gradientForBeta() -> MTLBuffer?\nfunc gradientForGamma() -> MTLBuffer?\nfunc mean() -> MTLBuffer?\nfunc reset()\nfunc variance() -> MTLBuffer?\nRelationships\nInherits From\nMPSNNGradientState\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNSpatialNormalization | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnspatialnormalization",
    "html": "Overview\n\nThe spatial normalization for a feature channel applies the kernel over local regions which extend spatially, but are in separate feature channels (i.e., they have the shape 1 x kernel width x kernel height).\n\nFor each feature channel, the function computes the sum of squares of X inside each rectangle, N2(i,j). It then divides each element of X as follows:\n\nWhere kw and kh are the values of the kernelWidth and kernelHeight properties, respectively. It is your responsibility to ensure that the combination of the values of the delta and alphakernelWidthkernelHeight properties does not result in a situation where the denominator becomes zero (in such situations the resulting pixel-value is undefined).\n\nNote\n\nThe encoding methods in the MPSUnaryImageKernel class can be used to encode an MPSCNNSpatialNormalization object to a MTLCommandBuffer object.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nInitializes a spatial normalization kernel.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int)\nInitializes a spatial normalization kernel.\nInstance Properties\nvar alpha: Float\nThe \"alpha\" variable of the kernel function.\nvar beta: Float\nThe \"beta\" variable of the kernel function.\nvar delta: Float\nThe \"delta\" variable of the kernel function.\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNLocalContrastNormalizationGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalizationgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int)\nInstance Properties\nvar alpha: Float\nvar beta: Float\nvar delta: Float\nvar p0: Float\nvar pm: Float\nvar ps: Float\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNCrossChannelNormalizationGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnncrosschannelnormalizationgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, kernelSize: Int)\nInstance Properties\nvar alpha: Float\nvar beta: Float\nvar delta: Float\nvar kernelSize: Int\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations."
  },
  {
    "title": "MPSCNNLogSoftMaxGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlogsoftmaxgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nSoftmax Layers\nclass MPSCNNSoftMax\nA neural transfer function that is useful for classification tasks.\nclass MPSCNNLogSoftMax\nA neural transfer function that is useful for constructing a loss function to be minimized when training neural networks.\nclass MPSCNNSoftMaxGradient\nA gradient softmax filter."
  },
  {
    "title": "MPSCNNSoftMaxGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnsoftmaxgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNGradientKernel\nSee Also\nSoftmax Layers\nclass MPSCNNSoftMax\nA neural transfer function that is useful for classification tasks.\nclass MPSCNNLogSoftMax\nA neural transfer function that is useful for constructing a loss function to be minimized when training neural networks.\nclass MPSCNNLogSoftMaxGradient\nA gradient logarithmic softmax filter."
  },
  {
    "title": "MPSCNNLogSoftMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlogsoftmax",
    "html": "Overview\n\nThe logarithmic softmax filter is calculated by taking the natural logarithm of the result of a softmax filter.\n\nFor each feature channel per pixel in an image in a feature map, the logarithmic softmax filter computes the following:\n\nWhere R is the result channel in the pixel, N is the number of feature channels, and y=ln(x) satisfies eʸ=x.\n\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nSoftmax Layers\nclass MPSCNNSoftMax\nA neural transfer function that is useful for classification tasks.\nclass MPSCNNLogSoftMaxGradient\nA gradient logarithmic softmax filter.\nclass MPSCNNSoftMaxGradient\nA gradient softmax filter."
  },
  {
    "title": "MPSCNNNeuronLogarithm | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronlogarithm",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, a: Float, b: Float, c: Float)\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSCNNNeuronTanH | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneurontanh",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nTopics\nInitializers\ninit(device: MTLDevice, a: Float, b: Float)\nInitializes a hyperbolic tangent neuron filter.\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSImageBox | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagebox",
    "html": "Overview\n\nThe kernel elements all have equal weight, achieving a blur effect (each result is the unweighted average of the surrounding pixels). This allows for much faster algorithms, especially for larger blur radii. The box height and width must be odd numbers.\n\nThe box blur is a separable filter and the Metal Performance Shaders framework will act accordingly to give best performance for multi-dimensional blurs.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int)\nInitializes a box filter.\nProperties\nvar kernelHeight: Int\nThe height of the filter window. Must be an odd number.\nvar kernelWidth: Int\nThe width of the filter window. Must be an odd number.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSImageEuclideanDistanceTransform | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageeuclideandistancetransform",
    "html": "Topics\nCreating a Euclidean distance transform\ninit(device: MTLDevice)\nCreates a Euclidean distance transform that runs on a specified device.\ninit?(coder: NSCoder, device: MTLDevice)\nCreates a Euclidean distance transform that uses a specified decoder for your data and runs on a specified device.\nLimiting the search for nonzero pixels\nvar searchLimitRadius: Float\nLimits the search in an image from a pixel to the closest nonzero pixel within a specified radius.\nRelationships\nInherits From\nMPSUnaryImageKernel"
  },
  {
    "title": "MPSImageLanczosScale | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagelanczosscale",
    "html": "Overview\n\nYou can use this filter to enlarge or reduce the size of an image, or to change the aspect ratio of an image. The filter uses a Lanczos resampling algorithm, that typically produces better quality for photographs, but is slower than linear sampling that uses GPU texture units. Lanczos downsampling does not require a low pass filter to be applied before it is used. Because the resampling function has negative lobes, Lanczos can result in ringing artifacts near sharp edges, making it less suitable for vector art.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nProperties\nstruct MPSScaleTransform\nA transform matrix for explicit resampling control with a Lanczos kernel.\nRelationships\nInherits From\nMPSImageScale\nSee Also\nImage Manipulation Filters\nclass MPSImageConversion\nA filter that performs a conversion of color space, alpha, or pixel format.\nclass MPSImageScale\nA filter that resizes and changes the aspect ratio of an image.\nclass MPSImageBilinearScale\nA filter that resizes and changes the aspect ratio of an image using Bilinear resampling.\nclass MPSImageTranspose\nA filter that transposes an image."
  },
  {
    "title": "MPSImageThresholdBinary | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdbinary",
    "html": "Overview\n\nAn MPSImageThresholdBinary filter converts a single channel image to a binary image. If the input image is not a single channel image, the function first converts the input image into a single channel luminance image using the linear gray color transform, and then it applies the threshold.\n\nListing 1 shows the threshold binary function.\n\nListing 1 Threshold binary function\ndestinationPixelValue = sourcePixelValue > thresholdValue ? maximumValue : 0\n\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, thresholdValue: Float, maximumValue: Float, linearGrayColorTransform: UnsafePointer<Float>?)\nInitializes the kernel.\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter.\nvar maximumValue: Float\nThe maximum value used to initialize the threshold filter.\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Threshold Filters\nclass MPSImageThresholdBinaryInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or a specified value otherwise.\nclass MPSImageThresholdToZero\nA filter that returns the original value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdToZeroInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or the original value otherwise.\nclass MPSImageThresholdTruncate\nA filter that clamps the return value to an upper specified value."
  },
  {
    "title": "MPSImageHistogramSpecification | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogramspecification",
    "html": "Overview\n\nMPSImageHistogramSpecification is a generalized version of histogram equalization operation. The histogram specification filter converts the image so that its histogram matches the desired histogram.\n\nThe process is divided into three steps:\n\nCall the init(device:histogramInfo:) method to create a MPSImageHistogramSpecification object.\n\nCall the encodeTransform(to:sourceTexture:sourceHistogram:sourceHistogramOffset:desiredHistogram:desiredHistogramOffset:) method. This creates a privately held image transform which will convert the distribution of the source histogram to the desired histogram. This process runs on a command buffer when it is committed to a command queue. It must complete before the next step can be run. It may be performed on the same command buffer. The sourceTexture argument is used by the method to determine the number of channels and therefore which histogram data in the source histogram buffer to use. The source histogram and desired histogram must have been computed either on the CPU or using the MPSImageHistogram kernel.\n\nCall the encode(commandBuffer:sourceTexture:destinationTexture:) method to read data from the source texture, apply the equalization transform to it, and write to the destination texture. This step is also done on the GPU on a command queue.\n\nNote\n\nYou can reuse the same specification transform on other images to perform the same transform on those images. (Since their distribution is probably different, they will probably not arrive at the same distribution as the desired histogram.) This filter usually will not be able to work in place.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, histogramInfo: UnsafePointer<MPSImageHistogramInfo>)\nInitializes a histogram with specific information.\nfunc encodeTransform(to: MTLCommandBuffer, sourceTexture: MTLTexture, sourceHistogram: MTLBuffer, sourceHistogramOffset: Int, desiredHistogram: MTLBuffer, desiredHistogramOffset: Int)\nEncodes the transform function to a command buffer using a compute command encoder. The transform function computes the equalization lookup table.\nProperties\nvar histogramInfo: MPSImageHistogramInfo\nA structure describing the histogram content.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nHistogram Image Filters\nclass MPSImageHistogram\nA filter that computes the histogram of an image.\nclass MPSImageHistogramEqualization\nA filter that equalizes the histogram of an image.\nRelated Documentation\nMetal Image Filters: Using the image filters provided by the Metal Performance Shaders framework."
  },
  {
    "title": "MPSCopyAllocator | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscopyallocator",
    "html": "Discussion\n\nThe block takes the following parameters:\n\nfilter\n\nA valid pointer to the kernel that is calling the copy allocator.\n\ncommandBuffer\n\nA valid command buffer that can be used to obtain the device against which to allocate the new texture. You may also enqueue operations on the command buffer to initialize the texture on an encoder allocated in the block. You may not submit, enqueue, or wait for scheduling/completion of the command buffer.\n\nsourceTexture\n\nThe texture that is providing the source image for the filter. You may wish to use its size and pixel format for the next texture, but you are not required to do so.\n\nThe copy allocator returns a new valid texture to use as the destination for the kernel operation. If the calling function succeeds, its texture parameter will be overwritten with a pointer to this texture. If the calling function fails, then the texture will be released before the calling function returns.\n\nAllocating a new texture each time is slow (they take up to 1 ms each). You can recycle old textures (or buffers and make texture from them) and reuse the memory inside the copy allocator block.\n\nIf there is any metadata associated with the source texture, such as colorspace information, resource label, CPU cache mode, purgeable state, etc., it may need to be similarly associated with the new texture to avoid losing your metadata.\n\nIf the kernel’s clipRect property doesn’t cover the entire image, you may need to copy pixels from the source texture to the new texture, or regions of the next texture will be uninitialized. You can make a command encoder to encode work on the command buffer here, if necessary. It will be scheduled to run immediately before the kernel work. You may call any of the enqueue(), commit(), waitUntilCompleted(), or waitUntilScheduled() methods inside the copy allocator block. Make sure to call endEncoding() on the command encoder so that the command buffer has no active encoder before returning.\n\nNote\n\nThe next command placed on the command buffer after the copy allocator returns is almost assuredly going to be encoded with a compute command encoder. Creating any other type of encoder in the copy allocator will probably cost an additional 0.5 ms of both CPU and GPU time (or more!) due to a double mode switch penalty.\n\nListing 1 shows a minimal copy allocator implementation.\n\nListing 1 Minimal MPSCopyAllocator Implementation\nlet copyAllocator: MPSCopyAllocator =\n{\n    (kernel: MPSKernel, buffer: MTLCommandBuffer, texture: MTLTexture) -> MTLTexture in\n    \n    let descriptor = MTLTextureDescriptor.texture2DDescriptor(\n        pixelFormat: texture.pixelFormat,\n        width: texture.width,\n        height: texture.height,\n        mipmapped: false)\n    \n    return buffer.device.makeTexture(descriptor: descriptor)\n}\n\n\n\nSee Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, inPlaceTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationImage: MPSImage)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out of place.\nfunc sourceRegion(destinationSize: MTLSize) -> MPSRegion\nDetermines the region of the source texture that will be read for an encode operation."
  },
  {
    "title": "encode(commandBuffer:inPlaceTexture:fallbackCopyAllocator:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsunaryimagekernel/1618873-encode",
    "html": "Parameters\ncommandBuffer\n\nA valid command buffer to receive the encoded kernel.\n\ntexture\n\nA pointer to a valid texture containing the source image. On success, the image contents and possibly the texture itself will be replaced with the result image.\n\ncopyAllocator\n\nAn optional block to allocate a new texture to hold the operation results, in case in-place operation is not possible. The allocator may use a different pixel format or size than the original texture. You may enqueue operations on the provided command buffer using the provided compute command encoder to initialize the texture contents.\n\nReturn Value\n\ntrue if the operation succeeded (the texture may have been replaced with a new texture if a copy allocator was provided).\n\nfalse if the operation failed (the texture is unmodified).\n\nDiscussion\n\nThis method attempts to apply the kernel in place on a texture. In-place operation means that the same texture is used both to hold the input image and the results. Operating in-place can be an excellent way to reduce resource utilization, and save time and energy. While simple Metal kernels can not operate in place because textures can not be readable and writable at the same time, some Metal Performance Shaders kernels can operate in place because they use multi-pass algorithms. Whether a kernel can operate in-place can depend on current hardware, OS version, and the parameters and properties passed to it. You should never assume that a kernel will continue to work in place, even if you have observed it doing so before.\n\nIf the in-place operation succeeds, this method returns true. If the in-place operation fails and no copy allocator is provided, then this method returns false. Without a fallback copy allocator, in neither case is the pointer held at texture modified.\n\nFailure during in-place operation is very common and will occur inconsistently across different hardware platforms and OS versions. Without a fallback copy allocator, operating in place may require significant error handling code to accompany each call to this method, further complicating your code.\n\nYou may find it simplifies your code to provide a fallback copy allocator so that the operation can proceed reliably even when it can not complete in-place. When an in-place filter fails, the copy allocator will be invoked to create a new texture in which to write the results, allowing the filter to proceed reliably out-of-place. The original texture will be released, replaced with a pointer to the new texture and true will be returned. If the copy allocator returns an invalid texture, it is released, texture remains unmodified, and false is returned.\n\nListing 1 In-Place Operation Example\nid <MTLTexture> inPlaceTex = ...;\nMPSImageSobel *sobelFiler = [[MPSImageSobel alloc] initWithDevice: my_device];\n \n// With a fallback MPSCopyAllocator, failure should only occur in exceptional conditions such as MTLTexture allocation failure or programmer error.\n// That is, the operation is roughly as robust as the MPSCopyAllocator.\n// Depending on the quality of that, we might decide we are justified here in not checking the return value.\n[sobelFilter encodeToCommandBuffer: my_command_buffer inPlaceTexture: &inPlaceTex fallbackCopyAllocator: myAllocator];\n// inPlaceTex may be replaced!\n \n// If myAllocator was not called:\n//      inPlaceTex holds the original texture with the result pixels in it.\n// Else:\n//      1) myAllocator creates a new texture.\n//      2) The new texture pixel data is overwritten by MPSUnaryImageKernel.\n//      3) The old texture passed in *inPlaceTex is released once.\n//      4) *inPlaceTex = the new texture\n//\n// In either case, the caller should now hold one reference to the texture now held in inPlaceTex, whether it was replaced or not. Most of the time that means that nothing further needs to be done here, and you can proceed to the next image encoding operation. However, if other agents held references to the original texture, they still hold them and may need to be alerted that the texture has been replaced so that they can retain the new texture and release the old one.\n \n[sobelFilter release];  // if not ARC, clean up the MPSImageSobel object\n\nSee Also\nMethods\ntypealias MPSCopyAllocator\nA block to make a copy of a source texture for filters that can only execute out of place.\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationImage: MPSImage)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out of place.\nfunc sourceRegion(destinationSize: MTLSize) -> MPSRegion\nDetermines the region of the source texture that will be read for an encode operation."
  },
  {
    "title": "MPSImageIntegralOfSquares | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageintegralofsquares",
    "html": "Overview\n\nThe value at each position is the sum of all squared pixels in a source image rectangle, sumRect. Listing 1 shows the pseudocode used to calculate sumRect.\n\nListing 1 Pseudocode for sumRect\nsumRect.origin = filter.offset\nsumRect.size = dest_position - filter.clipRect.origin\n\n\nIf the channels in the source image are normalized, half-float or floating values, the destination image is recommended to be a 32-bit floating-point image. If the channels in the source image are integer values, it is recommended that an appropriate 32-bit integer image destination format is used.\n\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Integral Filters\nclass MPSImageIntegral\nA filter that calculates the sum of pixels over a specified region in an image."
  },
  {
    "title": "edgeMode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsunaryimagekernel/1618812-edgemode",
    "html": "Discussion\n\nMost kernel objects can read off the edge of a source image. This can happen because of a negative offset property, because the offset + clipRect.size is larger than the source image, or because the filter uses neighboring pixels in its calculations (e.g. convolution filters).\n\nThe default value is usually MPSImageEdgeMode.zero, but some kernels default to the MPSImageEdgeMode.clamp value instead if an edge mode of zero is either unsupported or undefined.\n\nSee Also\nProperties\nvar offset: MPSOffset\nThe position of the destination clip rectangle origin relative to the source buffer.\nstruct MPSOffset\nA signed coordinate with x, y, and z components.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.\nstruct MPSRegion\nA region of an image.\nenum MPSImageEdgeMode\nThe options used to control the edge behavior of an image filter when it reads outside the bounds of a source texture."
  },
  {
    "title": "MPSCNNNeuronPReLU | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronprelu",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nWhere i in [0 ... channels - 1]. That is, parameters aᵢ are learned and applied to each channel separately. Compare this to MPSCNNNeuronReLU where parameter a is shared across all channels.\n\nTopics\nInitializers\ninit(device: MTLDevice, a: UnsafePointer<Float>, count: Int)\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSCNNNeuronReLUN | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronrelun",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nThe default value of a is 1.0 and the default value of b is 6.0.\n\nTopics\nInitializers\ninit(device: MTLDevice, a: Float, b: Float)\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "MPSImageIntegral | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageintegral",
    "html": "Overview\n\nThe value at each position is the sum of all pixels in a source image rectangle, sumRect. Listing 1 shows the pseudocode used to calculate sumRect.\n\nListing 1 Pseudocode for sumRect\nsumRect.origin = filter.offset\nsumRect.size = dest_position - filter.clipRect.origin\n\n\nIf the channels in the source image are normalized, half-float or floating values, the destination image is recommended to be a 32-bit floating-point image. If the channels in the source image are integer values, it is recommended that an appropriate 32-bit integer image destination format is used.\n\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Integral Filters\nclass MPSImageIntegralOfSquares\nA filter that calculates the sum of squared pixels over a specified region in an image."
  },
  {
    "title": "MPSCNNNeuronLinear | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronlinear",
    "html": "Overview\n\nFor each pixel in an image, the filter applies the following function:\n\nTopics\nInitializers\ninit(device: MTLDevice, a: Float, b: Float)\nInitializes a linear neuron filter.\nDeprecated\nRelationships\nInherits From\nMPSCNNNeuron\nSee Also\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel."
  },
  {
    "title": "secondaryEdgeMode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618848-secondaryedgemode",
    "html": "Discussion\n\nMost kernel objects can read off the edge of a source image. This can happen because of a negative offset property, because the offset + clipRect.size is larger than the source image, or because the filter uses neighboring pixels in its calculations (e.g. convolution filters).\n\nThe default value is usually MPSImageEdgeMode.zero, but some kernels default to the MPSImageEdgeMode.clamp value instead if an edge mode of zero is either unsupported or undefined.\n\nSee Also\nProperties\nvar primaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the primary source buffer.\nvar secondaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the secondary source buffer.\nvar primaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the primary source image.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten."
  },
  {
    "title": "MPSImageTranspose | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagetranspose",
    "html": "Overview\n\nAn MPSImageTranspose filter applies a matrix transposition to the source image by exchanging its rows with its columns.\n\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Manipulation Filters\nclass MPSImageConversion\nA filter that performs a conversion of color space, alpha, or pixel format.\nclass MPSImageScale\nA filter that resizes and changes the aspect ratio of an image.\nclass MPSImageLanczosScale\nA filter that resizes and changes the aspect ratio of an image using Lanczos resampling.\nclass MPSImageBilinearScale\nA filter that resizes and changes the aspect ratio of an image using Bilinear resampling."
  },
  {
    "title": "MPSCNNBinaryConvolution | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbinaryconvolution",
    "html": "Overview\n\nThe MPSCNNBinaryConvolution optionally first binarizes the input image and then convolves the result with a set of binary-valued filters, each producing one feature map in the output image (which is a normal image).\n\nThe output is computed as follows:\n\nwhere the sum over dx,dy is over the spatial filter kernel window defined by kernelWidth and kernelHeight, sum over f is over the input feature channel indices within group, B contains the binary weights, interpreted as {-1, 1} or {0, 1} and scale[c] is the outputScaleTerms array and bias is the outputBiasTerms array. Above i is the image index in batch the sum over input channels f runs through the group indices. The convolution operator ⊗ is defined by MPSCNNBinaryConvolutionType passed in at initialization time of the filter:\n\nMPSCNNBinaryConvolutionType.binaryWeights\n\nThe input image is not binarized at all and the convolution is computed interpreting the weights as [0, 1] -> {-1, 1} with the given scaling terms.\n\nMPSCNNBinaryConvolutionType.XNOR\n\nThe convolution is computed by first binarizing the input image using the sign function bin(x) = x < 0 ? -1 : 1 and the convolution multiplication is done with the XNOR-operator:\n\n!(x ^ y) = delta_xy = { (x == y) ? 1 : 0 }\n\nand scaled according to the optional scaling operations.\n\nNote that we output the values of the bitwise convolutions to interval {-1, 1}, which means that the output of the XNOR-operator is scaled implicitly as follows:\n\nr = 2 * ( !(x ^ y) ) - 1 = { -1, 1 }\n\nThis means that for a dot-product of two 32-bit words the result is:\n\nr = 2 * popcount(!(x ^ y) ) - 32 = 32 - 2 * popcount( x ^ y ) = { -32, -30, ..., 30, 32 }\n\nMPSCNNBinaryConvolutionType.AND\n\nThe convolution is computed by first binarizing the input image using the sign function bin(x) = x < 0 ? -1 : 1 and the convolution multiplication is done with the AND-operator:\n\n(x & y) = delta_xy * delta_x1 = { (x == y == 1) ? 1 : 0 }\n\nand scaled according to the optional scaling operations.\n\nNote that we output the values of the AND-operation is assumed to lie in {0, 1} interval and hence no more implicit scaling takes place.\n\nThis means that for a dot-product of two 32-bit words the result is:\n\nr = popcount(x & y) = { 0, ..., 31, 32 }\n\nThe input data can be pre-offset and scaled by providing the inputBiasTerms and inputScaleTerms parameters for the initialization functions and this can be used for example to accomplish batch normalization of the data. The scaling of input values happens before possible beta-image computation.\n\nThe parameter beta above is an optional image which is used to compute scaling factors for each spatial position and image index. For the XNOR-Net based networks this is computed as follows:\n\nwhere (dx,dy) are summed over the convolution filter window.\n\nwhere in is the original input image (in full precision) and Nc is the number of input channels in the input image. Parameter beta is not passed as input and to enable beta-scaling the user can provide MPSCNNBinaryConvolutionFlags.useBetaScaling in the flags parameter in the initialization functions.\n\nFinally the normal activation neuron is applied and the result is written to the output image.\n\nNote\n\nMPSCNNBinaryConvolution does not currently support groups greater than 1.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, convolutionData: MPSCNNConvolutionDataSource, outputBiasTerms: UnsafePointer<Float>?, outputScaleTerms: UnsafePointer<Float>?, inputBiasTerms: UnsafePointer<Float>?, inputScaleTerms: UnsafePointer<Float>?, type: MPSCNNBinaryConvolutionType, flags: MPSCNNBinaryConvolutionFlags)\nInitializes a binary convolution kernel.\ninit(device: MTLDevice, convolutionData: MPSCNNConvolutionDataSource, scaleValue: Float, type: MPSCNNBinaryConvolutionType, flags: MPSCNNBinaryConvolutionFlags)\nInitializes a binary convolution kernel.\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\nenum MPSCNNBinaryConvolutionType\nOptions that defines what operations are used to perform binary convolution.\nenum MPSCNNBinaryConvolutionFlags\nOptions used to control binary convolution kernels.\nInstance Properties\nvar inputFeatureChannels: Int\nvar outputFeatureChannels: Int\nRelationships\nInherits From\nMPSCNNKernel\nSee Also\nConvolution Layers\nclass MPSCNNConvolution\nA convolution kernel that convolves the input image with a set of filters, with each producing one feature map in the output image.\nclass MPSCNNDepthWiseConvolutionDescriptor\nA description of a convolution object that does depthwise convolution.\nclass MPSCNNSubPixelConvolutionDescriptor\nA description of a convolution object that does subpixel upsampling and reshaping.\nclass MPSCNNConvolutionTranspose\nA transposed convolution kernel.\nclass MPSCNNConvolutionGradient\nA gradient convolution kernel.\nclass MPSCNNConvolutionGradientState\nAn object that exposes a gradient convolution kernel's gradient with respect to weights and biases.\nprotocol MPSImageSizeEncodingState\nA protocol for objects that contain information about an image size elsewhere in the graph.\nclass MPSCNNConvolutionWeightsAndBiasesState\nA class that stores weights and biases."
  },
  {
    "title": "MPSCNNDivide | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndivide",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNArithmetic\nSee Also\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSImagePyramid | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagepyramid",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice)\nInitializes a downwards 5-tap image pyramid with the default filter kernel and device.\ninit(device: MTLDevice, centerWeight: Float)\nInitialize a downwards 5-tap image pyramid with a central weight parameter and device.\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, weights: UnsafePointer<Float>)\nInitialize a downwards n-tap image pyramid with a custom filter kernel and device.\nProperties\nvar kernelWidth: Int\nThe width of the filter window. Must be an odd number.\nvar kernelHeight: Int\nThe height of the filter window. Must be an odd number.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid."
  },
  {
    "title": "MPSImageSobel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagesobel",
    "html": "Overview\n\nWhen the color model (e.g. RGB, two-channel, grayscale, etc.) of the source and destination textures match, the filter is applied to each color channel separately. If the destination is single-channel (i.e. monochrome) but the source is multi-channel, the pixel values are converted to grayscale before applying the Sobel operator by using the linear gray color transform vector v shown in the code listing below.\n\nLuminance = v[0] * pixel.x + v[1] * pixel.y + v[2] * pixel.z\n\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice)\nInitializes a Sobel filter on a given device using the default color transform.\ninit(device: MTLDevice, linearGrayColorTransform: UnsafePointer<Float>)\nInitializes a Sobel filter on a given device using a specific color transform.\nProperties\nvar colorTransform: UnsafePointer<Float>\nThe color transform used to initialize the Sobel filter.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSImageLaplacianPyramidSubtract | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagelaplacianpyramidsubtract",
    "html": "Relationships\nInherits From\nMPSImageLaplacianPyramid\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSImageLaplacianPyramid | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagelaplacianpyramid",
    "html": "Topics\nInstance Properties\nvar laplacianBias: Float\nvar laplacianScale: Float\nRelationships\nInherits From\nMPSImagePyramid\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSImageLaplacianPyramidAdd | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagelaplacianpyramidadd",
    "html": "Relationships\nInherits From\nMPSImageLaplacianPyramid\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSImageTent | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagetent",
    "html": "Overview\n\nThe kernel elements of the filter form a tent shape with increasing sides, for example:\n\nLike a box filter, this arrangement allows for much faster algorithms, especially for larger blur radii but with a more pleasing appearance.\n\nThe tent blur is a separable filter and the Metal Performance Shaders framework will act accordingly to give the best performance for multi-dimensional blurs.\n\nNote\n\nThe box filter, while fast, may yield square-ish looking blur effects. However, multiple passes of the box filter tend to smooth out with each additional pass. For example, two 3-wide box blurs produces the same effective convolution as a 5-wide tent blur.\n\nIn effect, addition passes tend to approximate a Gaussian line shape.\n\nRelationships\nInherits From\nMPSImageBox\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSCNNLossNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlossnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, lossDescriptor: MPSCNNLossDescriptor)\nInstance Properties\nvar inputLabels: MPSNNLabelsNode\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nLoss Layer Nodes\nclass MPSCNNYOLOLossNode\nA representation of a YOLO loss kernel.\nclass MPSNNLabelsNode\nA placeholder node denoting the per-element weight buffer used by loss and gradient loss kernels."
  },
  {
    "title": "MPSImageGaussianPyramid | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagegaussianpyramid",
    "html": "Overview\n\nThe Gaussian image pyramid kernel is enqueued as an in-place operation using the encode(commandBuffer:inPlaceTexture:fallbackCopyAllocator:) method. All mip-map levels (after level 1) present in the provided image are filled using the provided filter kernel. The fallbackCopyAllocator parameter is not used. The Gaussian image pyramid kernel ignores the clipRect and offset properties, and fills the entirety of the mip-map levels. Recall the size of the nth mip-map level as:\n\nw_n = max(1, floor(w_0 / 2^n))\n\nh_n = max(1, floor(h_0 / 2^n))\n\nWhere w_0 and h_0 are the width and height of the 0th level, respectively (i.e. the image dimensions themselves).\n\nThe Gaussian image pyramid is constructed as follows:\n\nFirst, the 0th level mip-map of the input image is filtered with the specified convolution kernel. The default convolution filter kernel is k = ww^T, where w = [1/16, 1/4, 3/8, 1/4, 1/16 ]^T. You may also modify this kernel with a centerWeight parameter of a resulting in k = ww^T, where w = [(1/4 - a/2), 1/4, a, 1/4, (1/4 - a/2) ]^T, or you may provide a completely custom kernel.\n\nAfterwards, the image is down-sampled by removing all odd rows and columns, which defines the next level in the Gaussian image pyramid.\n\nThis procedure is continued until every mip-map level present in the image is filled with all the pyramid levels.\n\nNote\n\nMake sure your chosen texture type is compatible with mip-mapping and also supports texture views (i.e. the texture’s usage includes the pixelFormatView option).\n\nRelationships\nInherits From\nMPSImagePyramid\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSNNTrainableNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnntrainablenode",
    "html": "Topics\nInstance Properties\nvar trainingStyle: MPSNNTrainingStyle\n\nRequired\n\nRelationships\nInherits From\nNSObjectProtocol\nConforming Types\nMPSCNNBatchNormalizationGradientNode\nMPSCNNBatchNormalizationNode\nMPSCNNConvolutionGradientNode\nMPSCNNConvolutionNode\nMPSCNNGroupNormalizationGradientNode\nMPSCNNGroupNormalizationNode\nMPSCNNInstanceNormalizationGradientNode\nMPSCNNInstanceNormalizationNode"
  },
  {
    "title": "MPSCNNYOLOLossNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnyololossnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, lossDescriptor: MPSCNNYOLOLossDescriptor)\nInstance Properties\nvar inputLabels: MPSNNLabelsNode\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nLoss Layer Nodes\nclass MPSCNNLossNode\nA representation of a loss kernel.\nclass MPSNNLabelsNode\nA placeholder node denoting the per-element weight buffer used by loss and gradient loss kernels."
  },
  {
    "title": "MPSImageLaplacian | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagelaplacian",
    "html": "Overview\n\nThis filter uses an optimized convolution filter with a 3x3 kernel with the following weights:\n\nNote\n\nThe optimized convolution filter used by the MPSImageLaplacian class could also be created by initializing an MPSImageConvolution object with kernelWidth=3, kernelHeight=3, and the weights specified above.\n\nTopics\nProperties\nvar bias: Float\nThe value added to a convolved pixel before it is converted back to its intended storage format.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSNNLabelsNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnlabelsnode",
    "html": "Relationships\nInherits From\nMPSNNStateNode\nSee Also\nLoss Layer Nodes\nclass MPSCNNLossNode\nA representation of a loss kernel.\nclass MPSCNNYOLOLossNode\nA representation of a YOLO loss kernel."
  },
  {
    "title": "MPSNNGradientFilterNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngradientfilternode",
    "html": "Relationships\nInherits From\nMPSNNFilterNode\nSee Also\nFilter Node Base Classes\nclass MPSNNFilterNode\nA placeholder node denoting a neural network filter stage."
  },
  {
    "title": "MPSImageMedian | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagemedian",
    "html": "Overview\n\nAn MPSImageMedian filter finds the median color value for each channel within a kernelDiameter * kernelDiameter window surrounding the pixel of interest. It is a common means of noise reduction and also as a smoothing filter with edge preserving qualities.\n\nNote\n\nThe MPSImageMedian filter supports only images with 8 or less bits per channel.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, kernelDiameter: Int)\nInitializes a filter for a particular kernel size and device.\nclass func maxKernelDiameter() -> Int\nQueries the maximum diameter, in pixels, of the filter window supported by the median filter.\nclass func minKernelDiameter() -> Int\nQueries the minimum diameter, in pixels, of the filter window supported by the median filter.\nProperties\nvar kernelDiameter: Int\nThe diameter, in pixels, of the filter window.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSImageErode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageerode",
    "html": "Overview\n\nAn MPSImageErode behaves like the MPSImageAreaMin filter, except that Metal calculates the intensity at each position relative to a different value before determining which is the maximum pixel value, allowing for shaped, nonrectangular morphological probes.\n\nThe code example below shows pseudocode for the calculation that returns each pixel value:\n\nfor each pixel in the filter window\n    value =  pixel[filterY][filterX] + filter[filterY*filter_width+filterX]\n    if( value < bestValue ){\n        result = value\n        bestValue = value\n    }\n\n\nThe definition of the MPSImageErode filter is different from its vImage counterpart (MPSImageErode_filter_value = 1.0f-vImageErode_filter_value.). This allows MPSImageDilate and MPSImageErode to use the same filter, making open and close operators easier to write.\n\nA filter that contains all zeros is identical to an MPSImageAreaMin filter. Metal handles the center filter element as 0 to avoid causing a general lightening of the image, and it handles the edgeMode property as MPSImageEdgeMode.clamp for this filter.\n\nRelationships\nInherits From\nMPSImageDilate\nSee Also\nMorphological Image Filters\nclass MPSImageAreaMax\nA filter that finds the maximum pixel value in a rectangular region centered around each pixel in the source image.\nclass MPSImageDilate\nA filter that finds the maximum pixel value in a rectangular region by applying a dilation function.\nclass MPSImageAreaMin\nA filter that finds the minimum pixel value in a rectangular region centered around each pixel in the source image."
  },
  {
    "title": "MPSImageConvolution | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageconvolution",
    "html": "Overview\n\nFilter width and height can be either 3, 5, 7 or 9. If there are multiple channels in the source image, each channel is processed independently.\n\nA separable convolution filter may perform better when done in two passes. . A convolution filter is separable if the ratio of filter values between all rows is constant over the whole row. For example, this edge detection filter:\n\nCan instead be separated into the product of two vectors, like so:\n\nAnd consequently can be done as two, one-dimensional convolution passes back to back on the same image. In this way, the number of multiplies (ignoring the fact that we could skip zeros here) is reduced from 3*3=9 to 3+3=6. There are similar savings for addition. For large filters, the savings can be profound.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, weights: UnsafePointer<Float>)\nInitializes a convolution filter.\nProperties\nvar kernelHeight: Int\nThe height of the filter window. Must be an odd number.\nvar kernelWidth: Int\nThe width of the filter window. Must be an odd number.\nvar bias: Float\nThe value added to a convolved pixel before it is converted back to its intended storage format.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nConvolution Image Filters\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "MPSImageTransformProvider | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagetransformprovider",
    "html": "Topics\nInstance Methods\nfunc transform(forSourceImage: MPSImage, handle: MPSHandle?) -> MPSScaleTransform\n\nRequired\n\nRelationships\nInherits From\nNSObjectProtocol\nNSSecureCoding\nSee Also\nResampling Nodes\nclass MPSNNBilinearScaleNode\nA representation of a bilinear resampling filter.\nclass MPSNNLanczosScaleNode\nA representation of a Lanczos resampling filter.\nclass MPSNNScaleNode\nAbstract node representing an image resampling filter."
  },
  {
    "title": "MPSImageDilate | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedilate",
    "html": "Overview\n\nAn MPSImageDilate filter behaves like the MPSImageAreaMax filter, except Metal calculates the intensity at each position relative to a different value before determining which is the maximum pixel value, allowing for shaped, nonrectangular morphological probes.\n\nThe code example below shows pseudocode for the calculation that returns each pixel value:\n\nfor each pixel in the filter window\n    value = pixel[filterY][filterX] - filter[filterY*filter_width+filterX]\n    if( value > bestValue ){\n        result = value\n        bestValue = value\n    }\n\n\nA filter that contains all zeros is identical to an MPSImageAreaMax filter. Metal handles the center filter element as 0 to avoid causing a general darkening of the image, and it handles the edgeMode property as MPSImageEdgeMode.clamp for this filter.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int, values: UnsafePointer<Float>)\nInitializes the kernel with a specified width, height, and weight values.\nProperties\nvar kernelHeight: Int\nThe height of the filter window. which must be an odd number.\nvar kernelWidth: Int\nThe width of the filter window which must be an odd number.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nMorphological Image Filters\nclass MPSImageAreaMax\nA filter that finds the maximum pixel value in a rectangular region centered around each pixel in the source image.\nclass MPSImageAreaMin\nA filter that finds the minimum pixel value in a rectangular region centered around each pixel in the source image.\nclass MPSImageErode\nA filter that finds the minimum pixel value in a rectangular region by applying an erosion function."
  },
  {
    "title": "MPSImageAreaMin | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageareamin",
    "html": "Overview\n\nAn MPSImageAreaMin filter has the same methods and properties as the MPSImageAreaMax class.\n\nIf there are multiple channels in the source image, each channel is processed independently. The edgeMode property value is assumed to always be MPSImageEdgeMode.clamp for this filter.\n\nRelationships\nInherits From\nMPSImageAreaMax\nSee Also\nMorphological Image Filters\nclass MPSImageAreaMax\nA filter that finds the maximum pixel value in a rectangular region centered around each pixel in the source image.\nclass MPSImageDilate\nA filter that finds the maximum pixel value in a rectangular region by applying a dilation function.\nclass MPSImageErode\nA filter that finds the minimum pixel value in a rectangular region by applying an erosion function."
  },
  {
    "title": "MPSImageAreaMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageareamax",
    "html": "Overview\n\nIf there are multiple channels in the source image, each channel is processed independently. The edgeMode property value is assumed to always be MPSImageEdgeMode.clamp for this filter.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, kernelWidth: Int, kernelHeight: Int)\nInitializes the kernel with a specified width and height.\nProperties\nvar kernelHeight: Int\nThe height of the filter window. Must be an odd number.\nvar kernelWidth: Int\nThe width of the filter window. Must be an odd number.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nMorphological Image Filters\nclass MPSImageDilate\nA filter that finds the maximum pixel value in a rectangular region by applying a dilation function.\nclass MPSImageAreaMin\nA filter that finds the minimum pixel value in a rectangular region centered around each pixel in the source image.\nclass MPSImageErode\nA filter that finds the minimum pixel value in a rectangular region by applying an erosion function."
  },
  {
    "title": "MPSNNLanczosScaleNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnlanczosscalenode",
    "html": "Relationships\nInherits From\nMPSNNScaleNode\nSee Also\nResampling Nodes\nclass MPSNNBilinearScaleNode\nA representation of a bilinear resampling filter.\nclass MPSNNScaleNode\nAbstract node representing an image resampling filter.\nprotocol MPSImageTransformProvider\nA general interface for objects that provide image resampling."
  },
  {
    "title": "MPSCNNUpsamplingNearestGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsamplingnearestgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, scaleFactorX: Double, scaleFactorY: Double)\nInstance Properties\nvar scaleFactorX: Double\nvar scaleFactorY: Double\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nUpsampling Layer Nodes\nclass MPSCNNUpsamplingBilinearNode\nA representation of a bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearestNode\nA representation of a nearest spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradientNode\nA representation of a gradient bilinear spatial upsampling filter."
  },
  {
    "title": "MPSNNBilinearScaleNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnbilinearscalenode",
    "html": "Relationships\nInherits From\nMPSNNScaleNode\nSee Also\nResampling Nodes\nclass MPSNNLanczosScaleNode\nA representation of a Lanczos resampling filter.\nclass MPSNNScaleNode\nAbstract node representing an image resampling filter.\nprotocol MPSImageTransformProvider\nA general interface for objects that provide image resampling."
  },
  {
    "title": "MPSNNScaleNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnscalenode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, outputSize: MTLSize)\ninit(source: MPSNNImageNode, transformProvider: MPSImageTransformProvider?, outputSize: MTLSize)\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nResampling Nodes\nclass MPSNNBilinearScaleNode\nA representation of a bilinear resampling filter.\nclass MPSNNLanczosScaleNode\nA representation of a Lanczos resampling filter.\nprotocol MPSImageTransformProvider\nA general interface for objects that provide image resampling."
  },
  {
    "title": "MPSCNNSpatialNormalizationGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnspatialnormalizationgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, kernelSize: Int)\nInstance Properties\nvar alpha: Float\nvar beta: Float\nvar delta: Float\nvar kernelHeight: Int\nvar kernelWidth: Int\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNUpsamplingBilinearGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsamplingbilineargradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, scaleFactorX: Double, scaleFactorY: Double)\nInstance Properties\nvar scaleFactorX: Double\nvar scaleFactorY: Double\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nUpsampling Layer Nodes\nclass MPSCNNUpsamplingBilinearNode\nA representation of a bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearestNode\nA representation of a nearest spatial upsampling filter.\nclass MPSCNNUpsamplingNearestGradientNode\nA representation of a gradient nearest spatial upsampling filter."
  },
  {
    "title": "MPSCNNUpsamplingNearestNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsamplingnearestnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, integerScaleFactorX: Int, integerScaleFactorY: Int)\nInstance Properties\nvar scaleFactorX: Double\nvar scaleFactorY: Double\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nUpsampling Layer Nodes\nclass MPSCNNUpsamplingBilinearNode\nA representation of a bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradientNode\nA representation of a gradient bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearestGradientNode\nA representation of a gradient nearest spatial upsampling filter."
  },
  {
    "title": "MPSCNNInstanceNormalizationDataSource | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationdatasource",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder)\n\nRequired\n\nInstance Properties\nvar numberOfFeatureChannels: Int\n\nRequired\n\nType Properties\nstatic var supportsSecureCoding: Bool\n\nRequired\n\nInstance Methods\nfunc beta() -> UnsafeMutablePointer<Float>?\n\nRequired\n\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(with: NSCoder)\nfunc epsilon() -> Float\nfunc gamma() -> UnsafeMutablePointer<Float>?\n\nRequired\n\nfunc label() -> String?\n\nRequired\n\nfunc load() -> Bool\nfunc purge()\nfunc updateGammaAndBeta(with: MTLCommandBuffer, instanceNormalizationStateBatch: [MPSCNNInstanceNormalizationGradientState]) -> MPSCNNNormalizationGammaAndBetaState?\nfunc updateGammaAndBeta(withInstanceNormalizationStateBatch: [MPSCNNInstanceNormalizationGradientState]) -> Bool\nRelationships\nInherits From\nNSCopying\nNSObjectProtocol\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNUpsamplingBilinearNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnupsamplingbilinearnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, integerScaleFactorX: Int, integerScaleFactorY: Int)\ninit(source: MPSNNImageNode, integerScaleFactorX: Int, integerScaleFactorY: Int, alignCorners: Bool)\nInstance Properties\nvar scaleFactorX: Double\nvar scaleFactorY: Double\nvar alignCorners: Bool\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nUpsampling Layer Nodes\nclass MPSCNNUpsamplingNearestNode\nA representation of a nearest spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradientNode\nA representation of a gradient bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearestGradientNode\nA representation of a gradient nearest spatial upsampling filter."
  },
  {
    "title": "MPSCNNNormalizationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnnormalizationnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\nInstance Properties\nvar alpha: Float\nvar beta: Float\nvar delta: Float\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel."
  },
  {
    "title": "MPSCNNLocalContrastNormalizationGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalizationgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, kernelWidth: Int, kernelHeight: Int)\nInstance Properties\nvar alpha: Float\nvar beta: Float\nvar delta: Float\nvar kernelHeight: Int\nvar kernelWidth: Int\nvar p0: Float\nvar pm: Float\nvar ps: Float\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNInstanceNormalizationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, dataSource: MPSCNNInstanceNormalizationDataSource)\nInstance Properties\nvar trainingStyle: MPSNNTrainingStyle\nRelationships\nInherits From\nMPSNNFilterNode\nConforms To\nMPSNNTrainableNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNInstanceNormalizationGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnninstancenormalizationgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\nRelationships\nInherits From\nMPSNNGradientFilterNode\nConforms To\nMPSNNTrainableNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSImageAdd | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageadd",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageArithmetic\nSee Also\nImage Arithmetic Filters\nclass MPSImageSubtract\nA filter that returns the element-wise difference of its two input images.\nclass MPSImageMultiply\nA filter that returns the element-wise product of its two input images.\nclass MPSImageDivide\nA filter that returns the element-wise quotient of its two input images.\nclass MPSImageArithmetic\nBase class for basic arithmetic nodes"
  },
  {
    "title": "MPSImageReduceColumnMax | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereducecolumnmax",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSImageReduceUnary\nSee Also\nImage Reduction Filters\nclass MPSImageReduceRowMax\nA filter that returns the maximum value for each row in an image.\nclass MPSImageReduceRowMin\nA filter that returns the minimum value for each row in an image.\nclass MPSImageReduceRowSum\nA filter that returns the sum of all values for a row in an image.\nclass MPSImageReduceRowMean\nA filter that returns the mean value for each row in an image.\nclass MPSImageReduceColumnMin\nA filter that returns the minimum value for each column in an image.\nclass MPSImageReduceColumnSum\nA filter that returns the sum of all values for a column in an image.\nclass MPSImageReduceColumnMean\nA filter that returns the mean value for each column in an image.\nclass MPSImageReduceUnary\nThe base class for reduction filters that take a single source as input."
  },
  {
    "title": "MPSImageScale | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagescale",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar scaleTransform: UnsafePointer<MPSScaleTransform>?\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Manipulation Filters\nclass MPSImageConversion\nA filter that performs a conversion of color space, alpha, or pixel format.\nclass MPSImageLanczosScale\nA filter that resizes and changes the aspect ratio of an image using Lanczos resampling.\nclass MPSImageBilinearScale\nA filter that resizes and changes the aspect ratio of an image using Bilinear resampling.\nclass MPSImageTranspose\nA filter that transposes an image."
  },
  {
    "title": "MPSImageThresholdToZero | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtozero",
    "html": "Overview\n\nAn MPSImageThresholdToZero filter converts a single channel image to a binary image. If the input image is not a single channel image, the function first converts the input image into a single channel luminance image using the linear gray color transform, and then it applies the threshold.\n\nListing 1 shows the threshold to zero function.\n\nListing 1 Threshold to zero function\ndestinationPixelValue = sourcePixelValue > thresholdValue ? sourcePixelValue : 0\n\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, thresholdValue: Float, linearGrayColorTransform: UnsafePointer<Float>?)\nInitializes the kernel.\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter.\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Threshold Filters\nclass MPSImageThresholdBinary\nA filter that returns a specified value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdBinaryInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or a specified value otherwise.\nclass MPSImageThresholdToZeroInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or the original value otherwise.\nclass MPSImageThresholdTruncate\nA filter that clamps the return value to an upper specified value."
  },
  {
    "title": "MPSImageConversion | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageconversion",
    "html": "Overview\n\nAn MPSImageConversion filter allows you to change the alpha encoding or color space of an image. For example, you can convert an image with a premultiplied alpha to non-premultiplied, or change the color space from one variant to another.\n\nAs with all Metal Performance Shaders filters, the conversion filter allows for source and destination textures with different pixel formats and, in that case, will convert the source texture's format to the destination texture's format. See Supported Pixel Formats for Image Kernels for a list of supported pixel formats.\n\nListing 1 shows how you can create an image conversion filter to map the color intensity from the sRGB color space to a linear gamma curve.\n\nListing 1 Mapping color intensity from the sRGB color space to a linear gamma curve.\nguard let srcColorSpace = CGColorSpace(name: CGColorSpace.sRGB),\n    let dstColorSpace = CGColorSpace(name: CGColorSpace.linearSRGB),\n    let device = MTLCreateSystemDefaultDevice() else {\n        return\n}\n     \nlet conversionInfo = CGColorConversionInfo(src: srcColorSpace,\n                                           dst: dstColorSpace)\n     \nlet conversion = MPSImageConversion(device: device,\n                                    srcAlpha: .alphaIsOne,\n                                    destAlpha: .alphaIsOne,\n                                    backgroundColor: nil,\n                                    conversionInfo: conversionInfo)\n\n\nTopics\nMethods\ninit(device: MTLDevice, srcAlpha: MPSAlphaType, destAlpha: MPSAlphaType, backgroundColor: UnsafeMutablePointer<CGFloat>?, conversionInfo: CGColorConversionInfo?)\nInitializes a filter that can convert texture color space, alpha, and pixel format.\nenum MPSAlphaType\nPremultiplication description for the color channels of an image.\nProperties\nvar sourceAlpha: MPSAlphaType\nPremultiplication description for the source texture.\nvar destinationAlpha: MPSAlphaType\nPremultiplication description for the destination texture.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Manipulation Filters\nclass MPSImageScale\nA filter that resizes and changes the aspect ratio of an image.\nclass MPSImageLanczosScale\nA filter that resizes and changes the aspect ratio of an image using Lanczos resampling.\nclass MPSImageBilinearScale\nA filter that resizes and changes the aspect ratio of an image using Bilinear resampling.\nclass MPSImageTranspose\nA filter that transposes an image."
  },
  {
    "title": "MPSImageThresholdBinaryInverse | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdbinaryinverse",
    "html": "Overview\n\nAn MPSImageThresholdBinaryInverse function converts a single channel image to a binary image. If the input image is not a single channel image, the function first converts the input image into a single channel luminance image using the linear gray color transform, and then it applies the threshold.Listing 1 shows the threshold binary inverse function.\n\nListing 1 Threshold binary inverse function\ndestinationPixelValue = sourcePixelValue > thresholdValue ? 0 : maximumValue\n\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, thresholdValue: Float, maximumValue: Float, linearGrayColorTransform: UnsafePointer<Float>?)\nInitializes the kernel.\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter.\nvar maximumValue: Float\nThe maximum value used to initialize the threshold filter.\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Threshold Filters\nclass MPSImageThresholdBinary\nA filter that returns a specified value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdToZero\nA filter that returns the original value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdToZeroInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or the original value otherwise.\nclass MPSImageThresholdTruncate\nA filter that clamps the return value to an upper specified value."
  },
  {
    "title": "MPSImageThresholdToZeroInverse | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtozeroinverse",
    "html": "Overview\n\nAn MPSImageThresholdToZeroInverse filter converts a single channel image to a binary image. If the input image is not a single channel image, the function first converts the input image into a single channel luminance image using the linear gray color transform, and then it applies the threshold.\n\nListing 1 shows the threshold to zero inverse function.\n\nListing 1 Threshold to zero inverse function\ndestinationPixelValue = sourcePixelValue > thresholdValue ? 0 : sourcePixelValue\n\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nNew Methods\ninit(device: MTLDevice, thresholdValue: Float, linearGrayColorTransform: UnsafePointer<Float>?)\nInitializes the kernel.\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter.\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Threshold Filters\nclass MPSImageThresholdBinary\nA filter that returns a specified value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdBinaryInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or a specified value otherwise.\nclass MPSImageThresholdToZero\nA filter that returns the original value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdTruncate\nA filter that clamps the return value to an upper specified value."
  },
  {
    "title": "MPSImageThresholdTruncate | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagethresholdtruncate",
    "html": "Overview\n\nAn MPSImageThresholdTruncate filter converts a single channel image to a binary image. If the input image is not a single channel image, the function first converts the input image into a single channel luminance image using the linear gray color transform, and then it applies the threshold.\n\nListing 1 shows the threshold truncate function.\n\nListing 1 Threshold truncate function\ndestinationPixelValue = sourcePixelValue > thresholdValue ? thresholdValue : sourcePixelValue\n\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, thresholdValue: Float, linearGrayColorTransform: UnsafePointer<Float>?)\nInitializes the kernel.\nProperties\nvar thresholdValue: Float\nThe threshold value used to initialize the threshold filter.\nvar transform: UnsafePointer<Float>\nThe color transform used to initialize the threshold filter.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nImage Threshold Filters\nclass MPSImageThresholdBinary\nA filter that returns a specified value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdBinaryInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or a specified value otherwise.\nclass MPSImageThresholdToZero\nA filter that returns the original value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdToZeroInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or the original value otherwise."
  },
  {
    "title": "primaryEdgeMode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618782-primaryedgemode",
    "html": "Discussion\n\nMost kernel objects can read off the edge of a source image. This can happen because of a negative offset property, because the offset + clipRect.size is larger than the source image, or because the filter uses neighboring pixels in its calculations (e.g. convolution filters).\n\nThe default value is usually MPSImageEdgeMode.zero, but some kernels default to the MPSImageEdgeMode.clamp value instead if an edge mode of zero is either unsupported or undefined.\n\nSee Also\nProperties\nvar primaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the primary source buffer.\nvar secondaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the secondary source buffer.\nvar secondaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the secondary source image.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten."
  },
  {
    "title": "readCount | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporaryimage/2097546-readcount",
    "html": "Discussion\n\nTemporary images must release their underlying textures for reuse immediately after last use. In order to facilitate prompt and convenient memory recycling, each time a MPSTemporaryImage object is read by an encode method of an MPSCNNKernel object, the value of its readCount property is automatically decremented. When the value of readCount reaches 0, the underlying texture is automatically made available and reusable to the framework for its own needs (and for other MPSTemporaryImage objects prior to return from the encode method). The contents of the underlying texture become undefined at this time.\n\nBy default, the value of readCount is initialized to 1, indicating a temporary image that may be overwritten any number of times, but read only once.\n\nYou may change the value of readCount as desired to allow MPSCNNKernel objects to read the MPSTemporaryImage object additional times. However, it is an error to change the value of readCount once it reaches 0 (it is also an error to read or write to a temporary image with a readCount value of 0). You may set the value of readCount to 0 yourself to cause the underlying texture to be returned to the framework. Writing to a temporary image does not adjust the value of readCount.\n\nThe Metal API Validation layer will assert if a temporary image is deallocated with a non-zero readCount value to help identify cases when resources are not returned promptly."
  },
  {
    "title": "featureChannels | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648918-featurechannels",
    "html": "Discussion\n\nThe default value is 1.\n\nSee Also\nProperties\nvar width: Int\nThe width of the image.\nvar height: Int\nThe height of the image.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar pixelFormat: MTLPixelFormat\nThe pixel format for the underlying texture.\nvar channelFormat: MPSImageFeatureChannelFormat\nThe storage format to use for each channel in the image.\nvar cpuCacheMode: MTLCPUCacheMode\nThe CPU cache mode of the underlying texture.\nvar storageMode: MTLStorageMode\nThe storage mode of underlying texture.\nvar usage: MTLTextureUsage\nOptions to specify the intended usage of the underlying texture."
  },
  {
    "title": "MPSCNNBatchNormalizationDataSource | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationdatasource",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder)\n\nRequired\n\nType Properties\nstatic var supportsSecureCoding: Bool\n\nRequired\n\nInstance Methods\nfunc beta() -> UnsafeMutablePointer<Float>?\n\nRequired\n\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(with: NSCoder)\nfunc epsilon() -> Float\nfunc gamma() -> UnsafeMutablePointer<Float>?\n\nRequired\n\nfunc label() -> String?\n\nRequired\n\nfunc load() -> Bool\n\nRequired\n\nfunc mean() -> UnsafeMutablePointer<Float>?\n\nRequired\n\nfunc numberOfFeatureChannels() -> Int\n\nRequired\n\nfunc purge()\n\nRequired\n\nfunc updateGammaAndBeta(with: MPSCNNBatchNormalizationState) -> Bool\nfunc updateGammaAndBeta(with: MTLCommandBuffer, batchNormalizationState: MPSCNNBatchNormalizationState) -> MPSCNNNormalizationGammaAndBetaState?\nfunc updateMeanAndVariance(with: MPSCNNBatchNormalizationState) -> Bool\nfunc updateMeanAndVariance(with: MTLCommandBuffer, batchNormalizationState: MPSCNNBatchNormalizationState) -> MPSCNNNormalizationMeanAndVarianceState?\nfunc variance() -> UnsafeMutablePointer<Float>?\n\nRequired\n\nRelationships\nInherits From\nNSCopying\nNSObjectProtocol\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNSpatialNormalizationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnspatialnormalizationnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, kernelSize: Int)\nInstance Properties\nvar kernelHeight: Int\nvar kernelWidth: Int\nRelationships\nInherits From\nMPSCNNNormalizationNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNBatchNormalizationGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\nRelationships\nInherits From\nMPSNNGradientFilterNode\nConforms To\nMPSNNTrainableNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNBatchNormalizationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbatchnormalizationnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, dataSource: MPSCNNBatchNormalizationDataSource)\nInstance Properties\nvar flags: MPSCNNBatchNormalizationFlags\nvar trainingStyle: MPSNNTrainingStyle\nRelationships\nInherits From\nMPSNNFilterNode\nConforms To\nMPSNNTrainableNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNSoftMaxGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnsoftmaxgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nSoftmax Layer Nodes\nclass MPSCNNSoftMaxNode\nA representation of a softmax filter.\nclass MPSCNNLogSoftMaxNode\nA representation of a logarithmic softmax filter kernel.\nclass MPSCNNLogSoftMaxGradientNode\nA representation of a gradient logarithmic softmax filter kernel."
  },
  {
    "title": "MPSCNNCrossChannelNormalizationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnncrosschannelnormalizationnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, kernelSize: Int)\nInstance Properties\nvar kernelSizeInFeatureChannels: Int\nRelationships\nInherits From\nMPSCNNNormalizationNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNLocalContrastNormalizationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlocalcontrastnormalizationnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, kernelSize: Int)\nInstance Properties\nvar kernelHeight: Int\nvar kernelWidth: Int\nvar p0: Float\nvar pm: Float\nvar ps: Float\nRelationships\nInherits From\nMPSCNNNormalizationNode\nSee Also\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes."
  },
  {
    "title": "MPSCNNNeuronNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronnode",
    "html": "Topics\nSupporting Types\nenum MPSCNNNeuronType\nThe types of neuron filter to append to a convolution.\nInitializers\ninit(source: MPSNNImageNode, descriptor: MPSNNNeuronDescriptor)\nInstance Properties\nvar a: Float\nvar b: Float\nvar c: Float\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter."
  },
  {
    "title": "MPSCNNNeuronSoftPlusNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronsoftplusnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, a: Float, b: Float)\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronExponentialNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronexponentialnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, a: Float, b: Float, c: Float)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNSoftMaxNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnsoftmaxnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nSoftmax Layer Nodes\nclass MPSCNNLogSoftMaxNode\nA representation of a logarithmic softmax filter kernel.\nclass MPSCNNLogSoftMaxGradientNode\nA representation of a gradient logarithmic softmax filter kernel.\nclass MPSCNNSoftMaxGradientNode\nA representation of a gradient softmax filter."
  },
  {
    "title": "MPSCNNLogSoftMaxGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlogsoftmaxgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nSoftmax Layer Nodes\nclass MPSCNNSoftMaxNode\nA representation of a softmax filter.\nclass MPSCNNLogSoftMaxNode\nA representation of a logarithmic softmax filter kernel.\nclass MPSCNNSoftMaxGradientNode\nA representation of a gradient softmax filter."
  },
  {
    "title": "MPSCNNLogSoftMaxNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnlogsoftmaxnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nSoftmax Layer Nodes\nclass MPSCNNSoftMaxNode\nA representation of a softmax filter.\nclass MPSCNNLogSoftMaxGradientNode\nA representation of a gradient logarithmic softmax filter kernel.\nclass MPSCNNSoftMaxGradientNode\nA representation of a gradient softmax filter."
  },
  {
    "title": "MPSCNNNeuronGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneurongradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, descriptor: MPSNNNeuronDescriptor)\nInstance Properties\nvar descriptor: MPSNNNeuronDescriptor\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronPowerNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronpowernode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, a: Float, b: Float, c: Float)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronLogarithmNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronlogarithmnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, a: Float, b: Float, c: Float)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronSigmoidNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronsigmoidnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronReLUNNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronrelunnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, a: Float, b: Float)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronLinearNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronlinearnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, a: Float, b: Float)\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronHardSigmoidNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronhardsigmoidnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, a: Float, b: Float)\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronELUNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronelunode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, a: Float)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNBinaryFullyConnectedNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbinaryfullyconnectednode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, weights: MPSCNNConvolutionDataSource, scaleValue: Float, type: MPSCNNBinaryConvolutionType, flags: MPSCNNBinaryConvolutionFlags)\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\ninit(source: MPSNNImageNode, weights: MPSCNNConvolutionDataSource, outputBiasTerms: UnsafePointer<Float>?, outputScaleTerms: UnsafePointer<Float>?, inputBiasTerms: UnsafePointer<Float>?, inputScaleTerms: UnsafePointer<Float>?, type: MPSCNNBinaryConvolutionType, flags: MPSCNNBinaryConvolutionFlags)\nRelationships\nInherits From\nMPSCNNBinaryConvolutionNode\nSee Also\nFully Connected Layer Nodes\nclass MPSCNNFullyConnectedNode\nA representation of a fully connected convolution layer, also known as an inner product layer."
  },
  {
    "title": "MPSCNNPoolingMaxGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingmaxgradientnode",
    "html": "Relationships\nInherits From\nMPSCNNPoolingGradientNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter."
  },
  {
    "title": "MPSCNNPoolingL2NormGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingl2normgradientnode",
    "html": "Relationships\nInherits From\nMPSCNNPoolingGradientNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter."
  },
  {
    "title": "MPSCNNPoolingGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolinggradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int, paddingPolicy: MPSNNPadding?)\nInstance Properties\nvar kernelHeight: Int\nvar kernelWidth: Int\nvar strideInPixelsX: Int\nvar strideInPixelsY: Int\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter."
  },
  {
    "title": "clipRect | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsunaryimagekernel/1618859-cliprect",
    "html": "Discussion\n\nThis value indicates which part of the destination to overwrite. If the clip rectangle does not lie completely within the destination image, then the intersection between the clip rectangle and destination bounds is used instead.\n\nThe default value is MPSRectNoClip, indicating that the entire image is used.\n\nSee Also\nProperties\nvar offset: MPSOffset\nThe position of the destination clip rectangle origin relative to the source buffer.\nstruct MPSOffset\nA signed coordinate with x, y, and z components.\nstruct MPSRegion\nA region of an image.\nvar edgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of an image.\nenum MPSImageEdgeMode\nThe options used to control the edge behavior of an image filter when it reads outside the bounds of a source texture."
  },
  {
    "title": "offset | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsunaryimagekernel/1618884-offset",
    "html": "Discussion\n\nThe offset is defined to be the position of the origin value of clipRect, in source coordinates.\n\nThe default value is {0, 0, 0}, indicating that the top left corners of the clip rectangle and the source image align.\n\nSee Also\nProperties\nstruct MPSOffset\nA signed coordinate with x, y, and z components.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.\nstruct MPSRegion\nA region of an image.\nvar edgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of an image.\nenum MPSImageEdgeMode\nThe options used to control the edge behavior of an image filter when it reads outside the bounds of a source texture."
  },
  {
    "title": "primaryOffset | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618880-primaryoffset",
    "html": "Discussion\n\nThe offset is defined to be the position of the origin value of clipRect, in source coordinates.\n\nThe default value is {0, 0, 0}, indicating that the top left corners of the clip rectangle and the primary source image align.\n\nSee Also\nProperties\nvar secondaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the secondary source buffer.\nvar primaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the primary source image.\nvar secondaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the secondary source image.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten."
  },
  {
    "title": "clipRect | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618879-cliprect",
    "html": "Discussion\n\nThis value indicates which part of the destination to overwrite. If the clip rectangle does not lie completely within the destination image, then the intersection between the clip rectangle and destination bounds is used instead.\n\nThe default value is MPSRectNoClip, indicating that the entire image is used.\n\nSee Also\nProperties\nvar primaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the primary source buffer.\nvar secondaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the secondary source buffer.\nvar primaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the primary source image.\nvar secondaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the secondary source image."
  },
  {
    "title": "secondaryOffset | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel/1618755-secondaryoffset",
    "html": "Discussion\n\nThe offset is defined to be the position of the origin value of clipRect, in source coordinates.\n\nThe default value is {0, 0, 0}, indicating that the top left corners of the clip rectangle and the secondary source image align.\n\nSee Also\nProperties\nvar primaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the primary source buffer.\nvar primaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the primary source image.\nvar secondaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the secondary source image.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten."
  },
  {
    "title": "MPSImageHistogram | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogram",
    "html": "Overview\n\nTypically, you use an MPSImageHistogram filter to calculate an image's histogram that is passed to a subsequent filter such as MPSImageHistogramEqualization or MPSImageHistogramSpecification.\n\nListing 1 shows how you can create a histogram filter to calculate the histogram of the MTLTexture, sourceTexture. The filter is passed an instance of MPSImageHistogramInfo that specifies information to compute the histogram for the channels of an image. After encoding, histogramInfoBuffer contains the histogram information and can be used for further operations such as equalization or specification.\n\nListing 1 Creating a histogram filter\nvar histogramInfo = MPSImageHistogramInfo(\n    numberOfHistogramEntries: 256,\n    histogramForAlpha: false,\n    minPixelValue: vector_float4(0,0,0,0),\n    maxPixelValue: vector_float4(1,1,1,1))\n     \nlet calculation = MPSImageHistogram(device: device,\n                                    histogramInfo: &histogramInfo)\nlet bufferLength = calculation.histogramSize(forSourceFormat: sourceTexture.pixelFormat)\nlet histogramInfoBuffer = device.makeBuffer(length: bufferLength, \n                                            options: [.storageModePrivate])\n     \ncalculation.encode(to: commandBuffer,\n                   sourceTexture: sourceTexture,\n                   histogram: histogramInfoBuffer,\n                   histogramOffset: 0)\n\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, histogramInfo: UnsafePointer<MPSImageHistogramInfo>)\nInitializes a histogram with specific information.\nstruct MPSImageHistogramInfo\nThe information used to compute the histogram channels of an image.\nfunc encode(to: MTLCommandBuffer, sourceTexture: MTLTexture, histogram: MTLBuffer, histogramOffset: Int)\nEncodes the filter to a command buffer using a compute command encoder.\nfunc histogramSize(forSourceFormat: MTLPixelFormat) -> Int\nThe amount of space the histogram will take up in the output buffer.\nProperties\nvar clipRectSource: MTLRegion\nThe source rectangle to use when reading data.\nvar zeroHistogram: Bool\nDetermines whether to zero-initialize the histogram results.\nvar histogramInfo: MPSImageHistogramInfo\nA structure describing the histogram content.\nvar minPixelThresholdValue: vector_float4\nRelationships\nInherits From\nMPSKernel\nSee Also\nHistogram Image Filters\nclass MPSImageHistogramEqualization\nA filter that equalizes the histogram of an image.\nclass MPSImageHistogramSpecification\nA filter that performs a histogram specification operation on an image."
  },
  {
    "title": "MPSImageHistogramEqualization | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagehistogramequalization",
    "html": "Overview\n\nThe process is divided into three steps:\n\nCall the init(device:histogramInfo:) method to create a MPSImageHistogramEqualization object.\n\nCall the encodeTransform(to:sourceTexture:histogram:histogramOffset:) method. This creates a privately held image transform (i.e. a cumulative distribution function of the histogram) which will be used to equalize the distribution of the histogram of the source image. This process runs on a command buffer when it is committed to a command queue. It must complete before the next step can be run. It may be performed on the same command buffer. The histogram argument specifies the histogram buffer which contains the histogram values for the source texture. The sourceTexture argument is used by the method to determine the number of channels and therefore which histogram data in the histogram buffer to use. The histogram for the source texture must have been computed either on the CPU or using the MPSImageHistogram kernel.\n\nCall the encode(commandBuffer:sourceTexture:destinationTexture:) method to read data from the source texture, apply the equalization transform to it, and write to the destination texture. This step is also done on the GPU on a command queue.\n\nNote\n\nYou can reuse the same equalization transform on other images to perform the same transform on those images. (Since their distribution is probably different, they will probably not be equalized by it.) This filter usually will not be able to work in place.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, histogramInfo: UnsafePointer<MPSImageHistogramInfo>)\nInitializes a histogram with specific information.\nfunc encodeTransform(to: MTLCommandBuffer, sourceTexture: MTLTexture, histogram: MTLBuffer, histogramOffset: Int)\nEncodes the transform function to a command buffer using a compute command encoder. The transform function computes the equalization lookup table.\nProperties\nvar histogramInfo: MPSImageHistogramInfo\nA structure describing the histogram content.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nHistogram Image Filters\nclass MPSImageHistogram\nA filter that computes the histogram of an image.\nclass MPSImageHistogramSpecification\nA filter that performs a histogram specification operation on an image.\nRelated Documentation\nMetal Image Filters: Using the image filters provided by the Metal Performance Shaders framework."
  },
  {
    "title": "MPSNNConcatenationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnconcatenationnode",
    "html": "Topics\nInitializers\ninit(sources: [MPSNNImageNode])\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nKernel Concatenation Nodes\nclass MPSNNConcatenationGradientNode\nA representation of the results from one or more gradient kernels."
  },
  {
    "title": "MPSCNNDropoutNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndropoutnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, keepProbability: Float)\ninit(source: MPSNNImageNode, keepProbability: Float, seed: Int, maskStrideInPixels: MTLSize)\nInstance Properties\nvar keepProbability: Float\nvar maskStrideInPixels: MTLSize\nvar seed: Int\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nDropout Layer Nodes\nclass MPSCNNDropoutGradientNode\nA representation of a gradient dropout filter."
  },
  {
    "title": "MPSNNConcatenationGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnconcatenationgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nKernel Concatenation Nodes\nclass MPSNNConcatenationNode\nA representation of the results from one or more kernels."
  },
  {
    "title": "MPSCNNDropoutGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndropoutgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, keepProbability: Float, seed: Int, maskStrideInPixels: MTLSize)\nInstance Properties\nvar keepProbability: Float\nvar maskStrideInPixels: MTLSize\nvar seed: Int\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nDropout Layer Nodes\nclass MPSCNNDropoutNode\nA representation of a dropout filter."
  },
  {
    "title": "MPSImageReadWriteParams | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagereadwriteparams",
    "html": "Topics\nInitializers\ninit()\ninit(featureChannelOffset: Int, numberOfFeatureChannelsToReadWrite: Int)\nInstance Properties\nvar featureChannelOffset: Int\nvar numberOfFeatureChannelsToReadWrite: Int\nSee Also\nMethods to Read and Write Raw Data\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nenum MPSDataLayout\nOptions that define how buffer data is arranged."
  },
  {
    "title": "MetalPerformanceShaders Structures | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/metalperformanceshaders_structures",
    "html": "Topics\nStructures\nstruct MPSAccelerationStructureUsage\nOptions that describe how an acceleration structure will be used.\nDeprecated\nstruct MPSAliasingStrategy\nstruct MPSCNNBatchNormalizationFlags\nOptions that define how statistics are calculated during batch normalization.\nstruct MPSCNNConvolutionGradientOption\nOptions that control which gradient to compute during backward propagation.\nstruct MPSCustomKernelArgumentCount\nA structure that contains the number of destination, source, and broadcaset textures used by a custom kernel.\nstruct MPSCustomKernelIndex\nstruct MPSCustomKernelInfo\nstruct MPSCustomKernelSourceInfo\nstruct MPSDeviceCapsValues\nstruct MPSDeviceOptions\nstruct MPSDimensionSlice\nstruct MPSImageCoordinate\nstruct MPSImageRegion\nstruct MPSImageType\nOptions that define a Metal Performance Shaders image type.\nstruct MPSIntegerDivisionParams\nParameters that define the parts of a division operation.\nstruct MPSIntersectionDistance\nAn intersection result that contains the distance from the ray origin to the intersection point.\nstruct MPSIntersectionDistancePrimitiveIndex\nAn intersection result that contains the distance from the ray origin to the intersection point, and the index of the intersected primitive.\nstruct MPSIntersectionDistancePrimitiveIndexBufferIndex\nstruct MPSIntersectionDistancePrimitiveIndexBufferIndexCoordinates\nstruct MPSIntersectionDistancePrimitiveIndexBufferIndexInstanceIndex\nstruct MPSIntersectionDistancePrimitiveIndexBufferIndexInstanceIndexCoordinates\nstruct MPSIntersectionDistancePrimitiveIndexCoordinates\nAn intersection result that contains the origin-intersection distance, intersected primitive index, and intersection point coordinates.\nstruct MPSIntersectionDistancePrimitiveIndexInstanceIndex\nAn intersection result that contains the origin-intersection distance, and intersected primitive and instance indices.\nstruct MPSIntersectionDistancePrimitiveIndexInstanceIndexCoordinates\nAn intersection result that contains the origin-intersection distance, intersected primitive and instance indices, and intersection point coordinates.\nstruct MPSMatrixCopyOffsets\nA description of matrix copy operations.\nstruct MPSMatrixOffset\nA description of row and column offsets into a matrix.\nstruct MPSMatrixRandomDistribution\nstruct MPSNDArrayOffsets\nstruct MPSNDArraySizes\nstruct MPSNNComparisonType\nstruct MPSNNConvolutionAccumulatorPrecisionOption\nOptions that specify convolution accumulator precision.\nstruct MPSNNTrainingStyle\nOptions that control how graph nodes are trained.\nstruct MPSRayMaskOptions\nOptions for ray intersector mask options.\nDeprecated\nstruct MPSRayOriginDirection\nA 3D ray with an origin and a direction.\nstruct MPSRayOriginMaskDirectionMaxDistance\nA 3D ray with an origin, a direction, and a mask to filter out intersections.\nstruct MPSRayOriginMinDistanceDirectionMaxDistance\nA 3D ray with an origin, a direction, and an intersection distance range from the origin.\nstruct MPSRayPackedOriginDirection\nstruct MPSStateTextureInfo\nAn encapsulation of a texture's dimensions, format, type, and usage."
  },
  {
    "title": "MPSSVGFTextureAllocator | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpssvgftextureallocator",
    "html": "Topics\nInstance Methods\nfunc `return`(MTLTexture)\n\nRequired\n\nfunc texture(with: MTLPixelFormat, width: Int, height: Int) -> MTLTexture?\n\nRequired\n\nRelationships\nInherits From\nNSObjectProtocol\nConforming Types\nMPSSVGFDefaultTextureAllocator"
  },
  {
    "title": "MPSTemporalAA | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporalaa",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar blendFactor: Float\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(to: MTLCommandBuffer, sourceTexture: MTLTexture, previousTexture: MTLTexture, destinationTexture: MTLTexture, motionVectorTexture: MTLTexture?, depthTexture: MTLTexture?)\nfunc encode(with: NSCoder)\nRelationships\nInherits From\nMPSKernel\nConforms To\nNSCopying\nNSSecureCoding"
  },
  {
    "title": "MPSStateResourceList | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsstateresourcelist",
    "html": "Topics\nInitializers\ninit()\nInstance Methods\nfunc appendBuffer(Int)\nfunc appendTexture(MTLTextureDescriptor)\nRelationships\nInherits From\nNSObject"
  },
  {
    "title": "MPSCNNDilatedPoolingMaxGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndilatedpoolingmaxgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int, dilationRateX: Int, dilationRateY: Int)\nInstance Properties\nvar dilationRateX: Int\nvar dilationRateY: Int\nRelationships\nInherits From\nMPSCNNPoolingGradientNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter."
  },
  {
    "title": "MPSCNNPoolingNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, filterSize: Int)\ninit(source: MPSNNImageNode, filterSize: Int, stride: Int)\ninit(source: MPSNNImageNode, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int)\nInstance Properties\nvar kernelHeight: Int\nvar kernelWidth: Int\nvar strideInPixelsX: Int\nvar strideInPixelsY: Int\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter."
  },
  {
    "title": "MPSCNNPoolingMaxNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingmaxnode",
    "html": "Relationships\nInherits From\nMPSCNNPoolingNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter."
  },
  {
    "title": "MPSCNNPoolingL2NormNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingl2normnode",
    "html": "Relationships\nInherits From\nMPSCNNPoolingNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter."
  },
  {
    "title": "MPSCNNKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnkernel",
    "html": "Overview\n\nAn MPSCNNKernel object consumes one MPSImage object and produces one MPSImage object.\n\nThe region overwritten in the destination image is described by the clipRectproperty. The top left corner of the region consumed (ignoring adjustments for filter size—for example, convolution filter size) is given by the offset property. The size of the region consumed is a function of the size of the clipRect property and any subsampling caused by pixel strides at work (for example, strideInPixelsX/strideInPixelsY in the MPSCNNPooling class). Wherever the offset and clipRect properties would cause an {x,y} pixel address not in the image to be read, the edgeMode property is used to determine what value to read there.\n\nThe z or depth component of the offset, origin and size properties indexes which images to use.\n\nIf the MPSImage object contains only a single image, then these values should be offset.z = 0, clipRect.origin.z = 0, and clipRect.size.depth = 1.\n\nIf the MPSImage object contains multiple images, then the value of clipRect.size.depth determines the number of images to process. Both the source and destination MPSImage objects must have at least this many images. The value of offset.z refers to the starting image index of the source. Thus, the value of offset.z + clipRect.size.depth must be <=source.numberOfImages. Similarly, the value of clipRect.origin.z determines the starting image index of the destination. Thus, the value of clipRect.origin.z + clipRect.size.depth must be <=destination.numberOfImages.\n\nThe destinationFeatureChannelOffset property can be used to control where the kernel will start writing in terms of feature channel dimension. For example, if the destination has 64 channels and thdestinationFeatureChannelOffsete kernel outputs 32 channels, channels 0-31 of the destination will be populated by the kernel (by default). But if you want the kernel to populate channels 32-63 of the destination, you can set the value of destinationFeatureChannelOffset to 32. Suppose you have a source of dimensions w x h x Ni, where N is the number of channels, which goes through a convolution filter C0 which produces the output O0 = w x h x N0 and C1 which produces the output O1 = w x h x N1 followed by concatenation which produces O = w x h x (N0 + N1). You can achieve this by creating an MPSImage object with dimensions w x h x (N0 + N1) and using this as the destination of both convolutions as follows:\n\nC0: destinationFeatureChannelOffset = 0, this will output N0 channels starting at channel 0 of destination thus populating [0,N0-1] channels.\n\nC1: destinationFeatureChannelOffset = N0, this will output N1 channels starting at channel N0 of destination thus populating [N0,N0+N1-1] channels.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar offset: MPSOffset\nThe position of the destination image's clip rectangle origin, relative to the source image.\nstruct MPSOffset\nA signed coordinate with x, y, and z components.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the clip rectangle will be overwritten.\nstruct MTLRegion\nThe bounds for a subset of an object's elements.\nvar destinationFeatureChannelOffset: Int\nThe number of channels in the destination image to skip before writing output data.\nvar edgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of an image.\nenum MPSImageEdgeMode\nThe options used to control the edge behavior of an image filter when it reads outside the bounds of a source texture.\nvar kernelHeight: Int\nvar kernelWidth: Int\nvar strideInPixelsX: Int\nvar strideInPixelsY: Int\nvar isBackwards: Bool\nvar padding: MPSNNPadding\nprotocol MPSNNPadding\nThe protocol that provides a description of how kernels should pad images.\nvar destinationImageAllocator: MPSImageAllocator\nprotocol MPSImageAllocator\nvar dilationRateX: Int\nvar dilationRateY: Int\nvar isStateModified: Bool\nvar sourceFeatureChannelMaxCount: Int\nvar sourceFeatureChannelOffset: Int\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage) -> MPSImage\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationImage: MPSImage)\nEncodes a kernel into a command buffer. The ensuing operation proceeds out-of-place.\nfunc appendBatchBarrier() -> Bool\nfunc batchEncodingStorageSize(sourceImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]?) -> Int\nfunc destinationImageDescriptor(sourceImages: [MPSImage], sourceStates: [MPSState]?) -> MPSImageDescriptor\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationState: MPSState, destinationImage: MPSImage)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationState: AutoreleasingUnsafeMutablePointer<MPSState?>, destinationStateIsTemporary: Bool) -> MPSImage\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage]) -> [MPSImage]\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], destinationImages: [MPSImage])\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], destinationStates: [MPSState]?, destinationImages: [MPSImage])\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], destinationStates: AutoreleasingUnsafeMutablePointer<NSArray?>, destinationStateIsTemporary: Bool) -> [MPSImage]\nfunc encodingStorageSize(sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage?) -> Int\nfunc isResultStateReusedAcrossBatch() -> Bool\nfunc resultState(sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSState?\nfunc resultStateBatch(sourceImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> [MPSState]?\nfunc temporaryResultState(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSState?\nfunc temporaryResultStateBatch(commandBuffer: MTLCommandBuffer, sourceImage: [MPSImage], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> [MPSState]?\nRelationships\nInherits From\nMPSKernel\nSee Also\nLayer Base Classes\nclass MPSCNNBinaryKernel\nA convolution neural network kernel.\nclass MPSCNNGradientKernel\nThe base class for gradient layers."
  },
  {
    "title": "MPSCNNDilatedPoolingMaxNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnndilatedpoolingmaxnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, filterSize: Int)\ninit(source: MPSNNImageNode, filterSize: Int, stride: Int, dilationRate: Int)\ninit(source: MPSNNImageNode, kernelWidth: Int, kernelHeight: Int, strideInPixelsX: Int, strideInPixelsY: Int, dilationRateX: Int, dilationRateY: Int)\nInstance Properties\nvar dilationRateX: Int\nvar dilationRateY: Int\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter."
  },
  {
    "title": "MPSCNNConvolutionGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiongradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, convolutionGradientState: MPSCNNConvolutionGradientStateNode, weights: MPSCNNConvolutionDataSource?)\nRelationships\nInherits From\nMPSNNGradientFilterNode\nConforms To\nMPSNNTrainableNode\nSee Also\nConvolution Layer Nodes\nclass MPSCNNBinaryConvolutionNode\nA representation of a convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolutionNode\nA representation of a convolution kernel.\nclass MPSCNNConvolutionTransposeNode\nA representation of a transposed convolution.\nclass MPSCNNConvolutionGradientStateNode\nA representation of a gradient convolution state.\nclass MPSCNNCrossChannelNormalizationGradientNode\nA representation of a gradient normalization kernel applied across feature channels."
  },
  {
    "title": "MPSCNNPoolingAverageNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnpoolingaveragenode",
    "html": "Relationships\nInherits From\nMPSCNNPoolingNode\nSee Also\nPooling Layer Nodes\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter."
  },
  {
    "title": "MPSCNNCrossChannelNormalizationGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnncrosschannelnormalizationgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, kernelSize: Int)\nInstance Properties\nvar kernelSize: Int\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nConvolution Layer Nodes\nclass MPSCNNBinaryConvolutionNode\nA representation of a convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolutionNode\nA representation of a convolution kernel.\nclass MPSCNNConvolutionTransposeNode\nA representation of a transposed convolution.\nclass MPSCNNConvolutionGradientNode\nA representation of a gradient convolution kernel.\nclass MPSCNNConvolutionGradientStateNode\nA representation of a gradient convolution state."
  },
  {
    "title": "MPSCNNConvolutionGradientStateNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiongradientstatenode",
    "html": "Relationships\nInherits From\nMPSNNGradientStateNode\nSee Also\nConvolution Layer Nodes\nclass MPSCNNBinaryConvolutionNode\nA representation of a convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolutionNode\nA representation of a convolution kernel.\nclass MPSCNNConvolutionTransposeNode\nA representation of a transposed convolution.\nclass MPSCNNConvolutionGradientNode\nA representation of a gradient convolution kernel.\nclass MPSCNNCrossChannelNormalizationGradientNode\nA representation of a gradient normalization kernel applied across feature channels."
  },
  {
    "title": "MPSCNNConvolutionTransposeNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiontransposenode",
    "html": "Topics\nInitializers\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\ninit(source: MPSNNImageNode, convolutionGradientState: MPSCNNConvolutionGradientStateNode?, weights: MPSCNNConvolutionDataSource)\nRelationships\nInherits From\nMPSCNNConvolutionNode\nSee Also\nConvolution Layer Nodes\nclass MPSCNNBinaryConvolutionNode\nA representation of a convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolutionNode\nA representation of a convolution kernel.\nclass MPSCNNConvolutionGradientNode\nA representation of a gradient convolution kernel.\nclass MPSCNNConvolutionGradientStateNode\nA representation of a gradient convolution state.\nclass MPSCNNCrossChannelNormalizationGradientNode\nA representation of a gradient normalization kernel applied across feature channels."
  },
  {
    "title": "MPSCNNBinaryConvolutionNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbinaryconvolutionnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, weights: MPSCNNConvolutionDataSource, scaleValue: Float, type: MPSCNNBinaryConvolutionType, flags: MPSCNNBinaryConvolutionFlags)\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\nenum MPSCNNBinaryConvolutionType\nOptions that defines what operations are used to perform binary convolution.\nenum MPSCNNBinaryConvolutionFlags\nOptions used to control binary convolution kernels.\ninit(source: MPSNNImageNode, weights: MPSCNNConvolutionDataSource, outputBiasTerms: UnsafePointer<Float>?, outputScaleTerms: UnsafePointer<Float>?, inputBiasTerms: UnsafePointer<Float>?, inputScaleTerms: UnsafePointer<Float>?, type: MPSCNNBinaryConvolutionType, flags: MPSCNNBinaryConvolutionFlags)\nRelationships\nInherits From\nMPSCNNConvolutionNode\nSee Also\nConvolution Layer Nodes\nclass MPSCNNConvolutionNode\nA representation of a convolution kernel.\nclass MPSCNNConvolutionTransposeNode\nA representation of a transposed convolution.\nclass MPSCNNConvolutionGradientNode\nA representation of a gradient convolution kernel.\nclass MPSCNNConvolutionGradientStateNode\nA representation of a gradient convolution state.\nclass MPSCNNCrossChannelNormalizationGradientNode\nA representation of a gradient normalization kernel applied across feature channels."
  },
  {
    "title": "MPSState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsstate",
    "html": "Overview\n\nSome MPS CNN kernels produce additional information beyond an MPSImage. These may be pooling indices where the result came from, convolution weights, or other information not contained in the usual MPSImage result from a MPSCNNKernel. An MPSState object typically contains one or more expensive MTLResource objects such as textures or buffers to store this information. It provides a base class with interfaces for managing this storage. Child classes may add additional functionality specific to their contents.\n\nSome MPSState objects are temporary. Temporary state objects, for example, MPSTemporaryImage and MPSTemporaryMatrix, are for very short lived storage, perhaps just a few lines of code within the scope of a single MTLCommandBuffer. They are very efficient for storage, as several temporary objects can share the same memory over the course of a command buffer. This can improve both memory usage and time spent in the kernel wiring down memory and such. You may find that some large CNN tasks can not be computed without them, as nontemporary storage would simply take up too much memory.\n\nIn exchange, the lifetime of the underlying storage in temporary MPSState objects needs to be carefully managed. ARC often waits until the end of scope to release objects. Temporary storage often needs to be released sooner than that. Consequently the lifetime of the data in the underlying Metal resources is managed by a readCount property. Each time a MPSCNNKernel reads a temporary MPSState object the readCount is automatically decremented. When it reaches 0, the underlying storage is recycled for use by other MPS temporary objects, and the data is becomes undefined. If you need to consume the data multiple times, you should set the readCount to a larger number to prevent the data from becoming undefined. You may set the readCount to 0 yourself to return the storage to MPS, if for any reason, you realize that the MPSState object will no longer be used.\n\nThe contents of a temporary MPSState object are only valid from creation to the time the readCount reaches 0. The data is only valid for the MTLCommandBuffer on which it was created. Nontemporary MPSState objects are valid on any MTLCommandBuffer on the same device until they are released.\n\nTopics\nInstance Properties\nvar isTemporary: Bool\nvar label: String?\nvar readCount: Int\nvar resource: MTLResource?\nDeprecated\nvar resourceCount: Int\nInitializers\ninit(device: MTLDevice, bufferSize: Int)\ninit(device: MTLDevice, resourceList: MPSStateResourceList)\ninit(device: MTLDevice, textureDescriptor: MTLTextureDescriptor)\ninit(resource: MTLResource?)\ninit(resources: [MTLResource]?)\nInstance Methods\nfunc bufferSize(at: Int) -> Int\nfunc destinationImageDescriptor(forSourceImages: [MPSImage], sourceStates: [MPSState]?, for: MPSKernel, suggestedDescriptor: MPSImageDescriptor) -> MPSImageDescriptor\nfunc resource(at: Int, allocateMemory: Bool) -> MTLResource?\nfunc resourceSize() -> Int\nfunc resourceType(at: Int) -> MPSStateResourceType\nfunc synchronize(on: MTLCommandBuffer)\nfunc textureInfo(at: Int) -> MPSStateTextureInfo\nType Methods\nclass func temporaryState(with: MTLCommandBuffer) -> Self\nclass func temporaryState(with: MTLCommandBuffer, bufferSize: Int) -> Self\nclass func temporaryState(with: MTLCommandBuffer, resourceList: MPSStateResourceList) -> Self\nclass func temporaryState(with: MTLCommandBuffer, textureDescriptor: MTLTextureDescriptor) -> Self\nRelationships\nInherits From\nNSObject"
  },
  {
    "title": "MPSNNArithmeticGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnarithmeticgradientnode",
    "html": "Topics\nInitializers\ninit(gradientImages: [MPSNNImageNode], forwardFilter: MPSNNFilterNode, isSecondarySourceFilter: Bool)\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNBinaryGradientStateNode, isSecondarySourceFilter: Bool)\nInstance Properties\nvar bias: Float\nvar isSecondarySourceFilter: Bool\nvar maximumValue: Float\nvar minimumValue: Float\nvar primaryScale: Float\nvar secondaryScale: Float\nvar secondaryStrideInFeatureChannels: Int\nvar secondaryStrideInPixelsX: Int\nvar secondaryStrideInPixelsY: Int\nRelationships\nInherits From\nMPSNNGradientFilterNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSNNMultiplicationGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnmultiplicationgradientnode",
    "html": "Relationships\nInherits From\nMPSNNArithmeticGradientNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSNNMultiplicationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnmultiplicationnode",
    "html": "Relationships\nInherits From\nMPSNNBinaryArithmeticNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSNNSubtractionGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnsubtractiongradientnode",
    "html": "Relationships\nInherits From\nMPSNNArithmeticGradientNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSNNAdditionGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnadditiongradientnode",
    "html": "Relationships\nInherits From\nMPSNNArithmeticGradientNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSNNSubtractionNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnsubtractionnode",
    "html": "Relationships\nInherits From\nMPSNNBinaryArithmeticNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSNNAdditionNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnadditionnode",
    "html": "Relationships\nInherits From\nMPSNNBinaryArithmeticNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSHandle | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpshandle",
    "html": "Topics\nInstance Methods\nfunc label() -> String?\n\nRequired\n\nRelationships\nInherits From\nNSObjectProtocol\nNSSecureCoding\nSee Also\nNeural Network Graphs\nclass MPSNNGraph\nAn optimized representation of a graph of neural network image and filter nodes.\nclass MPSNNImageNode\nA placeholder node denoting the position of a neural network image in a graph."
  },
  {
    "title": "copy(with:device:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpskernel/1618912-copy",
    "html": "Parameters\nzone\n\nThe zone in which to allocate the kernel object.\n\ndevice\n\nThe Metal device for the new kernel object.\n\nReturn Value\n\nA copy of this kernel object.\n\nDiscussion\n\nThe same kernel objects should not be used to encode separate kernel operations on multiple command buffers from multiple threads. Many kernels have mutable properties that might be changed by another thread while the kernel is being encoded. If you need to use a kernel from multiple threads, make a copy of it for each additional thread using copy(with:) or copy(with:device:). Note that the copy(with:) method makes a copy of the kernel object on the same device.\n\nThis method fails if the device is not supported. Query the MPSSupportsMTLDevice(_:) function to determine whether the device is supported.\n\nSee Also\nMethods\ninit(device: MTLDevice)\nInitializes a new kernel object."
  },
  {
    "title": "MPSNNImageNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnimagenode",
    "html": "Topics\nInitializers\ninit(handle: MPSHandle?)\nInstance Properties\nvar exportFromGraph: Bool\nvar format: MPSImageFeatureChannelFormat\nenum MPSImageFeatureChannelFormat\nEncodes the representation of a single channel within an image.\nvar handle: MPSHandle?\nvar imageAllocator: MPSImageAllocator\nvar stopGradient: Bool\nvar synchronizeResource: Bool\nType Methods\nclass func exportedNode(with: MPSHandle?) -> Self\nSupporting Types\nprotocol MPSHandle\nThe protocol that provides resource identification.\nenum MPSImageFeatureChannelFormat\nEncodes the representation of a single channel within an image.\nprotocol MPSImageAllocator\nRelationships\nInherits From\nNSObject\nSee Also\nNeural Network Graphs\nclass MPSNNGraph\nAn optimized representation of a graph of neural network image and filter nodes.\nprotocol MPSHandle\nThe protocol that provides resource identification."
  },
  {
    "title": "MPSUnaryImageKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsunaryimagekernel",
    "html": "Overview\n\nMPSUnaryImageKernel defines shared behavior for most image processing kernels (filters) such as edging modes, clipping, and tiling support for image operations that consumes a single source textures. It is not meant to be used directly, but provides API abstraction and in some cases may allow some level of polymorphic manipulation of image kernel objects.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, inPlaceTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\ntypealias MPSCopyAllocator\nA block to make a copy of a source texture for filters that can only execute out of place.\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationImage: MPSImage)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out of place.\nfunc sourceRegion(destinationSize: MTLSize) -> MPSRegion\nDetermines the region of the source texture that will be read for an encode operation.\nProperties\nvar offset: MPSOffset\nThe position of the destination clip rectangle origin relative to the source buffer.\nstruct MPSOffset\nA signed coordinate with x, y, and z components.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.\nstruct MPSRegion\nA region of an image.\nvar edgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of an image.\nenum MPSImageEdgeMode\nThe options used to control the edge behavior of an image filter when it reads outside the bounds of a source texture.\nRelationships\nInherits From\nMPSKernel\nSee Also\nImage Filter Base Classes\nclass MPSBinaryImageKernel\nA kernel that consumes two textures and produces one texture."
  },
  {
    "title": "init(device:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpskernel/1618763-init",
    "html": "Parameters\ndevice\n\nThe Metal device on which the kernel will be used.\n\nReturn Value\n\nAn initialized kernel object.\n\nDiscussion\n\nThis method fails if the device is not supported. Query the MPSSupportsMTLDevice(_:) function to determine whether the device is supported.\n\nSee Also\nMethods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nMakes a copy of this kernel object for a new device."
  },
  {
    "title": "init(commandBuffer:textureDescriptor:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporaryimage/2097543-init",
    "html": "Parameters\ncommandBuffer\n\nThe command buffer on which the temporary image will be exclusively used.\n\ntextureDescriptor\n\nA texture descriptor that describes the temporary image texture to create.\n\nReturn Value\n\nA valid MPSTemporaryImage object.\n\nDiscussion\n\nThe temporary image will be released when the command buffer is committed. The underlying texture will become invalid before this time due to the action of the readCount property.\n\nThis function provides access to pixel formats not typically covered by the init(commandBuffer:imageDescriptor:) method. The feature channels will be inferred from the pixel format without changing the width. The following restrictions apply:\n\nThe texture type must be MTLTextureType.type2D or MTLTextureType.type2DArray.\n\nThe texture usage must contain at least one of shaderRead or shaderWrite.\n\nThe storage mode must be MTLStorageMode.private.\n\nThe depth must be 1."
  },
  {
    "title": "prefetchStorage(with:imageDescriptorList:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporaryimage/2097544-prefetchstorage",
    "html": "Parameters\ncommandBuffer\n\nThe command buffer on which the temporary images will be exclusively used.\n\ndescriptorList\n\nAn array of image descriptors that describe the temporary images that will be created.\n\nDiscussion\n\nThe texture cache that underlies the temporary images can automatically allocate new storage as needed, whenever you create new temporary images. However, sometimes a more global view of what you plan to make is useful for maximizing memory reuse to get the most efficient operation. Calling this class method provides a hint to the texture cache about what the list of temporary images will be.\n\nNote\n\nCalling this method is purely a performance and memory optimization; it is never necessary to call this method."
  },
  {
    "title": "defaultAllocator() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporaryimage/2867130-defaultallocator",
    "html": "See Also\nMethods to Get an Image Allocator\nprotocol MPSImageAllocator"
  },
  {
    "title": "MPSBinaryImageKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsbinaryimagekernel",
    "html": "Overview\n\nMPSBinaryImageKernel defines shared behavior for most image processing kernels (filters) such as edging modes, clipping, and tiling support for image operations that consume two source textures. It is not meant to be used directly, but provides API abstraction and in some cases may allow some level of polymorphic manipulation of image kernel objects.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, inPlaceSecondaryTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, inPlacePrimaryTexture: UnsafeMutablePointer<MTLTexture>, secondaryTexture: MTLTexture, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryTexture: MTLTexture, secondaryTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out-of-place.\nfunc encode(commandBuffer: MTLCommandBuffer, primaryImage: MPSImage, secondaryImage: MPSImage, destinationImage: MPSImage)\nfunc primarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the primary source texture that will be read for an encode operation.\nfunc secondarySourceRegion(forDestinationSize: MTLSize) -> MPSRegion\nDetermines the region of the secondary source texture that will be read for an encode operation.\nProperties\nvar primaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the primary source buffer.\nvar secondaryOffset: MPSOffset\nThe position of the destination clip rectangle origin relative to the secondary source buffer.\nvar primaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the primary source image.\nvar secondaryEdgeMode: MPSImageEdgeMode\nThe edge mode to use when texture reads stray off the edge of the secondary source image.\nvar clipRect: MTLRegion\nAn optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.\nRelationships\nInherits From\nMPSKernel\nSee Also\nImage Filter Base Classes\nclass MPSUnaryImageKernel\nA kernel that consumes one texture and produces one texture."
  },
  {
    "title": "init(commandBuffer:imageDescriptor:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporaryimage/2097545-init",
    "html": "Parameters\ncommandBuffer\n\nThe command buffer on which the temporary image will be exclusively used.\n\nimageDescriptor\n\nAn image descriptor that describes the image to create.\n\nReturn Value\n\nA valid MPSTemporaryImage object.\n\nDiscussion\n\nThe temporary image will be released when the command buffer is committed. The underlying texture will become invalid before this time due to the action of the readCount property."
  },
  {
    "title": "MPSImageGaussianBlur | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagegaussianblur",
    "html": "Overview\n\nNote\n\nThe Gaussian blur utilizes a very fast algorithm that typically runs at approximately half the speed of copy speeds. Notably, it is faster than either the tent or box blur except perhaps for very large filter windows. Mathematically, it is an approximate Gaussian. Some non-Gaussian behavior may be detectable with advanced analytical methods such as FFT.\n\nIf an analytically clean Gaussian filter is required, use the MPSImageConvolution filter instead with an appropriate set of weights. The MPSImageGaussianBlur filter is intended to be suitable for all common image processing needs demanding ~10 bits of precision or less.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice, sigma: Float)\nInitializes a Gaussian blur filter.\nProperties\nvar sigma: Float\nThe sigma value with which the filter was created.\nRelationships\nInherits From\nMPSUnaryImageKernel\nSee Also\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images."
  },
  {
    "title": "sourceRegion(destinationSize:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsunaryimagekernel/1618754-sourceregion",
    "html": "Parameters\ndestinationSize\n\nThe size of the full virtual destination image.\n\nReturn Value\n\nThe area in the virtual source image that will be read.\n\nDiscussion\n\nThis method is used to determine which region of the source texture will be read by the encode(commandBuffer:sourceTexture:destinationTexture:) method when the filter runs. This information may be needed if the source image is broken into multiple textures. The size of the full (untiled) destination image is provided. The region of the full (untiled) source image that will be read is returned. You can then piece together an appropriate texture containing that information for use in your tiled context.\n\nThis method will consult the offset and clipRect properties to determine the full region read by the function. Other properties, such as kernel height and width, will be consulted as necessary. All properties should be set to their intended values prior to calling this method.\n\nImportant\n\nThis function operates using global image coordinates, but the encode(commandBuffer:sourceTexture:destinationTexture:) method uses coordinates local to the source and destination image textures. Consequently, the offset and clipRect properties attached to this object will need to be updated using a global-to-local coordinate transform before the encode(commandBuffer:sourceTexture:destinationTexture:) method is called.\n\nSee Also\nMethods\nfunc encode(commandBuffer: MTLCommandBuffer, inPlaceTexture: UnsafeMutablePointer<MTLTexture>, fallbackCopyAllocator: MPSCopyAllocator?) -> Bool\nThis method attempts to apply a kernel in place on a texture.\ntypealias MPSCopyAllocator\nA block to make a copy of a source texture for filters that can only execute out of place.\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, destinationImage: MPSImage)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceTexture: MTLTexture, destinationTexture: MTLTexture)\nEncodes a kernel into a command buffer, out of place."
  },
  {
    "title": "MPSCNNNeuronTanHNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneurontanhnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, a: Float, b: Float)\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronSoftSignNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronsoftsignnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronPReLUNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronprelunode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, aData: Data)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNNeuronReLUNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneuronrelunode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, a: Float)\nRelationships\nInherits From\nMPSCNNNeuronNode\nSee Also\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes."
  },
  {
    "title": "MPSCNNFullyConnectedNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnfullyconnectednode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, weights: MPSCNNConvolutionDataSource)\nRelationships\nInherits From\nMPSCNNConvolutionNode\nSee Also\nFully Connected Layer Nodes\nclass MPSCNNBinaryFullyConnectedNode\nA representation of a fully connected convolution layer with binary weights and optionally binarized input image."
  },
  {
    "title": "MPSNNGridSample | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngridsample",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar useGridValueAsInputCoordinate: Bool\nRelationships\nInherits From\nMPSCNNBinaryKernel"
  },
  {
    "title": "MPSNNResizeBilinear | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnresizebilinear",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, resizeWidth: Int, resizeHeight: Int, alignCorners: Bool)\nInstance Properties\nvar alignCorners: Bool\nvar resizeHeight: Int\nvar resizeWidth: Int\nRelationships\nInherits From\nMPSCNNKernel"
  },
  {
    "title": "MPSNNReductionSpatialMeanNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionspatialmeannode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "label | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648899-label",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data."
  },
  {
    "title": "pixelSize | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648854-pixelsize",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "texture | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648903-texture",
    "html": "Discussion\n\nThis is a 2D texture if numberOfImages=1 and featureChannels<=4. It is a 2D texture array otherwise.\n\nTo avoid the high cost of premature allocation of the underlying texture, avoid accessing this property except when strictly necessary. Calls to the encode methods of an MPSCNNKernel object typically cause their arguments to become allocated. Likewise, MPSImage objects initialized with the init(texture:featureChannels:) method have already been allocated.\n\nSee Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "usage | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648828-usage",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "precision | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648880-precision",
    "html": "Discussion\n\nThis is precision, not size (float is 24 bits, not 32; half-precision floating-point is 11 bits, not 16; Snorm pixel formats have one less bit of precision for the sign bit, etc.). For formats like MTLPixelFormat.b5g6r5Unorm, this value is the precision of the most precise channel (which is 6 in this case). When this information is unavailable, typically for compressed formats, this value is 0.\n\nSee Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "pixelFormat | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648844-pixelformat",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "textureType | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648948-texturetype",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "featureChannels | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648901-featurechannels",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "numberOfImages | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor/1648846-numberofimages",
    "html": "Discussion\n\nThe default value is 1.\n\nSee Also\nProperties\nvar width: Int\nThe width of the image.\nvar height: Int\nThe height of the image.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar pixelFormat: MTLPixelFormat\nThe pixel format for the underlying texture.\nvar channelFormat: MPSImageFeatureChannelFormat\nThe storage format to use for each channel in the image.\nvar cpuCacheMode: MTLCPUCacheMode\nThe CPU cache mode of the underlying texture.\nvar storageMode: MTLStorageMode\nThe storage mode of underlying texture.\nvar usage: MTLTextureUsage\nOptions to specify the intended usage of the underlying texture."
  },
  {
    "title": "MetalPerformanceShaders Constants | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/metalperformanceshaders_constants",
    "html": "Topics\nConstants\nvar MPSBatchSizeIndex: Int32\nvar MPSCustomKernelIndexDestIndex: MPSCustomKernelIndex\nvar MPSCustomKernelIndexSrc0Index: MPSCustomKernelIndex\nvar MPSCustomKernelIndexSrc1Index: MPSCustomKernelIndex\nvar MPSCustomKernelIndexSrc2Index: MPSCustomKernelIndex\nvar MPSCustomKernelIndexSrc3Index: MPSCustomKernelIndex\nvar MPSCustomKernelIndexSrc4Index: MPSCustomKernelIndex\nvar MPSCustomKernelIndexUserDataIndex: MPSCustomKernelIndex\nvar MPSDeviceCapsIndex: Int32\nvar MPSDeviceCapsLast: MPSDeviceCapsValues\nvar MPSDeviceCapsNull: MPSDeviceCapsValues\nvar MPSDeviceIsAppleDevice: MPSDeviceCapsValues\nvar MPSDeviceSupportsBFloat16Arithmetic: MPSDeviceCapsValues\nvar MPSDeviceSupportsFloat16BicubicFiltering: MPSDeviceCapsValues\nvar MPSDeviceSupportsFloat32Filtering: MPSDeviceCapsValues\nvar MPSDeviceSupportsNorm16BicubicFiltering: MPSDeviceCapsValues\nvar MPSDeviceSupportsQuadShuffle: MPSDeviceCapsValues\nvar MPSDeviceSupportsReadWriteTextures: MPSDeviceCapsValues\nvar MPSDeviceSupportsReadableArrayOfTextures: MPSDeviceCapsValues\nvar MPSDeviceSupportsSimdReduction: MPSDeviceCapsValues\nvar MPSDeviceSupportsSimdShuffle: MPSDeviceCapsValues\nvar MPSDeviceSupportsSimdShuffleAndFill: MPSDeviceCapsValues\nvar MPSDeviceSupportsSimdgroupBarrier: MPSDeviceCapsValues\nvar MPSDeviceSupportsWritableArrayOfTextures: MPSDeviceCapsValues\nvar MPSFunctionConstantIndex: Int32\nvar MPSFunctionConstantIndexReserved: Int32\nlet MPSFunctionConstantNone: MPSFunctionConstant\nlet MPSFunctionConstantNoneArray: (MPSFunctionConstant, MPSFunctionConstant)\nvar MPSImageType2d: MPSImageType\nvar MPSImageType2d_array: MPSImageType\nvar MPSImageType2d_array_noAlpha: MPSImageType\nvar MPSImageType2d_noAlpha: MPSImageType\nvar MPSImageTypeArray2d: MPSImageType\nvar MPSImageTypeArray2d_array: MPSImageType\nvar MPSImageTypeArray2d_array_noAlpha: MPSImageType\nvar MPSImageTypeArray2d_noAlpha: MPSImageType\nvar MPSImageType_ArrayMask: MPSImageType\nvar MPSImageType_BatchMask: MPSImageType\nvar MPSImageType_bitCount: MPSImageType\nvar MPSImageType_mask: MPSImageType\nvar MPSImageType_noAlpha: MPSImageType\nvar MPSImageType_texelFormatBFloat16: MPSImageType\nvar MPSImageType_texelFormatFloat16: MPSImageType\nvar MPSImageType_texelFormatMask: MPSImageType\nvar MPSImageType_texelFormatShift: MPSImageType\nvar MPSImageType_texelFormatStandard: MPSImageType\nvar MPSImageType_texelFormatUnorm8: MPSImageType\nvar MPSImageType_typeMask: MPSImageType\nvar MPSNDArrayConstantIndex: Int32\nvar MPSNDArrayConstantMultiDestDstAddressingIndex: Int32\nvar MPSNDArrayConstantMultiDestIndex: Int32\nvar MPSNDArrayConstantMultiDestIndex0: Int32\nvar MPSNDArrayConstantMultiDestIndex1: Int32\nvar MPSNDArrayConstantMultiDestSrcAddressingIndex: Int32\nvar MPSTextureLinkingConstantIndex: Int32\nvar MPSUserAvailableFunctionConstantStartIndex: Int32\nvar MPSUserConstantIndex: Int32"
  },
  {
    "title": "writeBytes(_:dataLayout:imageIndex:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/2867189-writebytes",
    "html": "See Also\nMethods to Read and Write Raw Data\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nstruct MPSImageReadWriteParams\nParameters that control reading and writing of a particular set of feature channels.\nenum MPSDataLayout\nOptions that define how buffer data is arranged."
  },
  {
    "title": "MetalPerformanceShaders Functions | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/metalperformanceshaders_functions",
    "html": "Topics\nFunctions\nfunc MPSFindIntegerDivisionParams(UInt16) -> MPSIntegerDivisionParams\nReturns the integer division parameters for a specified divisor.\nfunc MPSGetCustomKernelBatchedDestinationIndex(MPSCustomKernelArgumentCount) -> UInt\nReturns the index of the first destination texture argument.\nfunc MPSGetCustomKernelBatchedSourceIndex(MPSCustomKernelArgumentCount, UInt, UInt) -> UInt\nReturns the index of the specified batched source texture argument.\nfunc MPSGetCustomKernelBroadcastSourceIndex(MPSCustomKernelArgumentCount, UInt, UInt) -> UInt\nReturns the index of the specified nonbatched source texture argument.\nfunc MPSGetCustomKernelMaxBatchSize(MPSCustomKernelArgumentCount, UInt) -> UInt\nReturns the maximum allowed batch size.\nfunc MPSGetImageType(MPSImage) -> MPSImageType\nfunc MPSGetPreferredDevice(MPSDeviceOptions) -> MTLDevice?\nfunc MPSHintTemporaryMemoryHighWaterMark(MTLCommandBuffer, Int)\nTriggers Metal Performance Shaders to prefetch a Metal heap of the indicated size into its internal cache.\nfunc MPSImageBatchIncrementReadCount([MPSImage], Int) -> Int\nIncrements or decrements the read count of an image batch by a specified amount.\nfunc MPSImageBatchIterate([MPSImage], (MPSImage, Int) -> Int) -> Int\nExecutes a callback block once for each unique image in a batch.\nfunc MPSImageBatchResourceSize([MPSImage]) -> Int\nReturns the number of bytes used to allocate the specified image batch.\nfunc MPSImageBatchSynchronize([MPSImage], MTLCommandBuffer)\nRemoves any copy of the specified image batch from the device's caches, and, if needed, invalidates any CPU caches.\nfunc MPSSetHeapCacheDuration(MTLCommandBuffer, Double)\nSets the timeout after which unused cached Metal heaps are released.\nfunc MPSSizeofMPSDataType(MPSDataType) -> Int\nfunc MPSStateBatchIncrementReadCount([MPSState]?, Int) -> Int\nIncrements or decrements the read count of a state batch by a specified amount.\nfunc MPSStateBatchResourceSize([MPSState]?) -> Int\nReturns the number of bytes used to allocate the specified state batch.\nfunc MPSStateBatchSynchronize([MPSState], MTLCommandBuffer)\nRemoves any copy of the specified state batch from the device's caches, and, if needed, invalidates any CPU caches."
  },
  {
    "title": "MetalPerformanceShaders Enumerations | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/metalperformanceshaders_enumerations",
    "html": "Topics\nEnumerations\nenum MPSAccelerationStructureStatus\nConstants that indicate an acceleration structure build state.\nDeprecated\nenum MPSBoundingBoxIntersectionTestType\nOptions for the intersection test type for a ray intersector bounding box.\nDeprecated\nenum MPSCNNConvolutionWeightsLayout\nenum MPSCNNLossType\nConstants that indicate supported loss filter types.\nenum MPSCNNReductionType\nConstants that indicate supported reduction types.\nenum MPSCNNWeightsQuantizationType\nOptions that specify the type of quantization used to generate unsigned integer weights.\nenum MPSFloatDataTypeBit\nenum MPSFloatDataTypeShift\nenum MPSIntersectionDataType\nOptions that determine the data contained in an intersection result.\nenum MPSIntersectionType\nOptions that determine an intersection type for a ray intersector.\nenum MPSNNRegularizationType\nOptions that define the regularization type.\nenum MPSPolygonType\nDeprecated\nenum MPSRNNMatrixId\nOptions that define which matrix is copied in or out of a trainable RNN layer.\nenum MPSRayDataType\nOptions for the data type for an intersector ray.\nenum MPSRayMaskOperator\nDeprecated\nenum MPSStateResourceType\nOptions for the underlying resource type for a state object.\nenum MPSTemporalWeighting\nenum MPSTransformType\nConstants that indicate instance transformation types.\nenum MPSTriangleIntersectionTestType\nOptions for the ray-triangle intersection test.\nDeprecated"
  },
  {
    "title": "MPSNNLossCallback | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnlosscallback",
    "html": "Topics\nInstance Methods\nfunc scalarWeight(forSourceImage: MPSImage, destinationImage: MPSImage) -> Float\n\nRequired\n\nRelationships\nInherits From\nNSCopying\nNSObjectProtocol\nNSSecureCoding"
  },
  {
    "title": "writeBytes(_:dataLayout:bytesPerRow:region:featureChannelInfo:imageIndex:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/2867055-writebytes",
    "html": "See Also\nMethods to Read and Write Raw Data\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nstruct MPSImageReadWriteParams\nParameters that control reading and writing of a particular set of feature channels.\nenum MPSDataLayout\nOptions that define how buffer data is arranged."
  },
  {
    "title": "init(texture:featureChannels:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/2097547-init",
    "html": "Parameters\ntexture\n\nThe texture allocated by the user to be used as a backing storage for the image.\n\nfeatureChannels\n\nThe number of feature channels the texture contains.\n\nReturn Value\n\nA valid MPSImage object or nil, if failure.\n\nDiscussion\n\nIn a memory-intensive app, you can save memory (and allocation/deallocation time) by using an MPSTemporaryImage object, where the framework aggressively reuses underlying texture memory within the same command buffer. However, in certain cases, you may want more control on the allocation, placement, reuse, and recycling of memory-backing textures used in your app by using the Metal Resource Heaps API. In this case, an app can create an MPSImage object from a pre-allocated texture by calling this method.\n\nThe textureType property of the given texture can be of type MTLTextureType.type2D only if featureChannels<=4 (meaning that numberOfImages=1). Otherwise, the texture type should be MTLTextureType.type2DArray with the arrayLength property of the given texture being equal to numberOfImages*((featureChannels+3)/4).\n\nFor textures containing typical image data, the featureChannels parameter should be set to the number of valid color channels (e.g. for RGB data, even though the pixel format is a form of MTLPixelFormatRGBA, featureChannels should be set to 3.)."
  },
  {
    "title": "readBytes(_:dataLayout:imageIndex:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/2867188-readbytes",
    "html": "See Also\nMethods to Read and Write Raw Data\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nstruct MPSImageReadWriteParams\nParameters that control reading and writing of a particular set of feature channels.\nenum MPSDataLayout\nOptions that define how buffer data is arranged."
  },
  {
    "title": "MPSHeapProvider | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsheapprovider",
    "html": "Topics\nInstance Methods\nfunc newHeap(with: MTLHeapDescriptor) -> MTLHeap?\n\nRequired\n\nfunc retire(MTLHeap, cacheDelay: Double)\nRelationships\nInherits From\nNSObjectProtocol"
  },
  {
    "title": "MPSNNGramMatrixCallback | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngrammatrixcallback",
    "html": "Topics\nInstance Methods\nfunc alpha(forSourceImage: MPSImage, destinationImage: MPSImage) -> Float\n\nRequired\n\nRelationships\nInherits From\nNSCopying\nNSObjectProtocol\nNSSecureCoding"
  },
  {
    "title": "MPSCNNGroupNormalizationDataSource | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationdatasource",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder)\n\nRequired\n\nInstance Properties\nvar numberOfFeatureChannels: Int\n\nRequired\n\nvar numberOfGroups: Int\n\nRequired\n\nType Properties\nstatic var supportsSecureCoding: Bool\n\nRequired\n\nInstance Methods\nfunc beta() -> UnsafeMutablePointer<Float>?\n\nRequired\n\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(with: NSCoder)\nfunc epsilon() -> Float\nfunc gamma() -> UnsafeMutablePointer<Float>?\n\nRequired\n\nfunc label() -> String?\n\nRequired\n\nfunc updateGammaAndBeta(with: MTLCommandBuffer, groupNormalizationStateBatch: [MPSCNNGroupNormalizationGradientState]) -> MPSCNNNormalizationGammaAndBetaState?\nfunc updateGammaAndBeta(withGroupNormalizationStateBatch: [MPSCNNGroupNormalizationGradientState]) -> Bool\nRelationships\nInherits From\nNSCopying\nNSObjectProtocol"
  },
  {
    "title": "MPSNDArrayAllocator | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarrayallocator",
    "html": "Topics\nInstance Methods\nfunc array(for: MTLCommandBuffer, arrayDescriptor: MPSNDArrayDescriptor, kernel: MPSKernel) -> MPSNDArray\n\nRequired\n\nRelationships\nInherits From\nNSCopying\nNSObjectProtocol\nNSSecureCoding"
  },
  {
    "title": "MPSTemporaryNDArray | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporaryndarray",
    "html": "Topics\nInitializers\ninit(commandBuffer: MTLCommandBuffer, descriptor: MPSNDArrayDescriptor)\nInstance Properties\nvar readCount: Int\nType Methods\nclass func defaultAllocator() -> MPSNDArrayAllocator\nRelationships\nInherits From\nMPSNDArray"
  },
  {
    "title": "MPSSVGFDefaultTextureAllocator | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpssvgfdefaulttextureallocator",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nInstance Properties\nvar allocatedTextureCount: Int\nvar device: MTLDevice\nInstance Methods\nfunc reset()\nfunc `return`(MTLTexture)\nfunc texture(with: MTLPixelFormat, width: Int, height: Int) -> MTLTexture?\nRelationships\nInherits From\nNSObject\nConforms To\nMPSSVGFTextureAllocator"
  },
  {
    "title": "MPSNNReductionFeatureChannelsArgumentMinNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionfeaturechannelsargumentminnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSSVGFDenoiser | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpssvgfdenoiser",
    "html": "Topics\nInitializers\ninit(SVGF: MPSSVGF, textureAllocator: MPSSVGFTextureAllocator)\ninit(device: MTLDevice)\nInstance Properties\nvar bilateralFilterIterations: Int\nvar svgf: MPSSVGF\nvar textureAllocator: MPSSVGFTextureAllocator\nInstance Methods\nfunc clearTemporalHistory()\nfunc encode(commandBuffer: MTLCommandBuffer, sourceTexture: MTLTexture, destinationTexture: AutoreleasingUnsafeMutablePointer<MTLTexture>, sourceTexture2: MTLTexture?, destinationTexture2: AutoreleasingUnsafeMutablePointer<MTLTexture>?, motionVectorTexture: MTLTexture?, depthNormalTexture: MTLTexture, previousDepthNormalTexture: MTLTexture?)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceTexture: MTLTexture, motionVectorTexture: MTLTexture?, depthNormalTexture: MTLTexture, previousDepthNormalTexture: MTLTexture?) -> MTLTexture\nfunc releaseTemporaryTextures()\nRelationships\nInherits From\nNSObject"
  },
  {
    "title": "MPSNNReductionColumnSumNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductioncolumnsumnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSCNNConvolutionNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutionnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, weights: MPSCNNConvolutionDataSource)\nprotocol MPSCNNConvolutionDataSource\nThe protocol that provides convolution filter weights and bias terms.\nInstance Properties\nvar accumulatorPrecision: MPSNNConvolutionAccumulatorPrecisionOption\nvar convolutionGradientState: MPSCNNConvolutionGradientStateNode?\nvar trainingStyle: MPSNNTrainingStyle\nRelationships\nInherits From\nMPSNNFilterNode\nConforms To\nMPSNNTrainableNode\nSee Also\nConvolution Layer Nodes\nclass MPSCNNBinaryConvolutionNode\nA representation of a convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolutionTransposeNode\nA representation of a transposed convolution.\nclass MPSCNNConvolutionGradientNode\nA representation of a gradient convolution kernel.\nclass MPSCNNConvolutionGradientStateNode\nA representation of a gradient convolution state.\nclass MPSCNNCrossChannelNormalizationGradientNode\nA representation of a gradient normalization kernel applied across feature channels."
  },
  {
    "title": "MPSNNFilterNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnfilternode",
    "html": "Topics\nInstance Properties\nvar label: String?\nvar paddingPolicy: MPSNNPadding\nprotocol MPSNNPadding\nThe protocol that provides a description of how kernels should pad images.\nvar resultImage: MPSNNImageNode\nvar resultState: MPSNNStateNode?\nvar resultStates: [MPSNNStateNode]?\nclass MPSNNStateNode\nA placeholder node denoting the position in the graph of a state object.\nclass MPSNNBinaryGradientStateNode\nA representation of the state created to record the properties of a binary gradient kernel.\nclass MPSNNGradientStateNode\nA representation of the state created to record the properties of a gradient kernel at the time it was encoded.\nInstance Methods\nfunc gradientFilter(withSource: MPSNNImageNode) -> MPSNNGradientFilterNode\nfunc gradientFilter(withSources: [MPSNNImageNode]) -> MPSNNGradientFilterNode\nfunc gradientFilters(withSource: MPSNNImageNode) -> [MPSNNGradientFilterNode]\nfunc gradientFilters(withSources: [MPSNNImageNode]) -> [MPSNNGradientFilterNode]\nfunc trainingGraph(withSourceGradient: MPSNNImageNode?, nodeHandler: MPSGradientNodeBlock?) -> [MPSNNFilterNode]?\nRelationships\nInherits From\nNSObject\nSee Also\nFilter Node Base Classes\nclass MPSNNGradientFilterNode\nA representation of a gradient filter."
  },
  {
    "title": "MPSNNStateNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnstatenode",
    "html": "Topics\nInstance Properties\nvar handle: MPSHandle?\nvar exportFromGraph: Bool\nvar synchronizeResource: Bool\nRelationships\nInherits From\nNSObject"
  },
  {
    "title": "MPSNNBinaryArithmeticNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnbinaryarithmeticnode",
    "html": "Topics\nInitializers\ninit(leftSource: MPSNNImageNode, rightSource: MPSNNImageNode)\ninit(sources: [MPSNNImageNode])\nInstance Properties\nvar bias: Float\nvar maximumValue: Float\nvar minimumValue: Float\nvar primaryScale: Float\nvar primaryStrideInFeatureChannels: Int\nvar primaryStrideInPixelsX: Int\nvar primaryStrideInPixelsY: Int\nvar secondaryScale: Float\nvar secondaryStrideInFeatureChannels: Int\nvar secondaryStrideInPixelsX: Int\nvar secondaryStrideInPixelsY: Int\nInstance Methods\nfunc gradientClass() -> AnyClass\nfunc gradientFilters(withSources: [MPSNNImageNode]) -> [MPSNNGradientFilterNode]\nRelationships\nInherits From\nMPSNNFilterNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSNNArithmeticGradientStateNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnarithmeticgradientstatenode",
    "html": "Relationships\nInherits From\nMPSNNBinaryGradientStateNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators."
  },
  {
    "title": "MPSNNDivisionNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnndivisionnode",
    "html": "Relationships\nInherits From\nMPSNNBinaryArithmeticNode\nSee Also\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators."
  },
  {
    "title": "MPSNNInitialGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnninitialgradientnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSNNFilterNode"
  },
  {
    "title": "MPSNNGramMatrixCalculationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngrammatrixcalculationnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\ninit(source: MPSNNImageNode, alpha: Float)\nInstance Properties\nvar alpha: Float\nvar propertyCallBack: MPSNNGramMatrixCallback?\nRelationships\nInherits From\nMPSNNFilterNode"
  },
  {
    "title": "MPSNDArrayStridedSlice | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraystridedslice",
    "html": "Topics\nInstance Properties\nvar strides: MPSNDArrayOffsets\nRelationships\nInherits From\nMPSNDArrayUnaryKernel"
  },
  {
    "title": "MPSNDArrayMultiaryKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraymultiarykernel",
    "html": "Topics\nInitializers\ninit(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, sourceCount: Int)\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceArrays: [MPSNDArray]) -> MPSNDArray\nfunc encode(to: MTLCommandBuffer, sourceArrays: [MPSNDArray], destinationArray: MPSNDArray)\nfunc encode(to: MTLCommandBuffer, sourceArrays: [MPSNDArray], resultState: MPSState?, destinationArray: MPSNDArray)\nfunc encode(to: MTLCommandBuffer, sourceArrays: [MPSNDArray], resultState: AutoreleasingUnsafeMutablePointer<MPSState?>?, outputStateIsTemporary: Bool) -> MPSNDArray\nRelationships\nInherits From\nMPSNDArrayMultiaryBase"
  },
  {
    "title": "MPSImageEDLines | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageedlines",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, gaussianSigma: Float, minLineLength: UInt16, maxLines: Int, detailRatio: UInt16, gradientThreshold: Float, lineErrorThreshold: Float, mergeLocalityThreshold: Float)\nInstance Properties\nvar clipRectSource: MTLRegion\nvar detailRatio: UInt16\nvar gaussianSigma: Float\nvar gradientThreshold: Float\nvar lineErrorThreshold: Float\nvar maxLines: Int\nvar mergeLocalityThreshold: Float\nvar minLineLength: UInt16\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceTexture: MTLTexture, destinationTexture: MTLTexture?, endpointBuffer: MTLBuffer, endpointOffset: Int)\nRelationships\nInherits From\nMPSKernel"
  },
  {
    "title": "MPSCNNNeuronGeLUNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnneurongelunode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\nRelationships\nInherits From\nMPSCNNNeuronNode"
  },
  {
    "title": "MPSCNNFullyConnectedGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnfullyconnectedgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, convolutionGradientState: MPSCNNConvolutionGradientStateNode, weights: MPSCNNConvolutionDataSource?)\nRelationships\nInherits From\nMPSCNNConvolutionGradientNode"
  },
  {
    "title": "MPSPolygonBuffer | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpspolygonbuffer",
    "html": "Topics\nInitializers\ninit()\ninit?(coder: NSCoder)\nInstance Properties\nvar indexBuffer: MTLBuffer?\nvar indexBufferOffset: Int\nvar maskBuffer: MTLBuffer?\nvar maskBufferOffset: Int\nvar polygonCount: Int\nvar vertexBuffer: MTLBuffer?\nvar vertexBufferOffset: Int\nInstance Methods\nfunc copy(with: NSZone?) -> Self\nRelationships\nInherits From\nNSObject\nConforms To\nNSCopying\nNSSecureCoding"
  },
  {
    "title": "MPSSVGF | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpssvgf",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar bilateralFilterRadius: Int\nvar bilateralFilterSigma: Float\nvar channelCount: Int\nvar channelCount2: Int\nvar depthWeight: Float\nvar luminanceWeight: Float\nvar minimumFramesForVarianceEstimation: Int\nvar normalWeight: Float\nvar reprojectionThreshold: Float\nvar temporalReprojectionBlendFactor: Float\nvar temporalWeighting: MPSTemporalWeighting\nvar varianceEstimationRadius: Int\nvar varianceEstimationSigma: Float\nvar variancePrefilterRadius: Int\nvar variancePrefilterSigma: Float\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(with: NSCoder)\nfunc encodeBilateralFilter(to: MTLCommandBuffer, stepDistance: Int, sourceTexture: MTLTexture, destinationTexture: MTLTexture, depthNormalTexture: MTLTexture)\nfunc encodeBilateralFilter(to: MTLCommandBuffer, stepDistance: Int, sourceTexture: MTLTexture, destinationTexture: MTLTexture, sourceTexture2: MTLTexture?, destinationTexture2: MTLTexture?, depthNormalTexture: MTLTexture)\nfunc encodeReprojection(to: MTLCommandBuffer, sourceTexture: MTLTexture, previousTexture: MTLTexture, destinationTexture: MTLTexture, previousLuminanceMomentsTexture: MTLTexture, destinationLuminanceMomentsTexture: MTLTexture, previousFrameCount: MTLTexture, destinationFrameCount: MTLTexture, motionVectorTexture: MTLTexture?, depthNormalTexture: MTLTexture?, previousDepthNormalTexture: MTLTexture?)\nfunc encodeReprojection(to: MTLCommandBuffer, sourceTexture: MTLTexture, previousTexture: MTLTexture, destinationTexture: MTLTexture, previousLuminanceMomentsTexture: MTLTexture, destinationLuminanceMomentsTexture: MTLTexture, sourceTexture2: MTLTexture?, previousTexture2: MTLTexture?, destinationTexture2: MTLTexture?, previousLuminanceMomentsTexture2: MTLTexture?, destinationLuminanceMomentsTexture2: MTLTexture?, previousFrameCount: MTLTexture, destinationFrameCount: MTLTexture, motionVectorTexture: MTLTexture?, depthNormalTexture: MTLTexture?, previousDepthNormalTexture: MTLTexture?)\nfunc encodeVarianceEstimation(to: MTLCommandBuffer, sourceTexture: MTLTexture, luminanceMomentsTexture: MTLTexture, destinationTexture: MTLTexture, frameCount: MTLTexture, depthNormalTexture: MTLTexture?)\nfunc encodeVarianceEstimation(to: MTLCommandBuffer, sourceTexture: MTLTexture, luminanceMomentsTexture: MTLTexture, destinationTexture: MTLTexture, sourceTexture2: MTLTexture?, luminanceMomentsTexture2: MTLTexture?, destinationTexture2: MTLTexture?, frameCount: MTLTexture, depthNormalTexture: MTLTexture?)\nRelationships\nInherits From\nMPSKernel\nConforms To\nNSCopying\nNSSecureCoding"
  },
  {
    "title": "MPSTriangleAccelerationStructure | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstriangleaccelerationstructure",
    "html": "Topics\nInstance Properties\nvar triangleCount: Int\nRelationships\nInherits From\nMPSPolygonAccelerationStructure\nSee Also\nRay Tracing\nAnimating and Denoising a Raytraced Scene\nSupport dynamic scenes and denoising by extending your ray tracer with Metal Performance Shaders.\nclass MPSRayIntersector\nA kernel that performs intersection tests between rays and geometry.\nDeprecated\nclass MPSAccelerationStructureGroup\nA group of acceleration structures.\nDeprecated\nclass MPSInstanceAccelerationStructure\nAn acceleration structure built over instances of other acceleration structures.\nDeprecated\nclass MPSAccelerationStructure\nThe base class for data structures that are built over geometry and used to accelerate ray tracing.\nDeprecated"
  },
  {
    "title": "MPSCNNConvolutionTransposeGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiontransposegradientstate",
    "html": "Topics\nInstance Properties\nvar convolutionTranspose: MPSCNNConvolutionTranspose\nRelationships\nInherits From\nMPSCNNConvolutionGradientState"
  },
  {
    "title": "MPSPredicate | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpspredicate",
    "html": "Topics\nInitializers\ninit(buffer: MTLBuffer, offset: Int)\ninit(device: MTLDevice)\nInstance Properties\nvar predicateBuffer: MTLBuffer\nvar predicateOffset: Int\nRelationships\nInherits From\nNSObject"
  },
  {
    "title": "MPSCNNConvolutionTransposeGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiontransposegradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, weights: MPSCNNConvolutionDataSource)\nInstance Properties\nvar dataSource: MPSCNNConvolutionDataSource\nvar gradientOption: MPSCNNConvolutionGradientOption\nvar groups: Int\nvar sourceGradientFeatureChannels: Int\nvar sourceImageFeatureChannels: Int\nInstance Methods\nfunc reloadWeightsAndBiases(with: MTLCommandBuffer, state: MPSCNNConvolutionWeightsAndBiasesState)\nfunc reloadWeightsAndBiasesFromDataSource()\nRelationships\nInherits From\nMPSCNNGradientKernel"
  },
  {
    "title": "MPSPolygonAccelerationStructure | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpspolygonaccelerationstructure",
    "html": "Topics\nInstance Properties\nvar indexBuffer: MTLBuffer?\nvar indexBufferOffset: Int\nvar indexType: MPSDataType\nvar maskBuffer: MTLBuffer?\nvar maskBufferOffset: Int\nvar polygonBuffers: [MPSPolygonBuffer]?\nvar polygonCount: Int\nvar polygonType: MPSPolygonType\nvar vertexBuffer: MTLBuffer?\nvar vertexBufferOffset: Int\nvar vertexStride: Int\nRelationships\nInherits From\nMPSAccelerationStructure"
  },
  {
    "title": "MPSNNUnaryReductionNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnunaryreductionnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode)\nInstance Properties\nvar clipRectSource: MTLRegion\nRelationships\nInherits From\nMPSNNFilterNode"
  },
  {
    "title": "MPSQuadrilateralAccelerationStructure | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsquadrilateralaccelerationstructure",
    "html": "Topics\nInstance Properties\nvar quadrilateralCount: Int\nRelationships\nInherits From\nMPSPolygonAccelerationStructure"
  },
  {
    "title": "MPSNNReductionSpatialMeanGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionspatialmeangradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\nRelationships\nInherits From\nMPSNNGradientFilterNode"
  },
  {
    "title": "MPSDeviceProvider | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsdeviceprovider",
    "html": "Topics\nInstance Methods\nfunc mpsMTLDevice() -> MTLDevice!\n\nRequired\n\nRelationships\nConforming Types\nMPSKeyedUnarchiver\nSee Also\nKeyed Archivers\nclass NSKeyedArchiver\nAn encoder that stores an object’s data to an archive referenced by keys.\nclass MPSKeyedUnarchiver\nA keyed archiver that supports Metal Performance Shaders kernel decoding."
  },
  {
    "title": "MPSNNReshapeNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreshapenode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, resultWidth: Int, resultHeight: Int, resultFeatureChannels: Int)\nRelationships\nInherits From\nMPSNNFilterNode"
  },
  {
    "title": "MPSNNReshapeGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreshapegradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNGradientKernel"
  },
  {
    "title": "MPSNNReductionFeatureChannelsSumNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionfeaturechannelssumnode",
    "html": "Topics\nInstance Properties\nvar weight: Float\nRelationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReductionRowMaxNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionrowmaxnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReductionRowMeanNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionrowmeannode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReductionRowMinNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionrowminnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReshapeGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreshapegradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\nRelationships\nInherits From\nMPSNNGradientFilterNode"
  },
  {
    "title": "MPSNNReductionRowSumNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionrowsumnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReductionFeatureChannelsMinNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionfeaturechannelsminnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReductionFeatureChannelsMaxNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionfeaturechannelsmaxnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReductionFeatureChannelsMeanNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionfeaturechannelsmeannode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "width | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648884-width",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "height | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648952-height",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "device | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648857-device",
    "html": "See Also\nProperties\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "numberOfImages | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648900-numberofimages",
    "html": "See Also\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object."
  },
  {
    "title": "MPSDataLayout | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsdatalayout",
    "html": "Topics\nEnumeration Cases\ncase featureChannelsxHeightxWidth\ncase HeightxWidthxFeatureChannels\nRelationships\nConforms To\nSendable\nSee Also\nMethods to Read and Write Raw Data\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nstruct MPSImageReadWriteParams\nParameters that control reading and writing of a particular set of feature channels."
  },
  {
    "title": "MPSImageAllocator | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimageallocator",
    "html": "Topics\nInstance Methods\nfunc image(for: MTLCommandBuffer, imageDescriptor: MPSImageDescriptor, kernel: MPSKernel) -> MPSImage\n\nRequired\n\nfunc imageBatch(for: MTLCommandBuffer, imageDescriptor: MPSImageDescriptor, kernel: MPSKernel, count: Int) -> [MPSImage]\nRelationships\nInherits From\nNSObjectProtocol\nNSSecureCoding\nSee Also\nMethods to Get an Image Allocator\nclass func defaultAllocator() -> MPSImageAllocator"
  },
  {
    "title": "defaultAllocator() | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/2867148-defaultallocator",
    "html": "See Also\nMethods to Get an Image Allocator\nprotocol MPSImageAllocator"
  },
  {
    "title": "MetalPerformanceShaders Data Types | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/metalperformanceshaders_data_types",
    "html": "Topics\nData Types\ntypealias MPSAccelerationStructureCompletionHandler\nA block of code that's invoked when an operation on an acceleration structure has completed.\nDeprecated\ntypealias MPSAxisAlignedBoundingBox\nAn axis-aligned bounding box.\ntypealias MPSDeviceCaps\ntypealias MPSFunctionConstant\ntypealias MPSFunctionConstantInMetal\ntypealias MPSGradientNodeBlock\ntypealias MPSPackedFloat3\nA packed three-element vector."
  },
  {
    "title": "MPSNNGraph | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngraph",
    "html": "Overview\n\nOnce you have prepared a graph of MPSNNImageNode, MPSNNFilterNode, and, if needed, MPSNNStateNode objects, you may initialize a MPSNNGraph using the image node that you wish to appear as the result. The graph object will introspect the graph representation and determine which nodes are needed for inputs, and which nodes are produced as output state (if any). Nodes which are not needed to calculate the result image node are ignored. Some nodes may be internally concatenated with other nodes for better performance.\n\nNote\n\nThe MPSNNImageNode that you choose as the result node may be interior to a graph. This feature is provided as a means to examine intermediate computations in the full graph for debugging purposes.\n\nDuring MPSNNGraph construction, the graph attached to the result node will be parsed and reduced to an optimized representation. This representation may be saved using the NSSecureCoding protocol for later recall.\n\nWhen decoding a MPSNNGraph using a NSCoder, it will be created against the system default MTLDevice. If you would like to set the device, your NSCoder should conform to the MPSDeviceProvider protocol.\n\nDebugging Tips\n\nIn typical usage, some refinement, especially of padding policies, may be required to get the expected answer from Metal Performance Shaders. If the result image is the wrong size, padding is typically the problem. When the answers are incorrect, the offset or other property may be incorrectly configured at some stage. As the graph is generated starting from an output image node, you may create other graphs starting at any image node within the graph. This will give you a view into the result produced from each intermediate layer with a minimum of fuss. In addition, the usual debugDescription() method is available to inspect objects to make sure they conform to expectation.\n\nNote that certain operations such as neuron filters that follow convolution filters and image concatenation may be optimized away by the MPSNNGraph when it is constructed. The convolution can do neuron operations as part of its operation. Concatenation is best done by writing the result of earlier filter passes in the right place using destinationFeatureChannelOffset rather than by adding an extra copy. Other optimizations may be added as framework capabilities improve.\n\nTopics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit?(device: MTLDevice, resultImage: MPSNNImageNode)\nDeprecated\ninit?(device: MTLDevice, resultImage: MPSNNImageNode, resultImageIsNeeded: Bool)\ninit?(device: MTLDevice, resultImages: [MPSNNImageNode], resultsAreNeeded: UnsafeMutablePointer<ObjCBool>?)\nInstance Properties\nvar destinationImageAllocator: MPSImageAllocator\nprotocol MPSImageAllocator\nvar intermediateImageHandles: [MPSHandle]?\nvar outputStateIsTemporary: Bool\nvar resultHandle: MPSHandle?\nvar resultStateHandles: [MPSHandle]?\nvar sourceImageHandles: [MPSHandle]\nvar sourceStateHandles: [MPSHandle]?\nvar format: MPSImageFeatureChannelFormat\nvar resultImageIsNeeded: Bool\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceImages: [MPSImage]) -> MPSImage?\nfunc encode(to: MTLCommandBuffer, sourceImages: [MPSImage], sourceStates: [MPSState]?, intermediateImages: NSMutableArray?, destinationStates: NSMutableArray?) -> MPSImage?\nclass MPSState\nAn opaque data container for large storage in MPS CNN filters.\nclass MPSNNBinaryGradientState\nA class representing the state of a gradient binary kernel when it was encoded.\nclass MPSNNGradientState\nA class representing the state of a gradient kernel when it was encoded.\nfunc executeAsync(withSourceImages: [MPSImage], completionHandler: MPSNNGraphCompletionHandler) -> MPSImage\ntypealias MPSNNGraphCompletionHandler\nA notification when an asynchronous graph execution has finished.\nfunc encodeBatch(to: MTLCommandBuffer, sourceImages: [[MPSImage]], sourceStates: [[MPSState]]?) -> [MPSImage]?\nfunc encodeBatch(to: MTLCommandBuffer, sourceImages: [[MPSImage]], sourceStates: [[MPSState]]?, intermediateImages: NSMutableArray?, destinationStates: NSMutableArray?) -> [MPSImage]?\nfunc readCountForSourceImage(at: Int) -> Int\nfunc readCountForSourceState(at: Int) -> Int\nfunc reloadFromDataSources()\nRelationships\nInherits From\nMPSKernel\nConforms To\nNSCopying\nNSSecureCoding\nSee Also\nNeural Network Graphs\nclass MPSNNImageNode\nA placeholder node denoting the position of a neural network image in a graph.\nprotocol MPSHandle\nThe protocol that provides resource identification."
  },
  {
    "title": "readBytes(_:dataLayout:bytesPerRow:region:featureChannelInfo:imageIndex:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/2867105-readbytes",
    "html": "See Also\nMethods to Read and Write Raw Data\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nstruct MPSImageReadWriteParams\nParameters that control reading and writing of a particular set of feature channels.\nenum MPSDataLayout\nOptions that define how buffer data is arranged."
  },
  {
    "title": "MPSPurgeableState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpspurgeablestate",
    "html": "Topics\nConstants\ncase allocationDeferred\nThe image’s underlying texture hasn’t been allocated yet. Attempts to set another purgeable state using the setPurgeableState(_:) method will be ignored.\ncase keepCurrent\nEquivalent to the MTLPurgeableState.keepCurrent value.\ncase nonVolatile\nEquivalent to the MTLPurgeableState.nonVolatile value.\ncase volatile\nEquivalent to the MTLPurgeableState.volatile value.\ncase empty\nEquivalent to the MTLPurgeableState.empty value.\nRelationships\nConforms To\nSendable\nSee Also\nMethods\nfunc setPurgeableState(MPSPurgeableState) -> MPSPurgeableState\nSet (or query) the purgeable state of the image’s underlying texture."
  },
  {
    "title": "MPSImageDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagedescriptor",
    "html": "Overview\n\nYou use an MPSImageDescriptor to describe and create the properties of an MPSImage such as its size, pixel format and CPU cache mode.\n\nTopics\nMethods\ninit(channelFormat: MPSImageFeatureChannelFormat, width: Int, height: Int, featureChannels: Int)\nCreates an image descriptor for a single image.\ninit(channelFormat: MPSImageFeatureChannelFormat, width: Int, height: Int, featureChannels: Int, numberOfImages: Int, usage: MTLTextureUsage)\nCreates an image descriptor for an image container with options to set texture usage and batch size (number of images).\nProperties\nvar width: Int\nThe width of the image.\nvar height: Int\nThe height of the image.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar pixelFormat: MTLPixelFormat\nThe pixel format for the underlying texture.\nvar channelFormat: MPSImageFeatureChannelFormat\nThe storage format to use for each channel in the image.\nvar cpuCacheMode: MTLCPUCacheMode\nThe CPU cache mode of the underlying texture.\nvar storageMode: MTLStorageMode\nThe storage mode of underlying texture.\nvar usage: MTLTextureUsage\nOptions to specify the intended usage of the underlying texture.\nInstance Methods\nfunc copy(with: NSZone?) -> Self\nRelationships\nInherits From\nNSObject\nConforms To\nNSCopying"
  },
  {
    "title": "setPurgeableState(_:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648820-setpurgeablestate",
    "html": "Parameters\nstate\n\nThe desired purgeable state of the image’s underlying texture.\n\nReturn Value\n\nReturns the prior purgeable state of the image’s underlying texture.\n\nDiscussion\n\nThis method behaves the same as the setPurgeableState(_:) method of the MTLResource class, except that the state might be MPSPurgeableState.allocationDeferred, which means there is no underlying texture to mark as volatile or non-volatile. Attempts to set a purgeable state on MTLTexture objects that have not yet been allocated will be ignored.\n\nSee Also\nMethods\nenum MPSPurgeableState\nThe purgeable state of an image’s underlying texture."
  },
  {
    "title": "init(device:imageDescriptor:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage/1648920-init",
    "html": "Parameters\ndevice\n\nThe device on which the image will be used.\n\nimageDescriptor\n\nThe image descriptor.\n\nReturn Value\n\nA valid MPSImage object or nil, if failure.\n\nDiscussion\n\nStorage for the image data is allocated lazily on the first use of the MPSImage object, or when the texture property is first read."
  },
  {
    "title": "MPSNNReductionFeatureChannelsArgumentMaxNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductionfeaturechannelsargumentmaxnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReductionColumnMinNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductioncolumnminnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReductionColumnMeanNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductioncolumnmeannode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNReductionColumnMaxNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnreductioncolumnmaxnode",
    "html": "Relationships\nInherits From\nMPSNNUnaryReductionNode"
  },
  {
    "title": "MPSNNPadGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnpadgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\nRelationships\nInherits From\nMPSNNGradientFilterNode"
  },
  {
    "title": "MPSNNPadNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnpadnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, paddingSizeBefore: MPSImageCoordinate, paddingSizeAfter: MPSImageCoordinate, edgeMode: MPSImageEdgeMode)\nInstance Properties\nvar fillValue: Float\nRelationships\nInherits From\nMPSNNFilterNode"
  },
  {
    "title": "MPSNNPadGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnpadgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNGradientKernel"
  },
  {
    "title": "MPSNNPad | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnpad",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\ninit(device: MTLDevice, paddingSizeBefore: MPSImageCoordinate, paddingSizeAfter: MPSImageCoordinate)\ninit(device: MTLDevice, paddingSizeBefore: MPSImageCoordinate, paddingSizeAfter: MPSImageCoordinate, fillValueArray: Data?)\nInstance Properties\nvar fillValue: Float\nvar paddingSizeAfter: MPSImageCoordinate\nvar paddingSizeBefore: MPSImageCoordinate\nRelationships\nInherits From\nMPSCNNKernel"
  },
  {
    "title": "MPSNNMultiaryGradientStateNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnmultiarygradientstatenode",
    "html": "Relationships\nInherits From\nMPSNNStateNode"
  },
  {
    "title": "MPSNNLossGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnlossgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, labels: MPSNNImageNode, gradientState: MPSNNGradientStateNode?, lossDescriptor: MPSCNNLossDescriptor, isLabelsGradientFilter: Bool)\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, labels: MPSNNImageNode, weights: MPSNNImageNode?, gradientState: MPSNNGradientStateNode?, lossDescriptor: MPSCNNLossDescriptor, isLabelsGradientFilter: Bool)\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, labels: MPSNNImageNode, weights: MPSNNImageNode, gradientState: MPSNNGradientStateNode?, lossDescriptor: MPSCNNLossDescriptor, isLabelsGradientFilter: Bool)\ninit(sources: [MPSNNImageNode], gradientState: MPSNNGradientStateNode?, lossDescriptor: MPSCNNLossDescriptor, isLabelsGradientFilter: Bool)\nInstance Properties\nvar delta: Float\nvar epsilon: Float\nvar isLabelsGradientFilter: Bool\nvar labelSmoothing: Float\nvar lossType: MPSCNNLossType\nvar numberOfClasses: Int\nvar propertyCallBack: MPSNNLossCallback?\nvar reduceAcrossBatch: Bool\nvar reductionType: MPSCNNReductionType\nvar weight: Float\nRelationships\nInherits From\nMPSNNGradientFilterNode"
  },
  {
    "title": "MPSNNMultiaryGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnmultiarygradientstate",
    "html": "Relationships\nInherits From\nMPSState"
  },
  {
    "title": "MPSNNLossGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnlossgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, lossDescriptor: MPSCNNLossDescriptor)\nInstance Properties\nvar computeLabelGradients: Bool\nvar delta: Float\nvar epsilon: Float\nvar labelSmoothing: Float\nvar lossType: MPSCNNLossType\nvar numberOfClasses: Int\nvar reduceAcrossBatch: Bool\nvar reductionType: MPSCNNReductionType\nvar weight: Float\nInstance Methods\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceGradients: [MPSImage], sourceImages: [MPSImage], labels: [MPSImage], weights: [MPSImage]?, sourceStates: [MPSState]?) -> [MPSImage]\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceGradients: [MPSImage], sourceImages: [MPSImage], labels: [MPSImage], weights: [MPSImage]?, sourceStates: [MPSState]?, destinationGradients: [MPSImage])\nRelationships\nInherits From\nMPSCNNBinaryKernel"
  },
  {
    "title": "MPSNNLocalCorrelation | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnlocalcorrelation",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\ninit(device: MTLDevice, windowInX: Int, windowInY: Int, strideInX: Int, strideInY: Int)\nInstance Properties\nvar strideInX: Int\nvar strideInY: Int\nvar windowInX: Int\nvar windowInY: Int\nRelationships\nInherits From\nMPSNNReduceBinary"
  },
  {
    "title": "MPSNNInitialGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnninitialgradient",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nRelationships\nInherits From\nMPSCNNKernel"
  },
  {
    "title": "MPSNNGramMatrixCalculationGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngrammatrixcalculationgradient",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\ninit(device: MTLDevice, alpha: Float)\nInstance Properties\nvar alpha: Float\nRelationships\nInherits From\nMPSCNNGradientKernel"
  },
  {
    "title": "MPSNNGramMatrixCalculationGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngrammatrixcalculationgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode, alpha: Float)\nInstance Properties\nvar alpha: Float\nRelationships\nInherits From\nMPSNNGradientFilterNode"
  },
  {
    "title": "MPSNNForwardLossNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnforwardlossnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, labels: MPSNNImageNode, lossDescriptor: MPSCNNLossDescriptor)\ninit(source: MPSNNImageNode, labels: MPSNNImageNode, weights: MPSNNImageNode?, lossDescriptor: MPSCNNLossDescriptor)\ninit(source: MPSNNImageNode, labels: MPSNNImageNode, weights: MPSNNImageNode, lossDescriptor: MPSCNNLossDescriptor)\ninit(sources: [MPSNNImageNode], lossDescriptor: MPSCNNLossDescriptor)\nInstance Properties\nvar delta: Float\nvar epsilon: Float\nvar labelSmoothing: Float\nvar lossType: MPSCNNLossType\nvar numberOfClasses: Int\nvar propertyCallBack: MPSNNLossCallback?\nvar reduceAcrossBatch: Bool\nvar reductionType: MPSCNNReductionType\nvar weight: Float\nInstance Methods\nfunc gradientFilter(withSource: MPSNNImageNode) -> MPSNNLossGradientNode\nfunc gradientFilter(withSources: [MPSNNImageNode]) -> MPSNNLossGradientNode\nfunc gradientFilters(withSource: MPSNNImageNode) -> [MPSNNLossGradientNode]\nfunc gradientFilters(withSources: [MPSNNImageNode]) -> [MPSNNLossGradientNode]\nRelationships\nInherits From\nMPSNNFilterNode"
  },
  {
    "title": "MPSNNGramMatrixCalculation | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnngrammatrixcalculation",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\ninit(device: MTLDevice, alpha: Float)\nInstance Properties\nvar alpha: Float\nRelationships\nInherits From\nMPSCNNKernel"
  },
  {
    "title": "MPSNNForwardLoss | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnnforwardloss",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, lossDescriptor: MPSCNNLossDescriptor)\nInstance Properties\nvar delta: Float\nvar epsilon: Float\nvar labelSmoothing: Float\nvar lossType: MPSCNNLossType\nvar numberOfClasses: Int\nvar reduceAcrossBatch: Bool\nvar reductionType: MPSCNNReductionType\nvar weight: Float\nInstance Methods\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], labels: [MPSImage], weights: [MPSImage]?, destinationStates: [MPSState]?, destinationImages: [MPSImage])\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], labels: [MPSImage], weights: [MPSImage]?, outStates: AutoreleasingUnsafeMutablePointer<NSArray?>?, isTemporary: Bool) -> [MPSImage]\nRelationships\nInherits From\nMPSCNNKernel"
  },
  {
    "title": "MPSNNCropAndResizeBilinear | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnncropandresizebilinear",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, resizeWidth: Int, resizeHeight: Int, numberOfRegions: Int, regions: UnsafePointer<MPSRegion>)\nInstance Properties\nvar numberOfRegions: Int\nvar regions: UnsafePointer<MPSRegion>\nvar resizeHeight: Int\nvar resizeWidth: Int\nRelationships\nInherits From\nMPSCNNKernel"
  },
  {
    "title": "MPSNNComparisonNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnncomparisonnode",
    "html": "Topics\nInstance Properties\nvar comparisonType: MPSNNComparisonType\nRelationships\nInherits From\nMPSNNBinaryArithmeticNode"
  },
  {
    "title": "MPSNNCompare | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsnncompare",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nInstance Properties\nvar comparisonType: MPSNNComparisonType\nvar threshold: Float\nRelationships\nInherits From\nMPSCNNArithmetic"
  },
  {
    "title": "MPSNDArrayUnaryKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarrayunarykernel",
    "html": "Topics\nInitializers\ninit(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar dilationRates: MPSNDArraySizes\nDeprecated\nvar edgeMode: MPSImageEdgeMode\nDeprecated\nvar kernelSizes: MPSNDArraySizes\nDeprecated\nvar offsets: MPSNDArrayOffsets\nDeprecated\nvar strides: MPSNDArrayOffsets\nDeprecated\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceArray: MPSNDArray) -> MPSNDArray\nfunc encode(to: MTLCommandBuffer, sourceArray: MPSNDArray, destinationArray: MPSNDArray)\nfunc encode(to: MTLCommandBuffer, sourceArray: MPSNDArray, resultState: MPSState?, destinationArray: MPSNDArray)\nfunc encode(to: MTLCommandBuffer, sourceArray: MPSNDArray, resultState: AutoreleasingUnsafeMutablePointer<MPSState?>?, outputStateIsTemporary: Bool) -> MPSNDArray\nRelationships\nInherits From\nMPSNDArrayMultiaryKernel"
  },
  {
    "title": "MPSNDArrayUnaryGradientKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarrayunarygradientkernel",
    "html": "Topics\nInitializers\ninit(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceArray: MPSNDArray, sourceGradient: MPSNDArray, gradientState: MPSState) -> MPSNDArray\nfunc encode(to: MTLCommandBuffer, sourceArray: MPSNDArray, sourceGradient: MPSNDArray, gradientState: MPSState, destinationArray: MPSNDArray)\nRelationships\nInherits From\nMPSNDArrayMultiaryGradientKernel"
  },
  {
    "title": "MPSNDArrayStridedSliceGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraystridedslicegradient",
    "html": "Relationships\nInherits From\nMPSNDArrayUnaryGradientKernel"
  },
  {
    "title": "MPSNDArrayGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraygradientstate",
    "html": "Relationships\nInherits From\nMPSState"
  },
  {
    "title": "MPSNDArrayMultiaryGradientKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraymultiarygradientkernel",
    "html": "Topics\nInitializers\ninit(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, sourceCount: Int, sourceGradientIndex: Int)\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceArrays: [MPSNDArray], sourceGradient: MPSNDArray, gradientState: MPSState) -> MPSNDArray\nfunc encode(to: MTLCommandBuffer, sourceArrays: [MPSNDArray], sourceGradient: MPSNDArray, gradientState: MPSState, destinationArray: MPSNDArray)\nRelationships\nInherits From\nMPSNDArrayMultiaryBase"
  },
  {
    "title": "MPSNDArrayGatherGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraygathergradientstate",
    "html": "Relationships\nInherits From\nMPSNDArrayGradientState"
  },
  {
    "title": "MPSNDArrayGatherGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraygathergradient",
    "html": "Relationships\nInherits From\nMPSNDArrayBinaryPrimaryGradientKernel"
  },
  {
    "title": "MPSNDArrayDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraydescriptor",
    "html": "Topics\nInitializers\ninit(dataType: MPSDataType, dimensionCount: Int, dimensionSizes: UnsafeMutablePointer<Int>)\ninit(dataType: MPSDataType, shape: [NSNumber])\nInstance Properties\nvar dataType: MPSDataType\nvar numberOfDimensions: Int\nInstance Methods\nfunc dimensionOrder() -> vector_uchar16\nfunc length(ofDimension: Int) -> Int\nfunc reshape(withDimensionCount: Int, dimensionSizes: UnsafeMutablePointer<Int>)\nfunc reshape(withShape: [NSNumber])\nfunc sliceDimension(Int, withSubrange: MPSDimensionSlice)\nfunc sliceRange(forDimension: Int) -> MPSDimensionSlice\nfunc transposeDimension(Int, withDimension: Int)\nRelationships\nInherits From\nNSObject"
  },
  {
    "title": "MPSNDArrayBinarySecondaryGradientKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraybinarysecondarygradientkernel",
    "html": "Topics\nInitializers\ninit(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Methods\nfunc encode(to: MTLCommandBuffer, primarySourceArray: MPSNDArray, secondarySourceArray: MPSNDArray, sourceGradient: MPSNDArray, gradientState: MPSState) -> MPSNDArray\nfunc encode(to: MTLCommandBuffer, primarySourceArray: MPSNDArray, secondarySourceArray: MPSNDArray, sourceGradient: MPSNDArray, gradientState: MPSState, destinationArray: MPSNDArray)\nRelationships\nInherits From\nMPSNDArrayMultiaryGradientKernel"
  },
  {
    "title": "MPSNDArrayGather | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraygather",
    "html": "Topics\nInstance Properties\nvar axis: Int\nRelationships\nInherits From\nMPSNDArrayBinaryKernel"
  },
  {
    "title": "MPSNDArrayBinaryPrimaryGradientKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraybinaryprimarygradientkernel",
    "html": "Topics\nInitializers\ninit(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Methods\nfunc encode(to: MTLCommandBuffer, primarySourceArray: MPSNDArray, secondarySourceArray: MPSNDArray, sourceGradient: MPSNDArray, gradientState: MPSState) -> MPSNDArray\nfunc encode(to: MTLCommandBuffer, primarySourceArray: MPSNDArray, secondarySourceArray: MPSNDArray, sourceGradient: MPSNDArray, gradientState: MPSState, destinationArray: MPSNDArray)\nRelationships\nInherits From\nMPSNDArrayMultiaryGradientKernel"
  },
  {
    "title": "MPSNDArrayBinaryKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraybinarykernel",
    "html": "Topics\nInitializers\ninit(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar primaryDilationRates: MPSNDArraySizes\nDeprecated\nvar primaryEdgeMode: MPSImageEdgeMode\nDeprecated\nvar primaryKernelSizes: MPSNDArraySizes\nDeprecated\nvar primaryOffsets: MPSNDArrayOffsets\nDeprecated\nvar primaryStrides: MPSNDArrayOffsets\nDeprecated\nvar secondaryDilationRates: MPSNDArraySizes\nDeprecated\nvar secondaryEdgeMode: MPSImageEdgeMode\nDeprecated\nvar secondaryKernelSizes: MPSNDArraySizes\nDeprecated\nvar secondaryOffsets: MPSNDArrayOffsets\nDeprecated\nvar secondaryStrides: MPSNDArrayOffsets\nDeprecated\nInstance Methods\nfunc encode(to: MTLCommandBuffer, primarySourceArray: MPSNDArray, secondarySourceArray: MPSNDArray) -> MPSNDArray\nfunc encode(to: MTLCommandBuffer, primarySourceArray: MPSNDArray, secondarySourceArray: MPSNDArray, destinationArray: MPSNDArray)\nfunc encode(to: MTLCommandBuffer, primarySourceArray: MPSNDArray, secondarySourceArray: MPSNDArray, resultState: MPSState?, destinationArray: MPSNDArray)\nfunc encode(to: MTLCommandBuffer, primarySourceArray: MPSNDArray, secondarySourceArray: MPSNDArray, resultState: AutoreleasingUnsafeMutablePointer<MPSState?>?, outputStateIsTemporary: Bool) -> MPSNDArray\nRelationships\nInherits From\nMPSNDArrayMultiaryKernel"
  },
  {
    "title": "MPSNDArray | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarray",
    "html": "Topics\nInitializers\ninit(device: MTLDevice, descriptor: MPSNDArrayDescriptor)\ninit(device: MTLDevice, scalar: Double)\nInstance Properties\nvar dataType: MPSDataType\nvar dataTypeSize: Int\nvar device: MTLDevice\nvar label: String?\nvar numberOfDimensions: Int\nvar parent: MPSNDArray?\nInstance Methods\nfunc arrayView(with: MTLCommandBuffer, descriptor: MPSNDArrayDescriptor, aliasing: MPSAliasingStrategy) -> MPSNDArray?\nfunc descriptor() -> MPSNDArrayDescriptor\nfunc exportData(with: MTLCommandBuffer, to: MTLBuffer, destinationDataType: MPSDataType, offset: Int, rowStrides: UnsafeMutablePointer<Int>?)\nfunc exportData(with: MTLCommandBuffer, to: [MPSImage], offset: MPSImageCoordinate)\nfunc importData(with: MTLCommandBuffer, from: [MPSImage], offset: MPSImageCoordinate)\nfunc importData(with: MTLCommandBuffer, from: MTLBuffer, sourceDataType: MPSDataType, offset: Int, rowStrides: UnsafeMutablePointer<Int>?)\nfunc length(ofDimension: Int) -> Int\nfunc readBytes(UnsafeMutableRawPointer, strideBytes: UnsafeMutablePointer<Int>?)\nfunc resourceSize() -> Int\nfunc synchronize(on: MTLCommandBuffer)\nfunc writeBytes(UnsafeMutableRawPointer, strideBytes: UnsafeMutablePointer<Int>?)\nType Methods\nclass func defaultAllocator() -> MPSNDArrayAllocator\nRelationships\nInherits From\nNSObject"
  },
  {
    "title": "MPSMatrixRandomPhilox | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixrandomphilox",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\ninit(device: MTLDevice, destinationDataType: MPSDataType, seed: Int)\ninit(device: MTLDevice, destinationDataType: MPSDataType, seed: Int, distributionDescriptor: MPSMatrixRandomDistributionDescriptor)\nRelationships\nInherits From\nMPSMatrixRandom"
  },
  {
    "title": "MPSMatrixRandomMTGP32 | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixrandommtgp32",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\ninit(device: MTLDevice, destinationDataType: MPSDataType, seed: Int)\ninit(device: MTLDevice, destinationDataType: MPSDataType, seed: Int, distributionDescriptor: MPSMatrixRandomDistributionDescriptor)\nInstance Methods\nfunc synchronizeState(on: MTLCommandBuffer)\nRelationships\nInherits From\nMPSMatrixRandom"
  },
  {
    "title": "MPSMatrixRandomDistributionDescriptor | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixrandomdistributiondescriptor",
    "html": "Topics\nInstance Properties\nvar distributionType: MPSMatrixRandomDistribution\nvar maximum: Float\nvar mean: Float\nvar minimum: Float\nvar standardDeviation: Float\nType Methods\nclass func `default`() -> MPSMatrixRandomDistributionDescriptor\nclass func normalDistributionDescriptor(withMean: Float, standardDeviation: Float) -> MPSMatrixRandomDistributionDescriptor\nclass func normalDistributionDescriptor(withMean: Float, standardDeviation: Float, minimum: Float, maximum: Float) -> MPSMatrixRandomDistributionDescriptor\nclass func uniformDistributionDescriptor(withMinimum: Float, maximum: Float) -> MPSMatrixRandomDistributionDescriptor\nRelationships\nInherits From\nNSObject\nConforms To\nNSCopying"
  },
  {
    "title": "MPSMatrixRandom | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsmatrixrandom",
    "html": "Topics\nInstance Properties\nvar batchSize: Int\nvar batchStart: Int\nvar destinationDataType: MPSDataType\nvar distributionType: MPSMatrixRandomDistribution\nInstance Methods\nfunc encode(commandBuffer: MTLCommandBuffer, destinationMatrix: MPSMatrix)\nfunc encode(commandBuffer: MTLCommandBuffer, destinationVector: MPSVector)\nRelationships\nInherits From\nMPSKernel"
  },
  {
    "title": "MPSCNNMultiaryKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnmultiarykernel",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, sourceCount: Int)\nInstance Properties\nvar clipRect: MTLRegion\nvar destinationFeatureChannelOffset: Int\nvar destinationImageAllocator: MPSImageAllocator\nvar isBackwards: Bool\nvar isStateModified: Bool\nvar padding: MPSNNPadding\nvar sourceCount: Int\nInstance Methods\nfunc appendBatchBarrier() -> Bool\nfunc destinationImageDescriptor(sourceImages: [MPSImage], sourceStates: [MPSState]?) -> MPSImageDescriptor\nfunc dilationRateXatIndex(Int) -> Int\nfunc dilationRateYatIndex(Int) -> Int\nfunc edgeMode(at: Int) -> MPSImageEdgeMode\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage]) -> MPSImage\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], destinationImage: MPSImage)\nfunc encode(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], destinationState: AutoreleasingUnsafeMutablePointer<MPSState?>, destinationStateIsTemporary: Bool) -> MPSImage\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [[MPSImage]]) -> [MPSImage]\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [[MPSImage]], destinationImages: [MPSImage])\nfunc encodeBatch(commandBuffer: MTLCommandBuffer, sourceImages: [[MPSImage]], destinationStates: AutoreleasingUnsafeMutablePointer<NSArray?>, destinationStateIsTemporary: Bool) -> [MPSImage]\nfunc isResultStateReusedAcrossBatch() -> Bool\nfunc kernelHeight(at: Int) -> Int\nfunc kernelWidth(at: Int) -> Int\nfunc offset(at: Int) -> MPSOffset\nfunc resultState(sourceImages: [MPSImage], sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSState?\nfunc resultStateBatch(sourceImages: [[MPSImage]], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> [MPSState]?\nfunc setDilationRateX(Int, at: Int)\nfunc setDilationRateY(Int, at: Int)\nfunc setEdgeMode(MPSImageEdgeMode, at: Int)\nfunc setKernelHeight(Int, at: Int)\nfunc setKernelWidth(Int, at: Int)\nfunc setOffset(MPSOffset, at: Int)\nfunc setSourceFeatureChannelMaxCount(Int, at: Int)\nfunc setSourceFeatureChannelOffset(Int, at: Int)\nfunc setStrideInPixelsX(Int, at: Int)\nfunc setStrideInPixelsY(Int, at: Int)\nfunc sourceFeatureChannelMaxCount(at: Int) -> Int\nfunc sourceFeatureChannelOffset(at: Int) -> Int\nfunc stride(inPixelsXatIndex: Int) -> Int\nfunc stride(inPixelsYatIndex: Int) -> Int\nfunc temporaryResultState(commandBuffer: MTLCommandBuffer, sourceImages: [MPSImage], sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSState?\nfunc temporaryResultStateBatch(commandBuffer: MTLCommandBuffer, sourceImages: [[MPSImage]], sourceStates: [[MPSState]]?, destinationImage: [MPSImage]) -> [MPSState]?\nRelationships\nInherits From\nMPSKernel"
  },
  {
    "title": "MPSImageNormalizedHistogram | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagenormalizedhistogram",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, histogramInfo: UnsafePointer<MPSImageHistogramInfo>)\nInstance Properties\nvar clipRectSource: MTLRegion\nvar histogramInfo: MPSImageHistogramInfo\nvar zeroHistogram: Bool\nInstance Methods\nfunc encode(to: MTLCommandBuffer, sourceTexture: MTLTexture, minmaxTexture: MTLTexture, histogram: MTLBuffer, histogramOffset: Int)\nfunc histogramSize(forSourceFormat: MTLPixelFormat) -> Int\nRelationships\nInherits From\nMPSKernel"
  },
  {
    "title": "MPSImageCanny | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimagecanny",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\ninit(device: MTLDevice, linearToGrayScaleTransform: UnsafePointer<Float>, sigma: Float)\nInstance Properties\nvar colorTransform: UnsafePointer<Float>\nvar highThreshold: Float\nvar lowThreshold: Float\nvar sigma: Float\nvar useFastMode: Bool\nRelationships\nInherits From\nMPSUnaryImageKernel"
  },
  {
    "title": "MPSCommandBuffer | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscommandbuffer",
    "html": "Topics\nInitializers\ninit(commandBuffer: MTLCommandBuffer)\ninit(from: MTLCommandQueue)\nInstance Properties\nvar commandBuffer: MTLCommandBuffer\nvar heapProvider: MPSHeapProvider?\nvar predicate: MPSPredicate?\nvar rootCommandBuffer: MTLCommandBuffer\nInstance Methods\nfunc commitAndContinue()\nfunc prefetchHeap(forWorkloadSize: Int)\nRelationships\nInherits From\nNSObject\nConforms To\nMTLCommandBuffer"
  },
  {
    "title": "MPSCNNGroupNormalizationGradientState | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationgradientstate",
    "html": "Topics\nInstance Properties\nvar beta: MTLBuffer?\nvar gamma: MTLBuffer?\nvar gradientForBeta: MTLBuffer\nvar gradientForGamma: MTLBuffer\nvar groupNormalization: MPSCNNGroupNormalization\nRelationships\nInherits From\nMPSNNGradientState"
  },
  {
    "title": "MPSCNNGroupNormalizationNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationnode",
    "html": "Topics\nInitializers\ninit(source: MPSNNImageNode, dataSource: MPSCNNGroupNormalizationDataSource)\nInstance Properties\nvar trainingStyle: MPSNNTrainingStyle\nRelationships\nInherits From\nMPSNNFilterNode\nConforms To\nMPSNNTrainableNode"
  },
  {
    "title": "MPSCNNGroupNormalizationGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationgradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, gradientState: MPSNNGradientStateNode)\nRelationships\nInherits From\nMPSNNGradientFilterNode\nConforms To\nMPSNNTrainableNode"
  },
  {
    "title": "MPSCNNGroupNormalization | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalization",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, dataSource: MPSCNNGroupNormalizationDataSource)\nInstance Properties\nvar dataSource: MPSCNNGroupNormalizationDataSource\nvar epsilon: Float\nInstance Methods\nfunc reloadGammaAndBeta(with: MTLCommandBuffer, gammaAndBetaState: MPSCNNNormalizationGammaAndBetaState)\nfunc reloadGammaAndBetaFromDataSource()\nfunc resultState(sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNGroupNormalizationGradientState?\nfunc temporaryResultState(commandBuffer: MTLCommandBuffer, sourceImage: MPSImage, sourceStates: [MPSState]?, destinationImage: MPSImage) -> MPSCNNGroupNormalizationGradientState?\nRelationships\nInherits From\nMPSCNNKernel"
  },
  {
    "title": "MPSCNNGroupNormalizationGradient | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnngroupnormalizationgradient",
    "html": "Relationships\nInherits From\nMPSCNNGradientKernel"
  },
  {
    "title": "MPSCNNConvolutionTransposeGradientStateNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiontransposegradientstatenode",
    "html": "Relationships\nInherits From\nMPSCNNConvolutionGradientStateNode"
  },
  {
    "title": "MPSAccelerationStructure | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsaccelerationstructure",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit?(coder: NSCoder, group: MPSAccelerationStructureGroup)\ninit(device: MTLDevice)\ninit(group: MPSAccelerationStructureGroup)\nInstance Properties\nvar boundingBox: MPSAxisAlignedBoundingBox\nvar group: MPSAccelerationStructureGroup\nvar status: MPSAccelerationStructureStatus\nvar usage: MPSAccelerationStructureUsage\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc copy(with: NSZone?, group: MPSAccelerationStructureGroup) -> Self\nfunc encode(with: NSCoder)\nfunc encodeRefit(commandBuffer: MTLCommandBuffer)\nfunc rebuild()\nfunc rebuild(completionHandler: MPSAccelerationStructureCompletionHandler)\nRelationships\nInherits From\nMPSKernel\nConforms To\nNSCopying\nNSSecureCoding\nSee Also\nRay Tracing\nAnimating and Denoising a Raytraced Scene\nSupport dynamic scenes and denoising by extending your ray tracer with Metal Performance Shaders.\nclass MPSRayIntersector\nA kernel that performs intersection tests between rays and geometry.\nDeprecated\nclass MPSAccelerationStructureGroup\nA group of acceleration structures.\nDeprecated\nclass MPSInstanceAccelerationStructure\nAn acceleration structure built over instances of other acceleration structures.\nDeprecated\nclass MPSTriangleAccelerationStructure\nAn acceleration structure built over triangles.\nDeprecated"
  },
  {
    "title": "MPSCNNConvolutionTransposeGradientNode | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpscnnconvolutiontransposegradientnode",
    "html": "Topics\nInitializers\ninit(sourceGradient: MPSNNImageNode, sourceImage: MPSNNImageNode, convolutionTransposeGradientState: MPSCNNConvolutionTransposeGradientStateNode, weights: MPSCNNConvolutionDataSource?)\nRelationships\nInherits From\nMPSCNNConvolutionGradientNode"
  },
  {
    "title": "MPSInstanceAccelerationStructure | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsinstanceaccelerationstructure",
    "html": "Topics\nInstance Properties\nvar accelerationStructures: [MPSPolygonAccelerationStructure]?\nvar instanceBuffer: MTLBuffer?\nvar instanceBufferOffset: Int\nvar instanceCount: Int\nvar maskBuffer: MTLBuffer?\nvar maskBufferOffset: Int\nvar transformBuffer: MTLBuffer?\nvar transformBufferOffset: Int\nvar transformType: MPSTransformType\nRelationships\nInherits From\nMPSAccelerationStructure\nSee Also\nRay Tracing\nAnimating and Denoising a Raytraced Scene\nSupport dynamic scenes and denoising by extending your ray tracer with Metal Performance Shaders.\nclass MPSRayIntersector\nA kernel that performs intersection tests between rays and geometry.\nDeprecated\nclass MPSAccelerationStructureGroup\nA group of acceleration structures.\nDeprecated\nclass MPSTriangleAccelerationStructure\nAn acceleration structure built over triangles.\nDeprecated\nclass MPSAccelerationStructure\nThe base class for data structures that are built over geometry and used to accelerate ray tracing.\nDeprecated"
  },
  {
    "title": "MPSAccelerationStructureGroup | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsaccelerationstructuregroup",
    "html": "Topics\nInitializers\ninit(device: MTLDevice)\nInstance Properties\nvar device: MTLDevice\nRelationships\nInherits From\nNSObject\nSee Also\nRay Tracing\nAnimating and Denoising a Raytraced Scene\nSupport dynamic scenes and denoising by extending your ray tracer with Metal Performance Shaders.\nclass MPSRayIntersector\nA kernel that performs intersection tests between rays and geometry.\nDeprecated\nclass MPSInstanceAccelerationStructure\nAn acceleration structure built over instances of other acceleration structures.\nDeprecated\nclass MPSTriangleAccelerationStructure\nAn acceleration structure built over triangles.\nDeprecated\nclass MPSAccelerationStructure\nThe base class for data structures that are built over geometry and used to accelerate ray tracing.\nDeprecated"
  },
  {
    "title": "MPSRayIntersector | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsrayintersector",
    "html": "Topics\nInitializers\ninit?(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice)\nInstance Properties\nvar boundingBoxIntersectionTestType: MPSBoundingBoxIntersectionTestType\nvar cullMode: MTLCullMode\nvar frontFacingWinding: MTLWinding\nvar intersectionDataType: MPSIntersectionDataType\nvar intersectionStride: Int\nvar rayDataType: MPSRayDataType\nvar rayIndexDataType: MPSDataType\nvar rayMask: UInt32\nvar rayMaskOperator: MPSRayMaskOperator\nvar rayMaskOptions: MPSRayMaskOptions\nvar rayStride: Int\nvar triangleIntersectionTestType: MPSTriangleIntersectionTestType\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc encode(with: NSCoder)\nfunc encodeIntersection(commandBuffer: MTLCommandBuffer, intersectionType: MPSIntersectionType, rayBuffer: MTLBuffer, rayBufferOffset: Int, intersectionBuffer: MTLBuffer, intersectionBufferOffset: Int, rayCount: Int, accelerationStructure: MPSAccelerationStructure)\nfunc encodeIntersection(commandBuffer: MTLCommandBuffer, intersectionType: MPSIntersectionType, rayBuffer: MTLBuffer, rayBufferOffset: Int, intersectionBuffer: MTLBuffer, intersectionBufferOffset: Int, rayCountBuffer: MTLBuffer, rayCountBufferOffset: Int, accelerationStructure: MPSAccelerationStructure)\nfunc encodeIntersection(commandBuffer: MTLCommandBuffer, intersectionType: MPSIntersectionType, rayBuffer: MTLBuffer, rayBufferOffset: Int, rayIndexBuffer: MTLBuffer, rayIndexBufferOffset: Int, intersectionBuffer: MTLBuffer, intersectionBufferOffset: Int, rayIndexCount: Int, accelerationStructure: MPSAccelerationStructure)\nfunc encodeIntersection(commandBuffer: MTLCommandBuffer, intersectionType: MPSIntersectionType, rayBuffer: MTLBuffer, rayBufferOffset: Int, rayIndexBuffer: MTLBuffer, rayIndexBufferOffset: Int, intersectionBuffer: MTLBuffer, intersectionBufferOffset: Int, rayIndexCountBuffer: MTLBuffer, rayIndexCountBufferOffset: Int, accelerationStructure: MPSAccelerationStructure)\nfunc encodeIntersection(commandBuffer: MTLCommandBuffer, intersectionType: MPSIntersectionType, rayTexture: MTLTexture, intersectionTexture: MTLTexture, accelerationStructure: MPSAccelerationStructure)\nfunc recommendedMinimumRayBatchSize(rayCount: Int) -> Int\nRelationships\nInherits From\nMPSKernel\nConforms To\nNSCopying\nNSSecureCoding\nSee Also\nRay Tracing\nAnimating and Denoising a Raytraced Scene\nSupport dynamic scenes and denoising by extending your ray tracer with Metal Performance Shaders.\nclass MPSAccelerationStructureGroup\nA group of acceleration structures.\nDeprecated\nclass MPSInstanceAccelerationStructure\nAn acceleration structure built over instances of other acceleration structures.\nDeprecated\nclass MPSTriangleAccelerationStructure\nAn acceleration structure built over triangles.\nDeprecated\nclass MPSAccelerationStructure\nThe base class for data structures that are built over geometry and used to accelerate ray tracing.\nDeprecated"
  },
  {
    "title": "Animating and Denoising a Raytraced Scene | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/animating_and_denoising_a_raytraced_scene",
    "html": "Overview\n\nNote\n\nThis sample code project is associated with WWDC 2019 session 613: Ray Tracing with Metal.\n\nSee Also\nRay Tracing\nclass MPSRayIntersector\nA kernel that performs intersection tests between rays and geometry.\nDeprecated\nclass MPSAccelerationStructureGroup\nA group of acceleration structures.\nDeprecated\nclass MPSInstanceAccelerationStructure\nAn acceleration structure built over instances of other acceleration structures.\nDeprecated\nclass MPSTriangleAccelerationStructure\nAn acceleration structure built over triangles.\nDeprecated\nclass MPSAccelerationStructure\nThe base class for data structures that are built over geometry and used to accelerate ray tracing.\nDeprecated"
  },
  {
    "title": "MPSKernel | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpskernel",
    "html": "Overview\n\nYou should not use the MPSKernel class directly. Instead, a number of subclasses are available that define specific high-performance data-parallel operations.\n\nThe basic sequence for applying a kernel to an image is as follows:\n\nInitialize a kernel corresponding to the operation you wish to perform:\n\nlet sobel = MPSImageSobel(device: mtlDevice)\n\n\nEncode the kernel into a command buffer.\n\nsobel.offset = ...\nsobel.clipRect = ...\nsobel.options = ...\nsobel.encode(commandBuffer: commandBuffer,\n             sourceTexture: inputImage,\n             destinationTexture: resultImage)\n\n\nEncoding the kernel merely encodes the operation into a command buffer. It does not modify any pixels, yet. All kernel state has been copied to the command buffer. Kernels may be reused. If the texture was previously operated on by another command encoder (e.g. a render command encoder), you should call the endEncoding() method on the other encoder before encoding the filter.\n\nSome kernels work in place, even in situations where Metal might not normally allow in-place operation on textures. If in-place operation is desired, you may attempt to call the encode(commandBuffer:inPlaceTexture:fallbackCopyAllocator:) method. If the operation cannot be completed in place, then false will be returned and you will have to create a new result texture and try again. To make an in-place image filter reliable, pass a fallback MPSCopyAllocator block to the method to create a new texture to write to in the event that a filter cannot operate in place.\n\nYou may repeat step 2 to encode more kernels, as desired.\n\nAfter encoding any additional work to the command buffer using other encoders, submit the command buffer to your command queue, using:\n\ncommandBuffer.commit()\n\n\nNote\n\nIt should be self evident that step 2 may not be thread safe. That is, you can not have multiple threads manipulating the same properties on the same kernel object at the same time and achieve coherent output. In common usage, the kernel properties don’t often need to be changed from their default values, but if you need to apply the same filter to multiple images on multiple threads with cropping/tiling, make additional kernel objects per thread (they are cheap). You can use multiple kernel objects on multiple threads, as long as only one thread is operating on any particular kernel object at a time.\n\nTopics\nInitializers\ninit?(coder: NSCoder)\ninit?(coder: NSCoder, device: MTLDevice)\nMethods\ninit(device: MTLDevice)\nInitializes a new kernel object.\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nMakes a copy of this kernel object for a new device.\nProperties\nvar options: MPSKernelOptions\nThe set of options used to run the kernel.\nstruct MPSKernelOptions\nThe options used when creating a kernel.\nvar device: MTLDevice\nThe device on which the kernel will be used.\nvar label: String?\nThe string that identifies the kernel.\nRelationships\nInherits From\nNSObject\nConforms To\nNSCopying\nNSSecureCoding"
  },
  {
    "title": "MPSKeyedUnarchiver | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpskeyedunarchiver",
    "html": "Topics\nInitializers\ninit?(device: MTLDevice)\nDeprecated\ninit(forReadingFrom: Data, device: MTLDevice, error: NSErrorPointer)\ninit(forReadingWith: Data, device: MTLDevice)\nDeprecated\nInstance Methods\nfunc mpsMTLDevice() -> MTLDevice\nType Methods\nclass func unarchiveObject(with: Data, device: MTLDevice) -> Any?\nDeprecated\nclass func unarchiveObject(withFile: String, device: MTLDevice) -> Any?\nDeprecated\nclass func unarchiveTopLevelObject(with: Data, device: MTLDevice) -> Any\nDeprecated\nclass func unarchivedObject(of: AnyClass, from: Data, device: MTLDevice) -> Any\nclass func unarchivedObject(ofClasses: Set<AnyHashable>, from: Data, device: MTLDevice) -> Any\nRelationships\nInherits From\nNSKeyedUnarchiver\nConforms To\nMPSDeviceProvider\nSee Also\nKeyed Archivers\nclass NSKeyedArchiver\nAn encoder that stores an object’s data to an archive referenced by keys.\nprotocol MPSDeviceProvider\nAn interface that enables the setting of a Metal device for unarchived objects."
  },
  {
    "title": "Recurrent Neural Networks | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/recurrent_neural_networks",
    "html": "Topics\nRecurrent Neural Networks\nclass MPSRNNImageInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders images.\nclass MPSRNNMatrixInferenceLayer\nA recurrent neural network layer for inference on Metal Performance Shaders matrices.\nclass MPSRNNSingleGateDescriptor\nA description of a simple recurrent block or layer.\nclass MPSGRUDescriptor\nA description of a gated recurrent unit block or layer.\nclass MPSLSTMDescriptor\nA description of a long short-term memory block or layer.\nenum MPSRNNSequenceDirection\nDirections that a sequence of inputs can be processed by a recurrent neural network layer.\nclass MPSRNNMatrixTrainingLayer\nA layer for training recurrent neural networks on Metal Performance Shaders matrices.\nclass MPSRNNMatrixTrainingState\nA class that holds data from a forward pass to be used in a backward pass.\nSee Also\nNeural Networks\nTraining a Neural Network with Metal Performance Shaders\nUse an MPS neural network graph to train a simple neural network digit classifier.\nclass MPSImage\nA texture that may have more than four channels for use in convolutional neural networks.\nclass MPSTemporaryImage\nA texture for use in convolutional neural networks that stores transient data to be used and discarded promptly.\nObjects that Simplify the Creation of Neural Networks\nSimplify the creation of neural networks using networks of filter, image, and state nodes.\nConvolutional Neural Network Kernels\nBuild neural networks with layers."
  },
  {
    "title": "Matrices and Vectors | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/matrices_and_vectors",
    "html": "Topics\nMatrices\nclass MPSMatrix\nA 2D array of data that stores the data's values.\nclass MPSMatrixDescriptor\nA description of attributes used to create an MPS matrix.\nclass MPSTemporaryMatrix\nA matrix allocated on GPU private memory.\nVectors\nclass MPSVector\nA 1D array of data that stores the data's values.\nclass MPSVectorDescriptor\nA description of the length and data type of a vector.\nclass MPSTemporaryVector\nA vector allocated on GPU private memory.\nClasses for Decomposition and Solving\nclass MPSMatrixDecompositionCholesky\nA kernel for computing the Cholesky factorization of a matrix.\nclass MPSMatrixSolveCholesky\nA kernel for computing the solution of a linear system of equations using a Cholesky factorization.\nclass MPSMatrixDecompositionLU\nA kernel for computing the LU factorization of a matrix using partial pivoting with row interchanges.\nclass MPSMatrixSolveLU\nA kernel for computing the solution of a linear system of equations using an LU factorization.\nclass MPSMatrixSolveTriangular\nA kernel for computing the solution of a linear system of equations using a triangular coefficient matrix.\nclass MPSMatrixUnaryKernel\nA kernel that consumes one matrix and produces one matrix.\nclass MPSMatrixBinaryKernel\nA kernel that consumes two matrices and produces one matrix.\nenum MPSMatrixDecompositionStatus\nMatrix Arithmetic Operations\nclass MPSMatrixSum\nA kernel for performing a pointwise summation of a matrix.\nclass MPSMatrixMultiplication\nA matrix multiplication kernel.\nclass MPSMatrixVectorMultiplication\nA matrix-vector multiplication kernel\nclass MPSMatrixFindTopK\nA kernel for computing the top-K values and their corresponding indices in a matrix.\nMatrix Copying Operations\nclass MPSMatrixCopy\nA class that can perform multiple matrix copy operations.\nclass MPSMatrixCopyToImage\nA kernel that copies matrix data to a Metal Performance Shaders image.\nclass MPSMatrixCopyDescriptor\nA description of multiple matrix copy operations.\nclass MPSImageCopyToMatrix\nA class that copies image data to a matrix.\nMatrix Neural Network Operations\nclass MPSMatrixFullyConnected\nA kernel for applying a fully connected neural network layer.\nclass MPSMatrixFullyConnectedGradient\nA kernel for applying a fully gradient connected neural network layer.\nclass MPSMatrixNeuron\nA neuron activation kernel that operates on matrices.\nclass MPSMatrixNeuronGradient\nA gradient neuron activation kernel that operates on matrices.\nMatrix Softmax Operations\nclass MPSMatrixLogSoftMax\nA logarithmic softmax kernel that operates on matrices.\nclass MPSMatrixLogSoftMaxGradient\nA logarithmic gradient softmax kernel that operates on matrices.\nclass MPSMatrixSoftMax\nA softmax kernel that operates on matrices.\nclass MPSMatrixSoftMaxGradient\nA gradient softmax kernel that operates on matrices.\nMatrix Normalization Operations\nclass MPSMatrixBatchNormalization\nA batch normalization kernel that operates on matrices.\nclass MPSMatrixBatchNormalizationGradient\nA batch normalization gradient kernel that operates on matrices."
  },
  {
    "title": "Convolutional Neural Network Kernels | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/convolutional_neural_network_kernels",
    "html": "Overview\n\nThink carefully about the edge mode requested for pooling layers. The default value is MPSImageEdgeMode.zero, but there are times when a MPSImageEdgeMode.clamp value may be better.\n\nTo avoid reading off the edge of an image for filters that have a filter area (convolution, pooling), set MPSCNNKernel.offset = (MPSOffset){ .x = kernelWidth/2, .y = kernelHeight/2, .z = 0} and reduce the size of the output image by {kernelWidth-1, kernelHeight-1, 0}. The filter area stretches up and to the left of the kernel offset by {kernelWidth/2, kernelHeight/2}.\n\nAlways remember the following distinction:\n\nThe MPSCNNConvolution class takes weights in the order weight[outputChannels][kernelHeight][kernelWidth][inputChannels/groups].\n\nThe MPSCNNFullyConnected class takes weights in the order weight[outputChannels][sourceWidth][sourceHeight][inputChannels].\n\nInitialize MPSCNNKernel objects once and reuse them.\n\nYou can use MPSCNNNeuron objects and similar to perform pre-processing of images, such as scaling and resizing.\n\nSpecify a neuron filter with an MPSCNNConvolutionDescriptor object to combine the convolution and neuron operations.\n\nUse MPSTemporaryImage objects for intermediate images that live for a short period of time (one MTLCommandBuffer object).\n\nMPSTemporaryImage objects can reduce the amount of memory used by the CNN by several folds, and similarly reduce the amount of CPU time spent allocating storage and latency between the time a command buffer is committed and when it is actually executed on the GPU.\n\nYou cannot read or write to a MPSTemporaryImage object using the CPU. Generally, MPSTemporaryImage objects should be created as needed and thrown away promptly. Persistent objects should not retain them.\n\nPlease be sure to understand the purpose of the readCount property.\n\nBecause the Metal Performance Shaders framework encodes its work in place in your command buffer, you always have the option to insert your own code in between MPSCNNKernel encodings as a Metal function for tasks not covered by the framework. You do not need to use the Metal Performance Shaders framework for everything.\n\nTopics\nArithmetic Layers\nclass MPSCNNAdd\nAn addition operator.\nclass MPSCNNAddGradient\nA gradient addition operator.\nclass MPSCNNSubtract\nA subtraction operator.\nclass MPSCNNSubtractGradient\nA gradient subtraction operator.\nclass MPSCNNMultiply\nA multiply operator.\nclass MPSCNNMultiplyGradient\nA gradient multiply operator.\nclass MPSCNNDivide\nA division operator.\nclass MPSCNNArithmetic\nThe base class for arithmetic operators.\nclass MPSCNNArithmeticGradient\nThe base class for gradient arithmetic operators.\nclass MPSCNNArithmeticGradientState\nAn object that stores the clamp mask used by gradient arithmetic operators.\nConvolution Layers\nclass MPSCNNBinaryConvolution\nA convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolution\nA convolution kernel that convolves the input image with a set of filters, with each producing one feature map in the output image.\nclass MPSCNNDepthWiseConvolutionDescriptor\nA description of a convolution object that does depthwise convolution.\nclass MPSCNNSubPixelConvolutionDescriptor\nA description of a convolution object that does subpixel upsampling and reshaping.\nclass MPSCNNConvolutionTranspose\nA transposed convolution kernel.\nclass MPSCNNConvolutionGradient\nA gradient convolution kernel.\nclass MPSCNNConvolutionGradientState\nAn object that exposes a gradient convolution kernel's gradient with respect to weights and biases.\nprotocol MPSImageSizeEncodingState\nA protocol for objects that contain information about an image size elsewhere in the graph.\nclass MPSCNNConvolutionWeightsAndBiasesState\nA class that stores weights and biases.\nPooling Layers\nclass MPSCNNPoolingAverage\nAn average pooling filter.\nclass MPSCNNPoolingAverageGradient\nA gradient average pooling filter.\nclass MPSCNNPoolingL2Norm\nAn L2-norm pooling filter.\nclass MPSCNNPoolingMax\nA max pooling filter.\nclass MPSCNNDilatedPoolingMax\nA dilated max pooling filter.\nclass MPSCNNPooling\nA pooling kernel.\nclass MPSCNNPoolingGradient\nA gradient pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradient\nA gradient dilated max pooling filter.\nclass MPSCNNPoolingL2NormGradient\nA gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradient\nA gradient max pooling filter.\nFully Connected Layers\nclass MPSCNNBinaryFullyConnected\nA fully connected convolution layer with binary weights and optionally binarized input image.\nclass MPSCNNFullyConnected\nA fully connected convolution layer, also known as an inner product layer.\nclass MPSCNNFullyConnectedGradient\nA gradient fully connected convolution layer.\nNeuron Layers\nclass MPSCNNNeuronAbsolute\nAn absolute neuron filter.\nclass MPSCNNNeuronELU\nA parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoid\nA hard sigmoid neuron filter.\nclass MPSCNNNeuronLinear\nA linear neuron filter.\nclass MPSCNNNeuronPReLU\nA parametric ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronReLUN\nA ReLUN neuron filter.\nclass MPSCNNNeuronReLU\nA ReLU (Rectified Linear Unit) neuron filter.\nclass MPSCNNNeuronSigmoid\nA sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlus\nA parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSign\nA softsign neuron filter.\nclass MPSCNNNeuronTanH\nA hyperbolic tangent neuron filter.\nclass MPSCNNNeuron\nA filter that applies a neuron activation function.\nclass MPSCNNNeuronExponential\nAn exponential neuron filter.\nclass MPSCNNNeuronGradient\nA gradient neuron filter.\nclass MPSCNNNeuronLogarithm\nA logarithm neuron filter.\nclass MPSCNNNeuronPower\nA power neuron filter.\nclass MPSNNNeuronDescriptor\nAn object that specifies properties used by a neuron kernel.\nSoftmax Layers\nclass MPSCNNSoftMax\nA neural transfer function that is useful for classification tasks.\nclass MPSCNNLogSoftMax\nA neural transfer function that is useful for constructing a loss function to be minimized when training neural networks.\nclass MPSCNNLogSoftMaxGradient\nA gradient logarithmic softmax filter.\nclass MPSCNNSoftMaxGradient\nA gradient softmax filter.\nNormalization Layers\nclass MPSCNNCrossChannelNormalization\nA normalization kernel applied across feature channels.\nclass MPSCNNCrossChannelNormalizationGradient\nA gradient normalization kernel applied across feature channels.\nclass MPSCNNLocalContrastNormalization\nA local-contrast normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradient\nA gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalization\nA spatial normalization kernel.\nclass MPSCNNSpatialNormalizationGradient\nA gradient spatial normalization kernel.\nclass MPSCNNBatchNormalization\nA batch normalization kernel.\nclass MPSCNNBatchNormalizationGradient\nA gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationState\nAn object that stores data required to execute batch normalization.\nclass MPSCNNNormalizationMeanAndVarianceState\nAn object that stores mean and variance terms used to execute batch normalization.\nclass MPSCNNBatchNormalizationStatistics\nAn object that stores statistics required to execute batch normalization.\nclass MPSCNNBatchNormalizationStatisticsGradient\nAn object that stores the gradient of the loss function with respect to the batch statistics and batch normalization weights.\nclass MPSCNNInstanceNormalization\nAn instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradient\nA gradient instance normalization kernel.\nclass MPSCNNInstanceNormalizationGradientState\nAn object that stores information required to execute a gradient pass for instance normalization.\nclass MPSCNNNormalizationGammaAndBetaState\nAn object that stores gamma and beta terms used to apply a scale and bias in instance- or batch-normalization operations.\nUpsampling Layers\nclass MPSCNNUpsampling\nA filter that resamples an existing MPS image.\nclass MPSCNNUpsamplingBilinear\nA bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearest\nA nearest spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradient\nA gradient bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingGradient\nA gradient filter that upsamples an existing Metal Performance Shaders image.\nclass MPSCNNUpsamplingNearestGradient\nA gradient upsampling filter that samples the pixel nearest to the source when upsampling to the destination pixel.\nDropout Layers\nclass MPSCNNDropout\nA dropout filter.\nclass MPSCNNDropoutGradient\nA gradient dropout filter.\nclass MPSCNNDropoutGradientState\nA class that stores the mask used by dropout and gradient dropout filters.\nLoss Layers\nclass MPSCNNLoss\nA kernel that computes the loss and loss gradient between specified predictions and labels.\nclass MPSCNNLossDataDescriptor\nAn object that specifies properties used by a loss data descriptor.\nclass MPSCNNLossDescriptor\nAn object that specifies properties used by a loss kernel.\nclass MPSCNNLossLabels\nA class that stores the per-element weight buffer used by loss and gradient loss kernels.\nclass MPSCNNYOLOLoss\nA kernel that computes the YOLO loss and loss gradient between specified predictions and labels.\nclass MPSCNNYOLOLossDescriptor\nAn object that specifies properties used by a YOLO loss kernel.\nReduction Layers\nclass MPSNNReduceRowMax\nA reduction filter that returns the maximum value for each row in an image.\nclass MPSNNReduceRowMin\nA reduction filter that returns the minimum value for each row in an image.\nclass MPSNNReduceRowSum\nA reduction filter that returns the sum of all values for each row in an image.\nclass MPSNNReduceRowMean\nA reduction filter that returns the mean value for each row in an image.\nclass MPSNNReduceColumnMax\nA reduction filter that returns the maximum value for each column in an image.\nclass MPSNNReduceColumnMin\nA reduction filter that returns the minimum value for each column in an image.\nclass MPSNNReduceColumnSum\nA reduction filter that returns the sum of all values for each column in an image.\nclass MPSNNReduceColumnMean\nA reduction filter that returns the mean value for each column in an image.\nclass MPSNNReduceFeatureChannelsMax\nA reduction filter that returns the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMin\nA reduction filter that returns the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsSum\nA reduction filter that returns the sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsMean\nA reduction filter that returns the mean value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMax\nA reduction filter that returns the index of the location of the maximum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsArgumentMin\nA reduction filter that returns the index of the location of the minimum value for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsSum\nA reduction filter that returns the weighted sum of all values for each feature channel in an image.\nclass MPSNNReduceFeatureChannelsAndWeightsMean\nA reduction filter that returns the weighted sum for each feature channel in an image.\nclass MPSNNReduceUnary\nThe base class for unary reduction filters.\nclass MPSNNReduceBinary\nThe base class for binary reduction filters.\nReshape Layer\nclass MPSNNReshape\nThe base class for reshape operations.\nSlice Layer\nclass MPSNNSlice\nA kernel that extracts a slice from an image.\nOptimization Layers\nclass MPSNNOptimizerAdam\nAn optimization layer that performs an Adam pdate.\nclass MPSNNOptimizerRMSProp\nAn optimization layer that performs a root mean square propagation update.\nclass MPSNNOptimizerStochasticGradientDescent\nAn optimization layer that performs a gradient descent with an optional momentum update.\nclass MPSNNOptimizer\nThe base class for optimization layers.\nclass MPSNNOptimizerDescriptor\nAn object that specifies properties used by an optimizer kernel.\nLayer Base Classes\nclass MPSCNNKernel\nBase class for neural network layers.\nclass MPSCNNBinaryKernel\nA convolution neural network kernel.\nclass MPSCNNGradientKernel\nThe base class for gradient layers.\nPredefined Padding Policies\nclass MPSNNDefaultPadding\nA class that provides predefined padding policies for common tasks.\nSee Also\nNeural Networks\nTraining a Neural Network with Metal Performance Shaders\nUse an MPS neural network graph to train a simple neural network digit classifier.\nclass MPSImage\nA texture that may have more than four channels for use in convolutional neural networks.\nclass MPSTemporaryImage\nA texture for use in convolutional neural networks that stores transient data to be used and discarded promptly.\nObjects that Simplify the Creation of Neural Networks\nSimplify the creation of neural networks using networks of filter, image, and state nodes.\nRecurrent Neural Networks\nCreate recurrent neural networks."
  },
  {
    "title": "Image Filters | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/image_filters",
    "html": "Overview\n\nThe MPSUnaryImageKernel and MPSBinaryImageKernel base classes define several properties common to all image kernels:\n\nclipRect and clipRect\n\n\t\n\nA clip rectangle is available to all image kernels that write to a destination texture. It describes the sub-rectangle of the destination texture overwritten by the filter. If the clip rectangle is larger than the destination texture, then the intersection between the clip rectangle and the destination texture bounds is used instead. A clip rectangle may be used to avoid doing work to obscured regions of the destination image, or to manage tiling and limit operations to parts of an image—for example, if a user draws a rectangle on the screen and asks your app to just apply the filter there.\n\n\n\n\noffset, primaryOffset, and secondaryOffset\n\n\t\n\nAn offset is available to all image kernels that use a source texture from which pixel data is read. It describes the positioning of the source image relative to the result texture. An offset of {0, 0, 0} indicates that the top left pixel of the source texture is the center pixel used to create the top left corner of the destination texture clip rectangle (as a further example, an offset of {1, 2, 0} positions the top left corner of the clip rectangle at position x=1, y=2, and z=0 of the source image). The offset is the position of the top left corner of the clip rectangle in the source coordinate frame. It can be used for tiling and for translating an image up, down, left, or right by pixel increments. If there is no clip rectangle, then the offset is the top left corner of the region read by the filter. If there are multiple source textures, then the primary offset describes the top left corner of the region read in the primary source texture and the secondary offset describes the top left corner of the region read in the secondary source texture.\n\n\n\n\nedgeMode, primaryEdgeMode, and secondaryEdgeMode\n\n\t\n\nAn edge mode describes the behavior of texture reads that stray off the edge of the source image. This can happen if the offset is negative, meaning a read off the top or left edge of the image. This can also happen if the sum of the clip rectangle size and the offset is larger than the source image, meaning a read off the bottom or right edge of the image. Furthermore, it is also possible for image filters to have a kernel window that stretches to examine neighboring pixels beyond the image bounds (such as convolution, morphology, and resampling filters). If there are multiple source textures, then the primary edge mode describes the mode to use with the primary source texture and the secondary edge mode describes the mode to use with the secondary source texture.\n\nIn-Place Operation\n\nSome kernels can operate in place. This means that the same texture is used to hold both the input image and the result image. Operating in place is a great way to save memory, time, and energy. You can perform an in-place operation by using the encode(commandBuffer:inPlaceTexture:fallbackCopyAllocator:) method.\n\nUnfortunately, it is not always possible for kernels to run in place. Whether a particular kernel can operate in place can vary according to the hardware it is running on, the OS version, and the parameters and properties passed to it. You may not assume that because a kernel works in place today on a particular device that it will do so in the future.\n\nTo simplify error handling with failed in-place operation, the encode(commandBuffer:inPlaceTexture:fallbackCopyAllocator:) method takes an optional MPSCopyAllocator object. It is used to create a new texture when in-place operation is not possible so as to allow the operation to proceed out of place in a reliable fashion instead. When this happens, the input texture is released and replaced with a new texture. To make use of the feature, you will need to write a copy allocator block.\n\nListing 1 shows a minimal copy allocator implementation. For more information, see the MPSCopyAllocator reference.\n\nListing 1 Minimal MPSCopyAllocator Implementation\nlet myAllocator: MPSCopyAllocator =\n{\n    (kernel: MPSKernel, buffer: MTLCommandBuffer, texture: MTLTexture) -> MTLTexture in\n    \n    let descriptor = MTLTextureDescriptor.texture2DDescriptor(pixelFormat: texture.pixelFormat,\n                                                              width: texture.width,\n                                                              height: texture.height,\n                                                              mipmapped: false)\n    \n    return buffer.device.makeTexture(descriptor: descriptor)\n}\n\nSupported Pixel Formats for Image Kernels\n\nAll Metal Performance Shaders image kernels support source and destination textures with the following ordinary and packed pixel formats:\n\nMTLPixelFormat.r8Unorm, MTLPixelFormat.r8Unorm_srgb\n\nOrdinary formats with one 8-bit normalized unsigned integer component.\n\nMTLPixelFormat.rg8Unorm, MTLPixelFormat.rg8Unorm_srgb\n\nOrdinary formats with two 8-bit normalized unsigned integer components.\n\nMTLPixelFormat.rgba8Unorm, MTLPixelFormat.rgba8Unorm_srgb, MTLPixelFormat.bgra8Unorm, MTLPixelFormat.bgra8Unorm_srgb\n\nOrdinary formats with four 8-bit normalized unsigned integer components.\n\nMTLPixelFormat.r16Float, MTLPixelFormat.rg16Float, MTLPixelFormat.rgba16Float\n\nOrdinary format with 16-bit floating-point components.\n\nMTLPixelFormat.r32Float, MTLPixelFormat.rg32Float, MTLPixelFormat.rgba32Float\n\nOrdinary format with 32-bit floating-point components.\n\nMTLPixelFormat.r16Unorm, MTLPixelFormat.rg16Unorm, MTLPixelFormat.rgba16Unorm\n\nOrdinary format with 16-bit normalized unsigned integer components.\n\nMTLPixelFormat.b5g6r5Unorm, MTLPixelFormat.a1bgr5Unorm, MTLPixelFormat.abgr4Unorm, MTLPixelFormat.bgr5A1Unorm\n\nPacked 16-bit format with normalized unsigned integer color components.\n\nMTLPixelFormat.rgb10a2Unorm\n\nPacked 32-bit format with normalized unsigned integer color components.\n\nMTLPixelFormat.rg11b10Float, MTLPixelFormat.rgb9e5Float\n\nPacked 32-bit format with floating-point color components.\n\nSome compressed pixel formats can be used as source textures. They cannot be used as destination textures because they cannot be written to. Metal Performance Shaders image kernels support the following compression families:\n\nPVRTC\n\nEAC/ETC\n\nASTC\n\nThe following Metal Performance Shaders image kernels also support source and destination textures with ordinary signed and unsigned integer pixel formats:\n\nMPSImageTranspose\n\nMPSImageIntegral\n\nMPSImageIntegralOfSquares\n\nThe ordinary signed and unsigned integer pixel formats supported by these image kernels:\n\nMTLPixelFormat.r8Sint, MTLPixelFormat.rg8Sint, MTLPixelFormat.rgba8Sint\n\nOrdinary format with 8-bit signed integer components.\n\nMTLPixelFormat.r8Uint, MTLPixelFormat.rg8Uint, MTLPixelFormat.rgba8Uint\n\nOrdinary format with 8-bit unsigned integer components.\n\nMTLPixelFormat.r16Sint, MTLPixelFormat.rg16Sint, MTLPixelFormat.rgba16Sint\n\nOrdinary format with 16-bit signed integer components.\n\nMTLPixelFormat.r16Uint, MTLPixelFormat.rg16Uint, MTLPixelFormat.rgba16Uint\n\nOrdinary format with 16-bit unsigned integer components.\n\nMTLPixelFormat.r32Sint, MTLPixelFormat.rg32Sint, MTLPixelFormat.rgba32Sint\n\nOrdinary format with 32-bit signed integer components.\n\nMTLPixelFormat.r32Uint, MTLPixelFormat.rg32Uint, MTLPixelFormat.rgba32Uint\n\nOrdinary format four 32-bit unsigned integer components.\n\nFor more information on pixel formats, see MTLPixelFormat and Pixel Format Capabilities.\n\nSample Code\nListing 2 Metal Performance Shaders Sample Code\n// Blur the input texture (in place if possible) on MTLCommandQueue q, and return the new texture.\n// This is a trivial example. It is not necessary or necessarily advised to enqueue a MPSKernel on\n// its own MTLCommandBuffer or using its own MTLComputeCommandEncoder. Group work together.\n    \n// Here we assume that you have already gotten a MTLDevice using MTLCreateSystemDefaultDevice() or\n// MTLCopyAllDevices(), used it to create a MTLCommandQueue with MTLDevice.newCommandQueue, and\n// similarly made textures with the device as needed.\nfunc myBlurTextureInPlace(inTexture: MTLTexture, blurRadius: Float, queue: MTLCommandQueue)\n{\n    // Create the usual Metal objects.\n    // MPS does not need a dedicated MTLCommandBuffer or MTLComputeCommandEncoder.\n    // This is a trivial example. You should reuse the MTL objects you already have, if you have them.\n    let device = queue.device;\n    let buffer = queue.makeCommandBuffer();\n    \n    // Create a MPS filter.\n    let blur = MPSImageGaussianBlur(device: device, sigma: blurRadius)\n    \n    // Defaults are okay here for other MPSKernel properties (clipRect, origin, edgeMode).\n    \n    // Attempt to do the work in place.  Since we provided a copyAllocator as an out-of-place\n    // fallback, we don’t need to check to see if it succeeded or not.\n    // See the \"Minimal MPSCopyAllocator Implementation\" code listing for a sample myAllocator.\n    let inPlaceTexture = UnsafeMutablePointer<MTLTexture>.allocate(capacity: 1)\n    inPlaceTexture.initialize(to: inTexture)\n    \n    blur.encode(commandBuffer: buffer, \n                inPlaceTexture: inPlaceTexture, \n                fallbackCopyAllocator: myAllocator)\n    \n    // The usual Metal enqueue process.\n    buffer.commit()\n    buffer.waitUntilCompleted()\n}\n\nTopics\nMorphological Image Filters\nclass MPSImageAreaMax\nA filter that finds the maximum pixel value in a rectangular region centered around each pixel in the source image.\nclass MPSImageDilate\nA filter that finds the maximum pixel value in a rectangular region by applying a dilation function.\nclass MPSImageAreaMin\nA filter that finds the minimum pixel value in a rectangular region centered around each pixel in the source image.\nclass MPSImageErode\nA filter that finds the minimum pixel value in a rectangular region by applying an erosion function.\nConvolution Image Filters\nclass MPSImageConvolution\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageMedian\nA filter that applies a median filter in a square region centered around each pixel in the source image.\nclass MPSImageBox\nA filter that convolves an image with a given kernel of odd width and height.\nclass MPSImageTent\nA filter that convolves an image with a tent filter.\nclass MPSImageGaussianBlur\nA filter that convolves an image with a Gaussian blur of a given sigma in both the x and y directions.\nclass MPSImageGaussianPyramid\nA filter that convolves an image with a Gaussian pyramid.\nclass MPSImageSobel\nA filter that convolves an image with the Sobel operator.\nclass MPSImageLaplacian\nAn optimized Laplacian filter, provided for ease of use.\nclass MPSImageLaplacianPyramid\nA filter that convolves an image with a Laplacian filter.\nclass MPSImageLaplacianPyramidAdd\nA filter that convolves an image with an additive Laplacian pyramid.\nclass MPSImageLaplacianPyramidSubtract\nA filter that convolves an image with a subtractive Laplacian pyramid.\nclass MPSImagePyramid\nA base class for creating different kinds of pyramid images.\nHistogram Image Filters\nclass MPSImageHistogram\nA filter that computes the histogram of an image.\nclass MPSImageHistogramEqualization\nA filter that equalizes the histogram of an image.\nclass MPSImageHistogramSpecification\nA filter that performs a histogram specification operation on an image.\nImage Threshold Filters\nclass MPSImageThresholdBinary\nA filter that returns a specified value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdBinaryInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or a specified value otherwise.\nclass MPSImageThresholdToZero\nA filter that returns the original value for each pixel with a value greater than a specified threshold or 0 otherwise.\nclass MPSImageThresholdToZeroInverse\nA filter that returns 0 for each pixel with a value greater than a specified threshold or the original value otherwise.\nclass MPSImageThresholdTruncate\nA filter that clamps the return value to an upper specified value.\nImage Integral Filters\nclass MPSImageIntegral\nA filter that calculates the sum of pixels over a specified region in an image.\nclass MPSImageIntegralOfSquares\nA filter that calculates the sum of squared pixels over a specified region in an image.\nImage Manipulation Filters\nclass MPSImageConversion\nA filter that performs a conversion of color space, alpha, or pixel format.\nclass MPSImageScale\nA filter that resizes and changes the aspect ratio of an image.\nclass MPSImageLanczosScale\nA filter that resizes and changes the aspect ratio of an image using Lanczos resampling.\nclass MPSImageBilinearScale\nA filter that resizes and changes the aspect ratio of an image using Bilinear resampling.\nclass MPSImageTranspose\nA filter that transposes an image.\nImage Statistics Filters\nclass MPSImageStatisticsMean\nA kernel that computes the mean for a given region of an image.\nclass MPSImageStatisticsMeanAndVariance\nA kernel that computes the mean and variance for a given region of an image.\nclass MPSImageStatisticsMinAndMax\nA kernel that computes the minimum and maximum pixel values for a given region of an image.\nImage Reduction Filters\nclass MPSImageReduceRowMax\nA filter that returns the maximum value for each row in an image.\nclass MPSImageReduceRowMin\nA filter that returns the minimum value for each row in an image.\nclass MPSImageReduceRowSum\nA filter that returns the sum of all values for a row in an image.\nclass MPSImageReduceRowMean\nA filter that returns the mean value for each row in an image.\nclass MPSImageReduceColumnMax\nA filter that returns the maximum value for each column in an image.\nclass MPSImageReduceColumnMin\nA filter that returns the minimum value for each column in an image.\nclass MPSImageReduceColumnSum\nA filter that returns the sum of all values for a column in an image.\nclass MPSImageReduceColumnMean\nA filter that returns the mean value for each column in an image.\nclass MPSImageReduceUnary\nThe base class for reduction filters that take a single source as input.\nImage Arithmetic Filters\nclass MPSImageAdd\nA filter that returns the element-wise sum of its two input images.\nclass MPSImageSubtract\nA filter that returns the element-wise difference of its two input images.\nclass MPSImageMultiply\nA filter that returns the element-wise product of its two input images.\nclass MPSImageDivide\nA filter that returns the element-wise quotient of its two input images.\nclass MPSImageArithmetic\nBase class for basic arithmetic nodes\nEuclidean Distance Transform Filter\nclass MPSImageEuclideanDistanceTransform\nA filter that performs a Euclidean distance transform on an image.\nFast Guided Filter\nclass MPSImageGuidedFilter\nA filter that performs edge-aware filtering on an image.\nKeypoints\nclass MPSImageFindKeypoints\nA kernel that is used to find a list of keypoints.\nstruct MPSImageKeypointData\nA structure that specifies keypoint information.\nstruct MPSImageKeypointRangeInfo\nA structure that specifies information to find the keypoints in an image.\nImage Filter Base Classes\nclass MPSUnaryImageKernel\nA kernel that consumes one texture and produces one texture.\nclass MPSBinaryImageKernel\nA kernel that consumes two textures and produces one texture.\nConstants\nMPSRectNoClip\nThe default clipping rectangle for a kernel object."
  },
  {
    "title": "Objects that Simplify the Creation of Neural Networks | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/objects_that_simplify_the_creation_of_neural_networks",
    "html": "Overview\n\nGraphs in Metal Performance Shaders offer a higher level graph API, intended to simplify the creation of neural networks. The graph is a network of MPSNNFilterNode, MPSNNImageNode and MPSNNStateNode objects.\n\nMPSNNImageNode represents MPSImage or MPSTemporaryImage objects\n\nMPSNNFilterNode represents MPSCNNKernel objects—each of the lower level MPSCNNKernel subclasses has an associated object that is a subclass of the MPSNNFilterNode\n\nMPSNNStateNode represents MPSState objects\n\nTopics\nNeural Network Graphs\nclass MPSNNGraph\nAn optimized representation of a graph of neural network image and filter nodes.\nclass MPSNNImageNode\nA placeholder node denoting the position of a neural network image in a graph.\nprotocol MPSHandle\nThe protocol that provides resource identification.\nArithmetic Layer Nodes\nclass MPSNNAdditionNode\nA representation of an addition operator.\nclass MPSNNAdditionGradientNode\nA representation of a gradient addition operator.\nclass MPSNNSubtractionNode\nA representation of an subtraction operator.\nclass MPSNNSubtractionGradientNode\nA representation of a gradient subtraction operator.\nclass MPSNNMultiplicationNode\nA representation of a multiplication operator.\nclass MPSNNMultiplicationGradientNode\nA representation of a gradient multiplication operator.\nclass MPSNNDivisionNode\nA representation of a division operator.\nclass MPSNNBinaryArithmeticNode\nVirtual base class for basic arithmetic nodes.\nclass MPSNNArithmeticGradientNode\nA representation of the base class for gradient arithmetic operators.\nclass MPSNNArithmeticGradientStateNode\nA representation of the clamp mask used by gradient arithmetic operators.\nConvolution Layer Nodes\nclass MPSCNNBinaryConvolutionNode\nA representation of a convolution kernel with binary weights and an input image using binary approximations.\nclass MPSCNNConvolutionNode\nA representation of a convolution kernel.\nclass MPSCNNConvolutionTransposeNode\nA representation of a transposed convolution.\nclass MPSCNNConvolutionGradientNode\nA representation of a gradient convolution kernel.\nclass MPSCNNConvolutionGradientStateNode\nA representation of a gradient convolution state.\nclass MPSCNNCrossChannelNormalizationGradientNode\nA representation of a gradient normalization kernel applied across feature channels.\nPooling Layer Nodes\nclass MPSCNNPoolingAverageNode\nA representation of an average pooling filter.\nclass MPSCNNDilatedPoolingMaxNode\nA representation of a dilated max pooling filter.\nclass MPSCNNPoolingL2NormNode\nA representation of a L2-norm pooling filter.\nclass MPSCNNPoolingMaxNode\nA representation of a max pooling filter.\nclass MPSCNNPoolingNode\nA representation of a MPS CNN pooling kernel.\nclass MPSCNNDilatedPoolingMaxGradientNode\nA representation of a gradient dilated max pooling filter.\nclass MPSCNNPoolingAverageGradientNode\nA representation of a gradient average pooling filter.\nclass MPSCNNPoolingGradientNode\nA representation of a gradient pooling kernel.\nclass MPSCNNPoolingL2NormGradientNode\nA representation of a gradient L2-norm pooling filter.\nclass MPSCNNPoolingMaxGradientNode\nA representation of a gradient max pooling filter.\nFully Connected Layer Nodes\nclass MPSCNNBinaryFullyConnectedNode\nA representation of a fully connected convolution layer with binary weights and optionally binarized input image.\nclass MPSCNNFullyConnectedNode\nA representation of a fully connected convolution layer, also known as an inner product layer.\nNeuron Layer Nodes\nclass MPSCNNNeuronAbsoluteNode\nA representation of an absolute neuron filter.\nclass MPSCNNNeuronELUNode\nA representation of a parametric ELU neuron filter.\nclass MPSCNNNeuronHardSigmoidNode\nA representation of a hard sigmoid neuron filter.\nclass MPSCNNNeuronLinearNode\nA representation of a linear neuron filter.\nclass MPSCNNNeuronPReLUNode\nA representation a PReLU neuron filter.\nclass MPSCNNNeuronReLUNNode\nA representation a ReLUN neuron filter.\nclass MPSCNNNeuronReLUNode\nA representation a ReLU neuron filter.\nclass MPSCNNNeuronSigmoidNode\nA representation of a sigmoid neuron filter.\nclass MPSCNNNeuronSoftPlusNode\nA representation of a parametric softplus neuron filter.\nclass MPSCNNNeuronSoftSignNode\nA representation of a softsign neuron filter.\nclass MPSCNNNeuronTanHNode\nA representation of a hyperbolic tangent neuron filter.\nclass MPSCNNNeuronExponentialNode\nA representation of an exponential neuron filter.\nclass MPSCNNNeuronGradientNode\nA representation of a gradient exponential neuron filter.\nclass MPSCNNNeuronLogarithmNode\nA representation of a logarithm neuron filter.\nclass MPSCNNNeuronPowerNode\nA representation of a power neuron filter.\nclass MPSCNNNeuronNode\nThe virtual base class for MPS CNN neuron nodes.\nSoftmax Layer Nodes\nclass MPSCNNSoftMaxNode\nA representation of a softmax filter.\nclass MPSCNNLogSoftMaxNode\nA representation of a logarithmic softmax filter kernel.\nclass MPSCNNLogSoftMaxGradientNode\nA representation of a gradient logarithmic softmax filter kernel.\nclass MPSCNNSoftMaxGradientNode\nA representation of a gradient softmax filter.\nNormalization Layer Nodes\nclass MPSCNNCrossChannelNormalizationNode\nA representation of a normalization kernel across feature channels.\nclass MPSCNNLocalContrastNormalizationNode\nA representation of a local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationNode\nA representation of a spatial normalization kernel.\nclass MPSCNNBatchNormalizationGradientNode\nA representation of a gradient batch normalization kernel.\nclass MPSCNNBatchNormalizationNode\nA representation of a batch normalization kernel.\nprotocol MPSCNNBatchNormalizationDataSource\nA protocol that defines methods that a batch normalization state uses to initialize scale factors, bias terms, and batch statistics.\nclass MPSCNNInstanceNormalizationGradientNode\nA representation of a gradient instance normalization kernel.\nprotocol MPSCNNInstanceNormalizationDataSource\nA protocol that defines methods that an instance normalization uses to initialize scale factors and bias terms.\nclass MPSCNNInstanceNormalizationNode\nA representation of an instance normalization kernel.\nclass MPSCNNLocalContrastNormalizationGradientNode\nA representation of a gradient local-contrast normalization kernel.\nclass MPSCNNSpatialNormalizationGradientNode\nA representation of a gradient spatial normalization kernel.\nclass MPSCNNNormalizationNode\nVirtual base class for CNN normalization nodes.\nUpsampling Layer Nodes\nclass MPSCNNUpsamplingBilinearNode\nA representation of a bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearestNode\nA representation of a nearest spatial upsampling filter.\nclass MPSCNNUpsamplingBilinearGradientNode\nA representation of a gradient bilinear spatial upsampling filter.\nclass MPSCNNUpsamplingNearestGradientNode\nA representation of a gradient nearest spatial upsampling filter.\nResampling Nodes\nclass MPSNNBilinearScaleNode\nA representation of a bilinear resampling filter.\nclass MPSNNLanczosScaleNode\nA representation of a Lanczos resampling filter.\nclass MPSNNScaleNode\nAbstract node representing an image resampling filter.\nprotocol MPSImageTransformProvider\nA general interface for objects that provide image resampling.\nDropout Layer Nodes\nclass MPSCNNDropoutNode\nA representation of a dropout filter.\nclass MPSCNNDropoutGradientNode\nA representation of a gradient dropout filter.\nKernel Concatenation Nodes\nclass MPSNNConcatenationNode\nA representation of the results from one or more kernels.\nclass MPSNNConcatenationGradientNode\nA representation of the results from one or more gradient kernels.\nLoss Layer Nodes\nclass MPSCNNLossNode\nA representation of a loss kernel.\nclass MPSCNNYOLOLossNode\nA representation of a YOLO loss kernel.\nclass MPSNNLabelsNode\nA placeholder node denoting the per-element weight buffer used by loss and gradient loss kernels.\nFilter Node Base Classes\nclass MPSNNFilterNode\nA placeholder node denoting a neural network filter stage.\nclass MPSNNGradientFilterNode\nA representation of a gradient filter.\nProtocols\nprotocol MPSNNTrainableNode\nA protocol that defines methods that determine whether and when neural network training parameters are updated.\nSee Also\nNeural Networks\nTraining a Neural Network with Metal Performance Shaders\nUse an MPS neural network graph to train a simple neural network digit classifier.\nclass MPSImage\nA texture that may have more than four channels for use in convolutional neural networks.\nclass MPSTemporaryImage\nA texture for use in convolutional neural networks that stores transient data to be used and discarded promptly.\nConvolutional Neural Network Kernels\nBuild neural networks with layers.\nRecurrent Neural Networks\nCreate recurrent neural networks."
  },
  {
    "title": "MPSTemporaryImage | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpstemporaryimage",
    "html": "Overview\n\nMPSTemporaryImage objects can provide a profound reduction in the aggregate texture memory and associated CPU-side allocation cost in your app. Metal Performance Shaders achieves this by automatically identifying MPSTemporaryImage objects that do not overlap in time over the course of a MTLCommandBuffer object’s lifetime and can therefore reuse the same memory. MPSTemporaryImage objects leverage an internal cache of preallocated reusable memory to hold pixel data to avoid typical memory allocation performance penalties common to ordinary MPSImage and MTLTexture objects.\n\nTo avoid data corruption due to aliasing, MPSTemporaryImage objects impose some important restrictions:\n\nThe underlying texture storage mode is MTLStorageMode.private. You cannot, for example, use the getBytes(_:bytesPerRow:from:mipmapLevel:) or replace(region:mipmapLevel:withBytes:bytesPerRow:) methods with them. Temporary images are strictly read and written by the GPU.\n\nThe temporary image may be used only on a single MTLCommandBuffer object. This limits the chronology to a single linear time stream.\n\nThe readCount property must be managed correctly.\n\nTemporary images must also adhere to the general pixel format restrictions for MPSImage objects.\n\nSince temporary images can only be used with a single command buffer, and can not be used off the GPU, they generally should not be kept around past the completion of their associated command buffer. The lifetime of a temporary image is typically expected to be extremely short, perhaps spanning only a few lines of code.\n\nTo keep the lifetime of the underlying texture allocation as short as possible, the texture is not allocated until the first time the MPSTemporaryImage object is used by an MPSCNNKernel object or until the first time the texture property is read. The readCount property serves to limit the lifetime of the texture on deallocation.\n\nYou may use the texture property with the encode methods of an MPSUnaryImageKernel subclass, if featureChannels<=4 and the texture conforms to the requirements of the given kernel. In such cases, the readCount property is not modified, since the enclosing object is not available. There is no locking mechanism provided to prevent a MTLTexture object returned from the texture property from becoming invalid when the value of the readCount property reaches 0.\n\nMPSTemporaryImage objects can otherwise be used wherever MPSImage objects are used.\n\nThe MPSTemporaryImage Class\n\nThe MPSTemporaryImage class extends the MPSImage class to provide advanced caching of unused memory, in order to increase performance and reduce memory footprint. MPSTemporaryImage objects are intended as fast GPU-only storage for intermediate image data needed only transiently within a single MTLCommandBuffer object. They accelerate the common case of image data which is created only to be consumed and destroyed immediately by the next operation(s) encoded in a command buffer. MPSTemporaryImage objects provide a convenient and simple way to save memory by automatically aliasing other MPSTemporaryImage objects in the same command buffer. Because they alias (i.e., share texel storage with) other textures in the same command buffer, the valid lifetime of the data in an MPSTemporaryImage object is extremely short, limited to a portion of a the command buffer itself.\n\nYou can not read or write data to an MPSTemporaryImage using the CPU, or use the data in other MTLCommandBuffer objects. Use regular MPSImage objects for more persistent storage.\n\nTopics\nInitializers\ninit(commandBuffer: MTLCommandBuffer, imageDescriptor: MPSImageDescriptor)\nInitializes a temporary image for use on a command buffer.\nclass MPSImageDescriptor\nA description of the attributes used to create an MPSImage.\ninit(commandBuffer: MTLCommandBuffer, textureDescriptor: MTLTextureDescriptor)\nLow-level interface for creating a temporary image using a texture descriptor.\nclass MTLTextureDescriptor\nAn object that you use to configure new Metal texture objects.\ninit(commandBuffer: MTLCommandBuffer, textureDescriptor: MTLTextureDescriptor, featureChannels: Int)\nMethods\nclass func prefetchStorage(with: MTLCommandBuffer, imageDescriptorList: [MPSImageDescriptor])\nA method that helps the framework decide which allocations to make ahead of time.\nMethods to Get an Image Allocator\nclass func defaultAllocator() -> MPSImageAllocator\nprotocol MPSImageAllocator\nProperties\nvar readCount: Int\nThe number of times a temporary image may be read by a CNN kernel before its contents become undefined.\nRelationships\nInherits From\nMPSImage\nSee Also\nNeural Networks\nTraining a Neural Network with Metal Performance Shaders\nUse an MPS neural network graph to train a simple neural network digit classifier.\nclass MPSImage\nA texture that may have more than four channels for use in convolutional neural networks.\nObjects that Simplify the Creation of Neural Networks\nSimplify the creation of neural networks using networks of filter, image, and state nodes.\nConvolutional Neural Network Kernels\nBuild neural networks with layers.\nRecurrent Neural Networks\nCreate recurrent neural networks."
  },
  {
    "title": "The MPSKernel Class | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/the_mpskernel_class",
    "html": "Overview\n\nThe MPSKernel is the base class for all Metal Performance Shaders kernels. It defines the baseline behavior for all kernels, declaring the device to run the kernel on, some debugging options, and a user-friendly label, should one be required. Derived from this class are the MPSUnaryImageKernel and MPSBinaryImageKernel subclasses, which define shared behavior for most image processing kernels (filters) such as edging modes, clipping, and tiling support for image operations that consume one or two source textures. Neither these nor the MPSKernel class are meant to be used directly. They just provide API abstraction and in some cases may allow some level of polymorphic manipulation of image kernel objects.\n\nSubclasses of the MPSUnaryImageKernel and MPSBinaryImageKernel classes provide specialized initialization and encoding methods to encode various image processing primitives into a command buffer, and may also provide additional configurable properties on their own. Many such image filters are available, such as:\n\nConvolution filters (Sobel, Gaussian)\n\nMorphological operators (dilate, erode)\n\nHistogram operators (equalization, specification)\n\nAll of these run on the GPU directly on texture and buffer objects.\n\nAs the MPSKernel, MPSUnaryImageKernel, and MPSBinaryImageKernel classes serve to unify a diversity of image operations into a simple consistent interface and calling sequence to apply image filters, subclasses implement details that diverge from the norm. For example, some filters may take a small set of parameters (for example, a convolution kernel) to govern how they function. However, the overall sequence for using kernel subclasses remains the same:\n\nDetermine whether the Metal Performance Shaders framework supports your device by querying the MPSSupportsMTLDevice(_:) function.\n\nAllocate the usual Metal objects to drive a Metal compute pipeline: MTLDevice, MTLCommandQueue, and MTLCommandBuffer. If your app has already written to any command buffers, Metal Performance Shaders can encode onto them inline with your own workload.\n\nCreate an appropriate kernel—for example, a MPSImageGaussianBlur object if you want to do a Gaussian blur. Kernels are generally lightweight but can be reused to save some setup time. They cannot be used by multiple threads concurrently, so if your app uses Metal from many threads concurrently, make extra kernels. MPSKernel objects conform to the NSCopying protocol.\n\nCall the kernel’s encoding method. Parameters for the encoding call vary by kernel type, but operate similarly. They create a command encoder, write commands to run the kernel into the command buffer, and then end the command encoder. This means you must call the endEncoding() method on your current command encoder before calling a kernel’s encode method. At this point, you can either release the kernel or keep it for later use to save some setup cost.\n\nIf you wish to encode further commands of your own on the command buffer, you must create a new command encoder to do so.\n\nWhen you are done with the command buffer, submit it to the device using the commit() method. The kernel will then begin running on the GPU. You can either use the waitUntilCompleted() or addCompletedHandler(_:) methods to be notified when the work is done.\n\nEach kernel is allocated against a particular device; a single kernel may not be used with multiple devices. This is necessary because the init(device:) methods sometimes allocate buffers and textures to hold data passed in as parameters to the initialization method, and a device is required to allocate them. Kernels provide a copy(with:device:) method that allows them to be copied for a new device.\n\nNote\n\nKernel objects are not entirely thread safe. While they may be used in a multithreaded context, you should not attempt to have multiple kernel objects writing to the same command buffer at the same time. They share restrictions with the command encoder in this regard. In limited circumstances, the same kernel can be used to write to multiple command buffers concurrently. However, that only works if the kernel is treated as an immutable object. That is, if subclass properties of a shared kernel are changed, then the change can be reflected on the other thread while the other thread is encoding its work, leading to undefined behavior. It is generally safest to just make copies of kernel objects, one for each thread.\n\nSee Also\nFundamentals\nTuning Hints"
  },
  {
    "title": "MPSSupportsMTLDevice(_:) | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/1618849-mpssupportsmtldevice",
    "html": "Parameters\ndevice\n\nA valid Metal device.\n\nReturn Value\n\ntrue if the device is supported.\n\nfalse if the device is not supported.\n\nDiscussion\n\nFor a full listing of Metal Performance Shaders feature set support, see Feature Availability."
  },
  {
    "title": "Tuning Hints | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/tuning_hints",
    "html": "Overview\n\nThe Metal Performance Shaders framework has been tuned for excellent performance across a diversity of devices and kernel parameters. The tuning process focuses on minimizing both CPU and GPU latency for back to back calls on the same command buffer. It is possible, however, to inadvertently undo this optimization effort by introducing costly operations into the pipeline around the kernel, leading to disappointing overall results.\n\nHere are some elements of good practice to avoid common pitfalls:\n\nDon’t wait for results to complete before enqueuing more work. There can be a significant delay (up to 2.5 ms) just to get an empty command buffer through the pipeline to where the waitUntilCompleted() method returns. Instead, start encoding the next command buffer(s) while you wait for the first one to complete. Enqueue them too, so they can start immediately after the previous one exits the GPU. Don’t wait for the CPU kernel to notice the first command buffer is done, start taking it apart, and eventually make a callback to the app before beginning work on encoding the next one. By allowing the CPU and GPU to work concurrently in this way, throughput can be enhanced by up to a factor of ten.\n\nThere is a large cost to allocating buffers and textures. The cost can swamp the CPU, preventing you from keeping the GPU busy. Try to preallocate and reuse the MTLResource objects as much as possible.\n\nThere is a cost to switching between render and compute encoders. Each time a new render encoder is used, there can be a substantial GPU mode switch cost that may undermine your throughput. To avoid the cost, try to batch compute work together. Since making a new command buffer forces you to make a new command encoder too, try to do more work with fewer command buffers.\n\nFor some image operations, particularly those involving multiple passes (e.g. chaining multiple image filters together), performance can be improved by up to a factor of two by breaking the work into tiles of ~512 KB in size. Use the sourceRegion(destinationSize:) method to find the region needed for each tile.\n\nSee Also\nFundamentals\nThe MPSKernel Class"
  },
  {
    "title": "MPSNDArrayMultiaryBase | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraymultiarybase",
    "html": "Topics\nInitializers\ninit(coder: NSCoder, device: MTLDevice)\ninit(device: MTLDevice, sourceCount: Int)\nInstance Properties\nvar destinationArrayAllocator: MPSNDArrayAllocator\nInstance Methods\nfunc copy(with: NSZone?, device: MTLDevice?) -> Self\nfunc destinationArrayDescriptor(forSourceArrays: [MPSNDArray], sourceState: MPSState?) -> MPSNDArrayDescriptor\nfunc dilationRates(forSourceIndex: Int) -> MPSNDArraySizes\nDeprecated\nfunc edgeMode(atSourceIndex: Int) -> MPSImageEdgeMode\nDeprecated\nfunc encode(with: NSCoder)\nfunc kernelSizes(forSourceIndex: Int) -> MPSNDArraySizes\nDeprecated\nfunc offsets(atSourceIndex: Int) -> MPSNDArrayOffsets\nDeprecated\nfunc resultState(forSourceArrays: [MPSNDArray], sourceStates: [MPSState]?, destinationArray: MPSNDArray) -> MPSState?\nfunc strides(forSourceIndex: Int) -> MPSNDArrayOffsets\nDeprecated\nRelationships\nInherits From\nMPSKernel"
  },
  {
    "title": "MPSNDArrayMatrixMultiplication | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsndarraymatrixmultiplication",
    "html": "Topics\nInstance Properties\nvar alpha: Double\nvar beta: Double\nRelationships\nInherits From\nMPSNDArrayMultiaryKernel"
  },
  {
    "title": "MPSImage | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/mpsimage",
    "html": "Overview\n\nSome image types, such as those found in convolutional neural networks (CNN), differ from a standard texture in that they may have more than 4 channels per pixel. While the channels could hold RGBA data, they will more commonly hold a number of structural permutations upon an RGBA image as the neural network progresses. It is not uncommon for each pixel to have 32 or 64 channels in it.\n\nSince a standard MTLTexture object cannot have more than 4 channels, the additional channels are stored in slices of a 2D texture array (i.e. a texture of type MTLTextureType.type2DArray) such that 4 consecutive channels are stored in each slice of this array. If the number of feature channels is N, the number of array slices needed is (N+3)/4. For example, a 9-channel CNN image with a width of 3 and a height of 2 will be stored as follows:\n\nFigure 1 The layout of a 9-channel CNN image with a width of 3 and a height of 2.\n\nThus, the width and height of the underlying 2D texture array is the same as the width and height of the MPSImage object and the array length is equal to (featureChannels+3)/4. (Channels marked with a ? are just for padding and should not contain NaN or INF values.)\n\nAn MPSImage object can contain multiple CNN images for batch processing. In order to create an MPSImage object that contains N images, create an MPSImageDescriptor object with the numberOfImages property set to N. The length of the 2D texture array (i.e. the number of slices) will be equal to ((featureChannels+3)/4)*numberOfImages, where consecutive (featureChannels+3)/4 slices of this array represent one image.\n\nAlthough an MPSImage object can contain more than one image, the actual number of images among these processed by an MPSCNNKernel object is controlled by the z dimension of the clipRect property. (A kernel processes n=clipRect.size.depth images from this collection.)\n\nThe starting index of the image to process from the source MPSImage object is given by offset.z. The starting index of the image in the destination MPSImage object where this processed image is written to is given by clipRect.origin.z. Thus, an MPSCNNKernel object takes the n=clipRect.size.depth image from the source at indices [offset.z, offset.z+n], processes each independently, and stores the result in the destination at indices [clipRect.origin.z, clipRect.origin.z+n] respectively. Thus, offset.z+n should be <=[source numberOfImages], clipRect.origin.z+n should be <=[destination numberOfImages], and offset.z must be >=0.\n\nFor example, suppose an MPSCNNConvolution object takes an input image with 16 channels and outputs an image with 32 channels. The number of slices needed in the source 2D texture array is 4 and the number of slices needed in the destination 2D texture array is 8. Suppose the source batch size is 5 and the destination batch size is 4. Thus, the number of source slices will be 4*5=20 and the number of destination slices will be 8*4=32. If you want to process image 2 and 3 of the source and store the result at index 1 and 2 in the destination, you can achieve this by setting offset.z=2, clipRect.origin.z=1, and clipRect.size.depth=2. The MPSCNNConvolution object will take, in this case, slices 4 and 5 of the source and produce slices 4 to 7 of the destination. Similarly, slices 6 and 7 will be used to produce slices 8 to 11 of the destination.\n\nAll MPSCNNKernel objects process images in the batch independently. That is, calling a MPSCNNKernel object on a batch is formally the same as calling it on each image in the batch sequentially. Computational and GPU work submission overhead will be amortized over more work if batch processing is used. This is especially important for better performance on small images.\n\nIf featureChannels<=4 and numberOfImages=1 (i.e. only one slice is needed to represent the image), the underlying metal texture type is chosen to be MTLTextureType.type2D rather than MTLTextureType.type2DArray as explained above.\n\nThe framework also provides MPSTemporaryImage objects, intended for very short-lived image data that is produced and consumed immediately in the same MTLCommandBuffer object. They are a useful way to minimize CPU-side texture allocation costs and greatly reduce the amount of memory used by your image pipeline.\n\nCreation of the underlying texture may occur lazily in some cases. In general, you should avoid calling the texture property to avoid materializing memory for longer than necessary. When possible, use the other MPSImage properties to get information about the object instead.\n\nThe MPSImage Class\n\nMTLBuffer and MTLTexture objects are commonly used in Metal apps and are used directly by the Metal Performance Shaders framework when possible. In apps that use CNN, kernels may need more than the four data channels that a MTLTexture object can provide. In these cases, an MPSImage object is used instead as an abstraction layer on top of a MTLTexture object. When more than 4 channels are needed, additional textures in the 2D texture array are added to hold additional channels in sets of four. An MPSImage object tracks this information as the number of feature channels in an image.\n\nCNN Images\n\nMPSCNNKernel objects operate on MPSImage objects. MPSImage objects are at their core MTLTexture objects; however, whereas MTLTexture objects commonly represent image or texel data, an MPSImage object is a more abstract representation of image features. The channels within an MPSImage do not necessarily correspond to colors in a color space (although they can, if necessary). As a result, there can be many more than four of them. Having 32 or 64 channels per pixel is not uncommon in CNN. This is achieved on the MTLTexture object abstraction by inserting extra RGBA pixels to handle the additional feature channels (if any) beyond 4. These extra pixels are stored as multiple slices of a 2D image array. Thus, each CNN pixel in a 32-channel image is represented as 8 array slices, with 4-channels stored per-pixel in each slice. The width and height of the MTLTexture object is the same as the width and height of the MPSImage object. The number of slices in the MTLTexture object is given by the number of feature channels rounded up to a multiple of 4.\n\nMPSImage objects can be created from existing MTLTexture objects. They may also be created anew from an MPSImageDescriptor and backed with either standard texture memory, or as MPSTemporaryImage objects using memory drawn from the framework’s internal cached texture backing store. MPSTemporaryImage objects can provide great memory usage and CPU time savings, but come with significant restrictions that should be understood before using them. For example, their contents are only valid during the GPU-side execution of a single MTLCommandBuffer object and can not be read from or written to by the CPU. They are provided as an efficient way to hold CNN computations that are used immediately within the scope of the same MTLCommandBuffer object and then discarded. Concatenation is also supported by allowing you to define from which destination feature channel to start writing the output of the current layer. In this way, your app can make a large MPSImage or MPSTemporaryImage object and fill in parts of it with multiple layers (as long as the destination feature channel offset is a multiple of 4).\n\nSupported Pixel Formats\n\nTable 1 shows pixel formats supported by MPSImage.\n\nTable 1 MPSImage supported pixel formats\n\nMTLPixelFormat.r8Unorm\n\n\t\n\nMTLPixelFormat.rg8Unorm\n\n\t\n\nMTLPixelFormat.rgba8Unorm\n\n\t\n\nMTLPixelFormat.bgra8Unorm\n\n\n\n\nMTLPixelFormat.r8Unorm_srgb\n\n\t\n\nMTLPixelFormat.rg8Unorm_srgb\n\n\t\n\nMTLPixelFormat.rgba8Unorm_srgb\n\n\t\n\nMTLPixelFormat.bgra8Unorm_srgb\n\n\n\n\nMTLPixelFormat.r16Unorm\n\n\t\n\nMTLPixelFormat.rg16Unorm\n\n\t\n\nMTLPixelFormat.rgba16Unorm\n\n\t\n\n\n\n\nMTLPixelFormat.r16Float\n\n\t\n\nMTLPixelFormat.rg16Float\n\n\t\n\nMTLPixelFormat.rgba16Float\n\n\t\n\n\n\n\nMTLPixelFormat.r32Float\n\n\t\n\nMTLPixelFormat.rg32Float\n\n\t\n\nMTLPixelFormat.rgba32Float\n\n\t\n\nTopics\nInitializers\ninit(device: MTLDevice, imageDescriptor: MPSImageDescriptor)\nInitializes an empty image.\nclass MPSImageDescriptor\nA description of the attributes used to create an MPSImage.\ninit(texture: MTLTexture, featureChannels: Int)\nInitializes an image from a texture. The user-allocated texture has been created for a specific number of feature channels and number of images.\ninit(parentImage: MPSImage, sliceRange: NSRange, featureChannels: Int)\nMethods\nfunc setPurgeableState(MPSPurgeableState) -> MPSPurgeableState\nSet (or query) the purgeable state of the image’s underlying texture.\nenum MPSPurgeableState\nThe purgeable state of an image’s underlying texture.\nMethods to Read and Write Raw Data\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, imageIndex: Int)\nstruct MPSImageReadWriteParams\nParameters that control reading and writing of a particular set of feature channels.\nenum MPSDataLayout\nOptions that define how buffer data is arranged.\nMethods to Get an Image Allocator\nclass func defaultAllocator() -> MPSImageAllocator\nprotocol MPSImageAllocator\nProperties\nvar device: MTLDevice\nThe device on which the image will be used.\nvar width: Int\nThe formal width of the image, in pixels.\nvar height: Int\nThe formal height of the image, in pixels.\nvar featureChannels: Int\nThe number of feature channels per pixel.\nvar numberOfImages: Int\nThe number of images for batch processing.\nvar textureType: MTLTextureType\nThe type of the underlying texture, typically MTLTextureType.type2D or MTLTextureType.type2DArray.\nenum MTLTextureType\nThe dimension of each image, including whether multiple images are arranged into an array or a cube.\nvar pixelFormat: MTLPixelFormat\nThe pixel format of the underlying texture.\nenum MTLPixelFormat\nThe data formats that describe the organization and characteristics of individual pixels in a texture.\nvar precision: Int\nThe number of bits of numeric precision available for each feature channel.\nvar usage: MTLTextureUsage\nThe intended usage of the underlying texture.\nstruct MTLTextureUsage\nAn enumeration for the various options that determine how you can use a texture.\nvar pixelSize: Int\nThe number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\nvar texture: MTLTexture\nThe underlying texture.\nprotocol MTLTexture\nA resource that holds formatted image data.\nvar label: String?\nA string to help identify this object.\nInstance Properties\nvar featureChannelFormat: MPSImageFeatureChannelFormat\nvar parent: MPSImage?\nInstance Methods\nfunc batchRepresentation() -> [MPSImage]\nfunc batchRepresentation(withSubRange: NSRange) -> [MPSImage]\nfunc readBytes(UnsafeMutableRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, bytesPerImage: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc resourceSize() -> Int\nfunc subImage(withFeatureChannelRange: NSRange) -> MPSImage\nfunc synchronize(on: MTLCommandBuffer)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, bytesPerColumn: Int, bytesPerRow: Int, bytesPerImage: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nfunc writeBytes(UnsafeRawPointer, dataLayout: MPSDataLayout, bytesPerRow: Int, bytesPerImage: Int, region: MTLRegion, featureChannelInfo: MPSImageReadWriteParams, imageIndex: Int)\nRelationships\nInherits From\nNSObject\nSee Also\nNeural Networks\nTraining a Neural Network with Metal Performance Shaders\nUse an MPS neural network graph to train a simple neural network digit classifier.\nclass MPSTemporaryImage\nA texture for use in convolutional neural networks that stores transient data to be used and discarded promptly.\nObjects that Simplify the Creation of Neural Networks\nSimplify the creation of neural networks using networks of filter, image, and state nodes.\nConvolutional Neural Network Kernels\nBuild neural networks with layers.\nRecurrent Neural Networks\nCreate recurrent neural networks."
  },
  {
    "title": "Training a Neural Network with Metal Performance Shaders | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders/training_a_neural_network_with_metal_performance_shaders",
    "html": "Overview\n\nThe sample code describes how to write a neural network using MPSNNGraph and how to train the network to recognize a digit in an image. The sample trains a network for 300 iterations on a batch size of 40 images. You’ll see how to set up training of weights and biases using data sources, including how to initialize and update weights. You’ll also see how to validate the network using a test dataset.\n\nNote\n\nThis sample code project is associated with WWDC 2019 session 614: Metal for Machine Learning.\n\nYou can use any dataset of your choice to train this model. The following dataset works well for this purpose:\n\nMNIST Dataset\n\nPlease note that Apple does not own the copyright to this dataset nor makes any representations about the applicable terms of use for this dataset.\n\nIf you choose to use this dataset, the sample includes a script that downloads the dataset from that location and pass it as input to the model.\n\nConfigure the Sample Code Project\n\nBefore you run the sample code project in Xcode:\n\nMake sure your Mac is running macOS 10.15 or later.\n\nMake sure you are running Xcode 11 or later.\n\nSee Also\nNeural Networks\nclass MPSImage\nA texture that may have more than four channels for use in convolutional neural networks.\nclass MPSTemporaryImage\nA texture for use in convolutional neural networks that stores transient data to be used and discarded promptly.\nObjects that Simplify the Creation of Neural Networks\nSimplify the creation of neural networks using networks of filter, image, and state nodes.\nConvolutional Neural Network Kernels\nBuild neural networks with layers.\nRecurrent Neural Networks\nCreate recurrent neural networks."
  },
  {
    "title": "Metal Performance Shaders | Apple Developer Documentation",
    "url": "https://developer.apple.com/documentation/metalperformanceshaders",
    "html": "Overview\n\nThe Metal Performance Shaders framework contains a collection of highly optimized compute and graphics shaders that are designed to integrate easily and efficiently into your Metal app. These data-parallel primitives are specially tuned to take advantage of the unique hardware characteristics of each GPU family to ensure optimal performance.\n\nApps adopting the Metal Performance Shaders framework achieve great performance without needing to create and maintain hand-written shaders for each GPU family. Metal Performance Shaders can be used along with your app’s existing Metal resources (such as the MTLCommandBuffer, MTLTexture, and MTLBuffer objects) and shaders.\n\nThe Metal Performance Shaders framework supports the following functionality:\n\nApply high-performance filters to, and extract statistical and histogram data from images.\n\nImplement and run neural networks for machine learning training and inference.\n\nSolve systems of equations, factorize matrices and multiply matrices and vectors.\n\nAccelerate ray tracing with high-performance ray-geometry intersection testing.\n\nTopics\nFundamentals\nThe MPSKernel Class\nTuning Hints\nDevice Support\nfunc MPSSupportsMTLDevice(MTLDevice?) -> Bool\nDetermines whether the Metal Performance Shaders framework supports a Metal device.\nImage Filters\nImage Filters\nApply high-performance filters to, and extract statistical and histogram data from images.\nNeural Networks\nImplement and run deep learning using previously obtained training data.\nTraining a Neural Network with Metal Performance Shaders\nUse an MPS neural network graph to train a simple neural network digit classifier.\nclass MPSImage\nA texture that may have more than four channels for use in convolutional neural networks.\nclass MPSTemporaryImage\nA texture for use in convolutional neural networks that stores transient data to be used and discarded promptly.\nObjects that Simplify the Creation of Neural Networks\nSimplify the creation of neural networks using networks of filter, image, and state nodes.\nConvolutional Neural Network Kernels\nBuild neural networks with layers.\nRecurrent Neural Networks\nCreate recurrent neural networks.\nMatrices and Vectors\nMatrices and Vectors\nSolve systems of equations, factorize matrices and multiply matrices and vectors.\nKernel Base Classes\nclass MPSKernel\nA standard interface for Metal Performance Shaders kernels.\nKeyed Archivers\nclass NSKeyedArchiver\nAn encoder that stores an object’s data to an archive referenced by keys.\nclass MPSKeyedUnarchiver\nA keyed archiver that supports Metal Performance Shaders kernel decoding.\nprotocol MPSDeviceProvider\nAn interface that enables the setting of a Metal device for unarchived objects.\nRay Tracing\nAnimating and Denoising a Raytraced Scene\nSupport dynamic scenes and denoising by extending your ray tracer with Metal Performance Shaders.\nclass MPSRayIntersector\nA kernel that performs intersection tests between rays and geometry.\nDeprecated\nclass MPSAccelerationStructureGroup\nA group of acceleration structures.\nDeprecated\nclass MPSInstanceAccelerationStructure\nAn acceleration structure built over instances of other acceleration structures.\nDeprecated\nclass MPSTriangleAccelerationStructure\nAn acceleration structure built over triangles.\nDeprecated\nclass MPSAccelerationStructure\nThe base class for data structures that are built over geometry and used to accelerate ray tracing.\nDeprecated\nClasses\nclass MPSCNNConvolutionTransposeGradient\nclass MPSCNNConvolutionTransposeGradientNode\nclass MPSCNNConvolutionTransposeGradientState\nclass MPSCNNConvolutionTransposeGradientStateNode\nclass MPSCNNFullyConnectedGradientNode\nclass MPSCNNGroupNormalization\nclass MPSCNNGroupNormalizationGradient\nclass MPSCNNGroupNormalizationGradientNode\nclass MPSCNNGroupNormalizationGradientState\nclass MPSCNNGroupNormalizationNode\nclass MPSCNNMultiaryKernel\nclass MPSCNNNeuronGeLUNode\nclass MPSCommandBuffer\nclass MPSImageCanny\nclass MPSImageEDLines\nclass MPSImageNormalizedHistogram\nA filter that computes the normalized histogram of an image.\nclass MPSMatrixRandom\nclass MPSMatrixRandomDistributionDescriptor\nclass MPSMatrixRandomMTGP32\nclass MPSMatrixRandomPhilox\nclass MPSNDArray\nclass MPSNDArrayBinaryKernel\nclass MPSNDArrayBinaryPrimaryGradientKernel\nclass MPSNDArrayBinarySecondaryGradientKernel\nclass MPSNDArrayDescriptor\nclass MPSNDArrayGather\nclass MPSNDArrayGatherGradient\nclass MPSNDArrayGatherGradientState\nclass MPSNDArrayGradientState\nclass MPSNDArrayMatrixMultiplication\nclass MPSNDArrayMultiaryBase\nclass MPSNDArrayMultiaryGradientKernel\nclass MPSNDArrayMultiaryKernel\nclass MPSNDArrayStridedSlice\nclass MPSNDArrayStridedSliceGradient\nclass MPSNDArrayUnaryGradientKernel\nclass MPSNDArrayUnaryKernel\nclass MPSNNCompare\nclass MPSNNComparisonNode\nclass MPSNNCropAndResizeBilinear\nA cropping and bilinear resizing filter.\nclass MPSNNForwardLoss\nclass MPSNNForwardLossNode\nclass MPSNNGramMatrixCalculation\nclass MPSNNGramMatrixCalculationGradient\nclass MPSNNGramMatrixCalculationGradientNode\nclass MPSNNGramMatrixCalculationNode\nclass MPSNNGridSample\nclass MPSNNInitialGradient\nclass MPSNNInitialGradientNode\nclass MPSNNLocalCorrelation\nclass MPSNNLossGradient\nclass MPSNNLossGradientNode\nclass MPSNNMultiaryGradientState\nclass MPSNNMultiaryGradientStateNode\nclass MPSNNPad\nclass MPSNNPadGradient\nclass MPSNNPadGradientNode\nclass MPSNNPadNode\nclass MPSNNReductionColumnMaxNode\nclass MPSNNReductionColumnMeanNode\nclass MPSNNReductionColumnMinNode\nclass MPSNNReductionColumnSumNode\nclass MPSNNReductionFeatureChannelsArgumentMaxNode\nclass MPSNNReductionFeatureChannelsArgumentMinNode\nclass MPSNNReductionFeatureChannelsMaxNode\nclass MPSNNReductionFeatureChannelsMeanNode\nclass MPSNNReductionFeatureChannelsMinNode\nclass MPSNNReductionFeatureChannelsSumNode\nclass MPSNNReductionRowMaxNode\nclass MPSNNReductionRowMeanNode\nclass MPSNNReductionRowMinNode\nclass MPSNNReductionRowSumNode\nclass MPSNNReductionSpatialMeanGradientNode\nclass MPSNNReductionSpatialMeanNode\nclass MPSNNReshapeGradient\nclass MPSNNReshapeGradientNode\nclass MPSNNReshapeNode\nclass MPSNNResizeBilinear\nA bilinear resizing filter.\nclass MPSNNUnaryReductionNode\nclass MPSPolygonAccelerationStructure\nDeprecated\nclass MPSPolygonBuffer\nDeprecated\nclass MPSPredicate\nclass MPSQuadrilateralAccelerationStructure\nDeprecated\nclass MPSSVGF\nclass MPSSVGFDefaultTextureAllocator\nclass MPSSVGFDenoiser\nclass MPSStateResourceList\nAn interface for objects that define resources for Metal Performance Shaders state containers.\nclass MPSTemporalAA\nclass MPSTemporaryNDArray\nProtocols\nprotocol MPSCNNGroupNormalizationDataSource\nprotocol MPSHeapProvider\nprotocol MPSNDArrayAllocator\nprotocol MPSNNGramMatrixCallback\nprotocol MPSNNLossCallback\nprotocol MPSSVGFTextureAllocator\nReference\nMetalPerformanceShaders Structures\nMetalPerformanceShaders Enumerations\nMetalPerformanceShaders Constants\nMetalPerformanceShaders Functions\nMetalPerformanceShaders Data Types\nSee Also\nRelated Documentation\nMetal\nRender advanced 3D graphics and compute data in parallel with graphics processors.\nMetal Programming Guide"
  }
]