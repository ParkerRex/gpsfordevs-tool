[
  {
    "title": "Developer Labs - visionOS - Apple Developer",
    "url": "https://developer.apple.com/visionos/labs/",
    "html": "Apple Vision Pro developer labs\n\nApply to attend a one-day developer lab to experience your visionOS, iPadOS, or iOS apps running on Apple Vision Pro. With support from Apple, you’ll be able to test and optimize your apps and games so they’ll be ready for the infinite spatial canvas.\n\nWhat to expect\n\nIn these self-directed coding and design labs, you’ll be able to test and optimize your apps for visionOS. Bring your Mac, code, and everything you need to modify, build, run, and test your app on Apple Vision Pro. Apple experts will be available to help you with setup and troubleshooting.\n\nLocations\n\nApple Vision Pro developer labs are available in London, Munich, Shanghai, Singapore, Sydney, and Tokyo.\n\nEligibility\n\nLab appointments are available to current members of the Apple Developer Program or the Apple Developer Enterprise Program who are at least 18 years old. You must have a new visionOS app in active development or an existing iPadOS or iOS app.\n\nHow to apply\n\nSign in with your Apple ID and complete the request form, which will require a screenshot of your app running in the visionOS simulator. Requests will be reviewed and priority will be given to new visionOS apps and existing iPadOS and iOS apps being enhanced for visionOS. We recommend one designer and one engineer attend the lab. Each member will need to submit a request separately for the same day and location.\n\nGet started"
  },
  {
    "title": "Developer Kit - visionOS - Apple Developer",
    "url": "https://developer.apple.com/visionos/developer-kit/",
    "html": "Apple Vision Pro developer kit\n\nHave an innovative idea for an app or game for visionOS that requires building and testing on Apple Vision Pro? Apply for an Apple Vision Pro developer kit. This kit will help you deliver amazing spatial experiences by letting you quickly build, iterate, and test on Vision Pro.\n\nHow it works\n\nWe’ll loan you an Apple Vision Pro developer kit to prepare your app for the launch of the new App Store on Apple Vision Pro.\n\nYou’ll also receive:\n\nHelp setting up the device and onboarding.\nCheck-ins with Apple experts for UI design and development guidance, and help refining your app.\nTwo additional code-level support requests, so you can troubleshoot any issues with your code.\n\nThis Apple-owned development device needs to be returned upon request.\n\nHow to apply\n\nSubmit a brief application for an Apple Vision Pro developer kit. You’ll need to be an Account Holder in the Apple Developer Program or Apple Developer Enterprise Program, provide details about your team’s development skills and existing apps, and agree to the terms and conditions. Applications will be reviewed and priority will be given to applicants creating an app that takes advantage of visionOS features and capabilities. If you’re selected to receive a kit, we’ll contact you.\n\nGet started"
  },
  {
    "title": "Compatibility Evaluations - visionOS - Apple Developer",
    "url": "https://developer.apple.com/visionos/compatibility-evaluations/",
    "html": "Apple Vision Pro\ncompatibility evaluations\n\nWe can help you make sure your app or game behaves as expected on Apple Vision Pro. Start with the steps and compatibility checklist below, then submit a request to have it evaluated directly on Apple Vision Pro. We’ll send you the evaluation results, along with any relevant screen captures or crash logs.\n\nBefore you submit\n\nMake sure to complete these steps to address common issues before submitting your visionOS, iPadOS, or iOS app for evaluation on the device.\n\nReview the following documentation to determine if your iPadOS or iOS app will run in visionOS or requires modification:\nChecking whether your existing app is compatible with visionOS\nMaking your existing app compatible with visionOS\nConsider whether any functionality of your app should be adjusted to provide alternatives for users on Apple Vision Pro — for example, if a feature requires the accelerometer, consider limiting that feature to devices with accelerometer support or providing an alternative for devices without accelerometer capabilities.\nRun and test your app in the visionOS simulator in Xcode, evaluate your app using the compatibility checklist below, and address any issues that may limit our ability to evaluate it. For example, if your app crashes on launch, we’ll be unable to evaluate and provide feedback on the app experience. Review these documentation for help:\nBringing your existing apps to visionOS\nInteracting with your app in the visionOS simulator\nEnsure that the version of your compatible app you’d like us to test has been submitted for review, either through TestFlight external testing or the App Store.\nIf your app requires a demo account, ensure the demo account information you’ve provided is active and up to date. Consider implementing a demonstration mode if your app operates in a highly regulated industry that restricts account creation.\nCompatibility checklist\n\nYour app will be evaluated in the following areas for compatibility with Apple Vision Pro. Check that your app passes the following evaluation areas before submitting your request for evaluation on the device.\n\nEvaluation area\n\n\t\n\nWhat to verify\n\n\t\n\nDetails\n\n\n\n\nApp is functional\n\n\t\n\nYour app launches and runs in the visionOS simulator without issues. The core functionality of your app works as expected.\n\n\t\n\nRun and exercise your app in the visionOS simulator to confirm there aren’t any issues during all use cases.\n\nDiagnosing and resolving bugs in your running app\nRunning your app in Simulator or on a device\n\n\n\nNo bugs are exhibited\n\n\t\n\nThe app’s features and functions work as intended without issue.\n\n\t\n\nCheck your app’s features in the visionOS simulator to confirm there aren’t any issues during primary task completion. Step through each view, page, layout, button, and feature to check functionality.\n\nDiagnosing and resolving bugs in your running app\n\n\n\nApp is performant\n\n\t\n\nYour app performs without visual disruption or stressing thermal and power facilities on iPad with M1 or later. Verify that the app runs smoothly in the visionOS simulator.\n\n\t\n\nCheck that your app performs smoothly on iPad or iPhone and in the visionOS simulator.\n\nImproving your app’s performance\nAnalyzing the performance of your Metal app\n\n\n\nApp doesn’t make capability assumptions\n\n\t\n\nYour app doesn’t depend on specific device features or functions that aren’t available on Apple Vision Pro.\n\n\t\n\nEnsure that your app considers authorization status and availability when using system features. Handle any unavailable features gracefully and provide alternatives wherever possible. Also make sure to handle instances where user permission isn’t granted.\n\nChecking whether your existing app is compatible with visionOS\nEstablishing UIRequiredDeviceCapabilities\n\n\n\nApp launches in the correct orientation\n\n\t\n\nYour app launches in the expected orientation for primary use. If your app supports multiple layouts, also verify that the rotation button appears and works as expected.\n\n\t\n\nMake sure your app specifies a preferred orientation in your Info.plist, as there’s no concept of rotating Apple Vision Pro.\n\nRun your iPad and iPhone apps in the Shared Space\n\n\n\nApp doesn’t rely on a camera\n\n\t\n\nYour app works without a rear camera or front FaceTime camera for taking photos or video. If a feature uses the camera, the app provides the option to choose from the photo library up front or a method to gracefully exit the camera view to continue use of the app.\n\n\t\n\nApple Vision Pro cameras aren’t accessible in the same way as iPhone and iPad. Make sure your app provides alternatives when a camera isn’t available.\n\nEnhance your iPad and iPhone apps for the Shared Space\n\n\n\nApp doesn’t require precise location\n\n\t\n\nYour app doesn’t rely on precise user location or GPS data in order to facilitate core functionality.\n\n\t\n\nApple Vision Pro doesn’t have GPS functions and supports basic location services. Also consider any potential safety implications of your app on Apple Vision Pro.\n\nChecking whether your existing app is compatible with visionOS\nMaking your existing app compatible with visionOS\n\n\n\nApp doesn’t rely on more than two touch inputs\n\n\t\n\nYour app doesn’t have features that rely on more than two touch inputs at once, without an alternative method, to complete a necessary task.\n\n\t\n\nvisionOS supports a maximum of two simultaneous touch inputs — one for each of the user’s hands. All system gesture recognizers handle these inputs correctly, including for zoom and rotation gestures that require multiple fingers. If you have custom gesture recognizers that require more than two fingers, update them to support one or two touches in visionOS.\n\nIf you have a game, verify that it’s playable and a good experience with only two simultaneous inputs. If your game requires more than two inputs, as with many virtual on-screen controls, consider supporting physical game controllers and set GCSupportsControllerUserInteraction properly to enable a “Requires Game Controller” badge on the App Store.\n\nGame controllers\nSubmitting a request\n\nThis service is available to members of the Apple Developer Program with a visionOS, iPadOS, or iOS app on TestFlight or the App Store. Once you’ve followed the steps above and evaluated your app using the compatibility checklist, you can submit a request for us to evaluate your app on Apple Vision Pro. We’ll complete a compatibility evaluation and send the results to the email address you provide. Results will include details of any issues from the compatibility checklist, along with any relevant screen captures and logs. Availability is limited and on a first-come-first-served basis. If capacity gets full, you’ll be added to the waitlist and we’ll reach out when more spots become available.\n\nGet started\nAdditional resources\n\nLearn more best practices for spatial computing on Apple Vision Pro.\n\nRun your iPad and iPhone apps in the Shared Space\nEnhance your iPad and iPhone apps for the Shared Space\nGet started with building apps for spatial computing\nApple Vision Pro Human Interface Guidelines"
  },
  {
    "title": "Downloads and Resources - visionOS - Apple Developer",
    "url": "https://developer.apple.com/visionos/resources/",
    "html": "Get visionOS resources\n\nTools, documentation, tutorials, videos, and more.\n\nXcode 15\n\nThis version includes the visionOS SDK, Reality Composer Pro, and everything you need to create apps for all Apple platforms.\n\nDownload Xcode\n\nDocumentation and videos\nAPI reference and sample code\n\nBrowse the latest documentation, including API reference, articles, and sample code for building visionOS apps.\n\nView documentation\n\nVideos\n\nLearn about spatial computing design and development through presentations by Apple engineers.\n\nWatch videos\n\nHuman Interface Guidelines\n\nFind guidance and UI resources for designing great apps that integrate seamlessly with visionOS.\n\nView the Human Interface Guidelines\nDownload Apple Design Resources\nForums\n\nAsk questions and discuss development topics with Apple engineers and other developers.\n\nVisit the forums\n\nOptional accessories\nDeveloper Strap\n\nProvides a USB-C connection between Apple Vision Pro and Mac and is helpful for accelerating the development of graphics-intensive apps and games.\n\nLearn more\n\n\nAvailable to Apple Developer Program members in the U.S."
  },
  {
    "title": "Learn - visionOS - Apple Developer",
    "url": "https://developer.apple.com/visionos/learn/",
    "html": "Learn about visionOS\n\nThe infinite canvas awaits.\n\nGet started with visionOS\nDesign for visionOS\nExplore developer tools\nGames and media experiences\nCollaboration and productivity\nWeb experiences\niPad and iPhone apps\nFind your path\n\nWith best-in-class frameworks and tools, visionOS is the perfect platform for you to create incredible spatial experiences. Whether you’re dreaming up an app or game, building a media experience, designing moments of connection and collaboration with SharePlay, creating apps for business, or updating your website to support visionOS, we’ve got sessions and information to help you make your plan. Get ready for the SDK with 46 sessions that will help you learn about developing for visionOS, designing for spatial experiences, and testing and tools.\n\nGet started with visionOS\n\nvisionOS brings familiar frameworks and brand new concepts together so you can build an entirely new universe of apps designed for spatial computing. To help get you started on your journey, we’ve put together an introductory series of sessions that cover the building blocks of spatial computing along with designing apps and games for this platform. Learn how familiar frameworks like SwiftUI, UIKit, RealityKit, and ARKit have evolved to help you build apps for an infinite canvas. These sessions are designed to provide a great foundation for developing for visionOS — no matter your prior experience with Apple platforms.\n\nMeet spatial computing\n\nDiscover the fundamentals that make up spatial computing — windows, volumes, and spaces — and find out how you can use these elements to build engaging and immersive experiences. We’ll take you through the frameworks you’ll use to create apps for visionOS and show you how to design with depth, scale, and immersion. Explore how you can use tools from Apple, like Xcode and the new Reality Composer Pro, and how you can make spatial computing apps that work well for everyone.\n\nGet started with building apps for spatial computing\nPrinciples of spatial design\nCreate accessible spatial experiences\nDevelop your first immersive app\n\nOnce you’ve familiarized yourself with the basics of visionOS, find out more about the frameworks that power this platform. Take a tour of SwiftUI for visionOS and learn how you can add depth to your windows and volumes, and use a Full Space to let people experience your app like never before. We’ll also introduce you to UIKit for spatial computing and share how you can use it alongside SwiftUI.\n\nMeet SwiftUI for spatial computing\nMeet UIKit for spatial computing\nRelated documentation\nCreating your first visionOS app\nAdding 3D content to your app\nCreating fully immersive experiences in your app\nDesigning for visionOS\nExplore SwiftUI and RealityKit\n\nFor an even deeper dive into SwiftUI and RealityKit, explore a dedicated series of sessions focusing on SwiftUI scene types to help you build great experiences across windows, volumes, and spaces. Get to know the Model 3D API, learn how you can add depth and dimension to your app, and find out how to render 3D content with RealityView. And we’ll help you get ready to launch into ImmersiveSpace — a new SwiftUI scene type that lets you make great immersive experiences for visionOS. Learn best practices for managing your scene types, increasing immersion, and building an \"out of this world\" experience.\n\nElevate your windowed app for spatial computing\nTake SwiftUI to the next dimension\nGo beyond the window with SwiftUI\nRelated documentation\nHello World\nPresenting windows and spaces\nPositioning and sizing windows\n\nIn our second series, learn how you can bring engaging and immersive content to your app with RealityKit. Get started with RealityKit entities, components, and systems, and find out how to add 3D models and effects to your project. We’ll show you how you can embed your content into an entity hierarchy, blend virtual content and the real world using anchors, bring particle effects into your apps, add video content, and create more immersive experiences with portals.\n\nEnhance your spatial computing app with RealityKit\nBuild spatial experiences with RealityKit\nRelated documentation\nDiorama\nUnderstanding RealityKit’s modular architecture\nRediscover ARKit\n\nLastly, we’ll help you get to know ARKit on visionOS. This platform uses ARKit algorithms to handle features like persistence, world mapping, segmentation, matting, and environment lighting. These algorithms are always running, allowing apps and games to automatically benefit from ARKit while in the Shared Space. Once your app opens a dedicated Full Space, it can take advantage of ARKit APIs and blend virtual content with the real world.\n\nWe’ll share how this framework has been completely reimagined to let you build interactive experiences — all while preserving privacy. Discover how you can make 3D content that interacts with someone’s room — whether you want to bounce a virtual ball off the floor or throw virtual paint on a wall. Explore the latest updates to the ARKit API and follow along as we demonstrate how to take advantage of hand tracking and scene geometry in your apps.\n\nMeet ARKit for spatial computing\nEvolve your ARKit app for spatial experiences\nRelated documentation\nHappy Beam\nSetting up access to ARKit data\nPlacing content on detected planes\nIncorporating real-world surroundings in an immersive experience\nTracking specific points in world space\nTracking preregistered images in 3D space\nDesign for visionOS\n\nFind out how you can design great apps, games, and experiences for spatial computing. Discover brand-new inputs and components. Dive into depth and scale. Add moments of immersion. Create spatial audio soundscapes. Find opportunities for collaboration and connection. And help people stay grounded to their surroundings while they explore entirely new worlds. Whether this is your first time designing spatial experiences or you’ve been building fully immersive apps for years, learn how you can create magical hero moments, enchanting soundscapes, human-centric UI, and more — all with visionOS.\n\nPrinciples of spatial design\nDesign spatial user interfaces\nDesign for spatial input\nExplore immersive sound design\nDesign considerations for vision and motion\nDesign spatial SharePlay experiences\nRelated documentation\nDesigning for visionOS\nDesigning for spatial layout\nDesigning immersive experiences\nDesigning for eyes\nDesigning for gestures\nAdopting best practices for privacy and user preferences\nImproving accessibility support in your visionOS app\nExplore developer tools for visionOS\n\nApple offers a comprehensive suite of tools to help you build great apps, games, and experiences for visionOS. Learn how you can get started in Xcode with your first visionOS project, explore updates to tooling and testing, find out how to take advantage of Reality Composer Pro in your 3D development workflow, and discover how you’ll be able use Unity’s authoring tools to create great experiences for spatial computing.\n\nDevelop with Xcode\n\nStart developing for visionOS with Xcode. We’ll show you how to add an visionOS destination to your existing projects or build an entirely new app, prototype in Xcode Previews, and import content from Reality Composer Pro. We’ll also share how you can use the visionOS simulator to evaluate your experiences against a variety of simulated scenes and lighting conditions. Learn how to create tests and visualizations to explore collisions, occlusions, and scene understanding for your spatial content, and optimize that content for performance and efficiency.\n\nWhat’s new in Xcode 15\nDevelop your first immersive app\nMeet RealityKit Trace\nExplore rendering for spatial computing\nOptimize app power and performance for spatial computing\nMeet Core Location for spatial computing\nRelated documentation\nDiagnosing and resolving bugs in your running app\nDiagnosing issues in the appearance of a running app\nCreating a performance plan for your visionOS app\nManaging files and folders in your Xcode project\nConfiguring your app icon\nRunning your app in Simulator or on a device\nInteracting with your app in the visionOS simulator\nMeet Reality Composer Pro\n\nDiscover a new way to preview and prepare 3D content for your visionOS apps. Available later this month, Reality Composer Pro leverages the power of USD to help you compose, edit and preview assets, such as 3D models, materials, and sounds. We’ll show you how to take advantage of this tool to create immersive content for your apps, add materials to objects, and bring your Reality Composer Pro content to life in Xcode. We’ll also take you through the latest updates to Universal Scene Description (USD) on Apple platforms.\n\nMeet Reality Composer Pro\nExplore materials in Reality Composer Pro\nWork with Reality Composer Pro content in Xcode\nExplore the USD ecosystem\nRelated documentation\nDesigning RealityKit content with Reality Composer Pro\nGet started with Unity\n\nLearn how you can build visionOS experiences directly in Unity. Discover how Unity developers can use their existing 3D scenes and assets to build an app or game for visionOS. Thanks to deep integration between Unity and Apple frameworks, you can create an experience anywhere you can use RealityKit — whether you’re building 3D content for a window, volume, or the Shared Space. You also get all the benefits of building for Apple platforms, including access to native inputs, passthrough, and more. And we’ll also show you how you can use Unity to create fully immersive experiences.\n\nLearn more about building apps in Unity\n\nCreate immersive Unity apps\nBring your Unity VR app to a fully immersive space\nLearn about TestFlight and App Store Connect\n\nApp Store Connect will provide the tools you need to manage, test, and deploy your visionOS apps on the App Store. We’ll share basics and best practices for deploying your first spatial computing app, adding support for visionOS to an existing app, and managing compatibility. We’ll also show you how TestFlight for visionOS lets you test your apps and collect valuable feedback as you iterate.\n\nExplore App Store Connect for spatial computing\nBuild games and media experiences\n\nDiscover how you can create truly immersive moments in your games and media experiences with visionOS. Games and media can take advantage of the full spectrum of immersion to tell incredible stories and connect with people in a new way. We’ll show you the pathways available for you to get started with game and narrative development for visionOS. Learn ways to render 3D content effectively with RealityKit, explore design considerations for vision and motion, and find out how you can create fully immersive experiences that transport people to a new world with Metal or Unity.\n\nBuild great games for spatial computing\nExplore rendering for spatial computing\nDesign considerations for vision and motion\nCreate immersive Unity apps\nBring your Unity VR app to a fully immersive space\nDiscover Metal for immersive apps\n\nSound can also dramatically enhance the experience of your visionOS apps and games — whether you add an effect to a button press or create an entirely immersive soundscape. Learn how Apple designers select sounds and build soundscapes to create textural, immersive experiences in windows, volumes, and spaces. We’ll share how you can enrich basic interactions in your app with sound when you place audio cues spatially, vary repetitive sounds, and build moments of sonic delight into your app.\n\nExplore immersive sound design\n\nIf your app or game features media content, we’ve got a series of sessions designed to help you update your video pipeline and build a great playback experience for visionOS. Learn how you can expand your delivery pipeline to support 3D content, and get tips and techniques for spatial media streaming in your app. We’ll also show you how to create engaging and immersive playback experiences with the frameworks and APIs that power video playback for visionOS.\n\nDeliver video content for spatial experiences\nCreate a great spatial playback experience\nRelated documentation\nDestination Video\nConfiguring your app for media playback\nAdopting the system player interface in visionOS\nControlling the transport behavior of a player\nMonitoring playback progress in your app\nTrimming and exporting media in visionOS\nBuild for collaboration, sharing, and productivity\n\nSharing and collaboration make up a central part of visionOS by offering experiences in apps and games that make people feel present as if they were in the same space. By default, people can share any app window with others on a FaceTime call, just like they can on Mac. But when you adopt the GroupActivities framework, you can create next-generation collaborative experiences.\n\nGet started designing and building for SharePlay on Apple Vision Pro by learning about the types of shared activities you can create in your app. Discover how you can establish shared context between participants in your experiences and find out how you can support even more meaningful interactions in your app by supporting Spatial Personas.\n\nDesign spatial SharePlay experiences\nBuild spatial SharePlay experiences\nBuild web experiences\n\nDiscover the web for visionOS and learn how people can experience your web content in a whole new way. Explore the input model for this platform and learn how you can optimize your website for spatial computing. We’ll also share how emerging standards are helping shape 3D experiences for the web, dig into the latest updates to Safari extensions, and help you use the developer features in Safari to prototype and test your experiences for Apple Vision Pro.\n\nMeet Safari for spatial computing\nWhat’s new in Safari extensions\nRediscover Safari developer features\n\nWhether you use Quick Look on the web or in your app, learn how you can add powerful previews for 3D content, spatial images and videos, and much more. We’ll share the different ways that the system presents these experiences, demonstrate how someone can drag and drop this content to create a new window in the Shared Space, and explore how you can access Quick Look directly within an app. We’ll also go over best practices when creating 3D content for Quick Look in visionOS, including important considerations for 3D quality and performance.\n\nDiscover Quick Look for spatial computing\nCreate 3D models for Quick Look spatial experiences\nRun your iPad and iPhone apps in visionOS\n\nDiscover how you can run your existing iPadOS and iOS apps in visionOS. Explore how iPadOS and iOS apps operate on this platform, learn about framework dependencies, and find out about the Designed for iPad app interaction. When you’re ready to take your existing apps to the next level, we’ll show you how to optimize your iPad and iPhone app experience for the Shared Space and help you improve your visual treatment.\n\nRun your iPad and iPhone apps in the Shared Space\nEnhance your iPad and iPhone apps for the Shared Space\nRelated documentation\nTake your iPad and iPhone apps even further on Apple Vision Pro\nBringing your existing apps to visionOS\nBringing your ARKit app to visionOS\nChecking whether your existing app is compatible with visionOS\nMaking your existing app compatible with visionOS"
  },
  {
    "title": "Work with Apple - visionOS - Apple Developer",
    "url": "https://developer.apple.com/visionos/work-with-apple/",
    "html": "Work with Apple\n\nGet direct support from Apple as you develop your apps and games for visionOS. Learn about upcoming events, testing opportunities, and other programs to support you as you create incredible experiences for this platform.\n\nCompatibility evaluations\n\nWe can help you make sure your visionOS, iPadOS, and iOS apps behave as expected on Apple Vision Pro. Align your app with the newly published compatibility checklist, then request to have your app evaluated directly on Apple Vision Pro.\n\nLearn more about compatibility evaluations\n\nDeveloper labs\n\nExperience your visionOS, iPadOS, and iOS apps running on Apple Vision Pro. With support from Apple, you’ll be able to test and optimize your apps for the infinite spatial canvas. Labs are available in Cupertino, London, Munich, New York City, Shanghai, Singapore, Sydney, and Tokyo.\n\nLearn more about developer labs\n\nDeveloper kit\n\nHave a great idea for a visionOS app that requires building and testing on Apple Vision Pro? Apply for an Apple Vision Pro developer kit. With continuous, direct access to Apple Vision Pro, you’ll be able to quickly build, test, and refine your app so it delivers amazing spatial experiences in visionOS.\n\nLearn more about the developer kit"
  },
  {
    "title": "Submit your apps to the App Store for Apple Vision Pro - Apple Developer",
    "url": "https://developer.apple.com/visionos/submit/",
    "html": "Submit your apps to the App Store for Apple Vision Pro\n\nApple Vision Pro has a brand-new App Store, where people can discover and download all the incredible apps for visionOS. Whether you’ve created a new visionOS app or are making your existing iPad or iPhone app available on Apple Vision Pro, here’s everything you need to know to prepare your app for the App Store.\n\nPrepare your app\nCreate your product page\nSubmit your app\nPrepare your app\nCompatible iPad and iPhone apps\n\nMost iPadOS and iOS apps can run unmodified on Apple Vision Pro, so your app can easily extend to this new platform — with no additional work required. Your compatible iPad and iPhone apps will be published automatically on the App Store for Apple Vision Pro, using the metadata you’ve already provided. You can edit your app’s availability at any time in App Store Connect.\n\nCheck whether your existing app is compatible with visionOS\n\nApps made for visionOS\n\nTake advantage of the visionOS SDK in Xcode 15.2 to build new spatial computing experiences for Apple Vision Pro. To learn how to build an app or game that takes advantage of the unique and immersive capabilities of visionOS, view our design and development resources.\n\nWhen you update your existing project for visionOS, the user interface of your app takes on the standard visionOS system appearance and you can add platform-specific capabilities. In most cases, you’ll only need to update your Xcode project’s settings and recompile your code.\n\nTest your app\n\nMake sure your apps work as expected on the latest release by testing on device or in the Simulator. You can submit a request to have your app evaluated directly on Apple Vision Pro by Apple after reviewing the compatibility checklist.\n\nAbout universal purchase\n\nWith universal purchase, people can discover and enjoy your app across their Apple devices with a single purchase. In-app purchases and subscriptions can also easily be set up and shared across platforms.\n\nYour product page will show the other platforms your app supports along with screenshots. And you’ll be able to promote your app using a single URL across your marketing channels.\n\nIf you’d prefer to offer your visionOS app as a separate paid app, simply set up as a new app record in App Store Connect.\n\nLearn about offering universal purchase\n\nCreate your product page\n\nYour product page helps people understand what to expect from your app — and why they should download it.\n\nWhen creating your product page, consult section 2.3 of the App Review Guidelines and accurately represent your app experience. Remember that you’re responsible for securing the content rights for all materials, and that any displayed account information or user data must be fictional.\n\nScreenshots and app previews\n\nScreenshots and app previews are key to conveying your app experience to potential users. Focus on creating high-quality screenshots that make good use of the app’s surroundings.\n\nQuality\nTo capture high-quality screenshots and app previews, use the Developer Capture feature in Reality Composer Pro. Don’t submit screenshots or app previews captured from a screen recording initiated from Control Center, as the recording will be foveated and have limited resolution. Learn more about capturing screenshots and video from Apple Vision Pro for 2D viewing.\nWhen capturing images or video, keep your head in a steady, fixed position. Tip: Sit with your feet flat on the floor and rest your hands on a stable surface.\nIf your app experience relies heavily on hands or specific gestures, you can display a person’s hands in your screenshots or app previews, but otherwise, don’t include them. Show only key motions or gestures — for example, two hands that enlarge a 3D object to reveal additional visual detail. Make sure hand placement doesn’t obstruct any key elements of the app experience.\nSurroundings\nConvey surroundings accurately. Depict your app within a user’s surroundings unless it uses a fully immersive space. This helps people understand they can use passthrough and still interact with people or objects in their physical space.\nWhen capturing, make sure your surroundings are uncluttered and free of any items or materials that may include sensitive content, personal information, or intellectual property. In addition, make sure your surroundings don’t distract from your app.\nIf you’re unable to capture screenshots or app previews using passthrough, you may use a system Environment, though simulating capture (see below) will offer a more differentiated view of your app.\nSimulating capture\n\nYou can simulate captures as long as they accurately depict your app. Use the Apple Design Templates to create simulated assets that accurately represent your app and include proper rendering effects. You can also use Simulator if needed. Before uploading screenshots captured in the Simulator to App Store Connect, you’ll need to resize and crop them to match the upload specifications.\n\nLearn about capturing screenshots and video from Apple Vision Pro for 2D viewing\nLearn about capturing screenshots and videos from Simulator\nDo\nKeep app window straight\nDepict uncluttered surroundings\nCapture clearly rendered (not foveated) images\nDon’t\nTilt or distract from your app window\nDepict cluttered surroundings\nShow foveated rendering\nApp icon\n\nOn visionOS, your app icon appears as a circular 3D object that comprises a background layer and one or two additional layers. App icons can subtly expand when viewed. App icons for compatible iPadOS and iOS apps will appear as square assets with rounded corners. For more about designing your app icon for visionOS, refer to the Human Interface Guidelines.\n\nDescribing your app\n\nYour app name, subtitle, and description should work together to highlight the features and functionality of your app.\n\nApp name: Choose a simple, memorable name that’s easy to spell and hints at what your app does. An app name can be up to 30 characters long and is shared across platforms.\nSubtitle: Use your subtitle to summarize your app and explain its value in greater detail. A subtitle can be up to 30 characters long and is also shared across platforms.\nDescription: The ideal description is a concise, informative paragraph followed by a short list of main features. Description text is specific to your product page on Apple Vision Pro, so be sure to highlight features that are unique to visionOS.\n\nFollow these style guidelines when writing about Apple Vision Pro and visionOS, including when marketing your app outside of the App Store.\n\nApple Vision Pro: Always typeset Apple Vision Pro as three words with an uppercase A, V, and P followed by lowercase letters. Don’t break Apple Vision Pro over two lines. Don’t use the article the before Apple Vision Pro. Apple Vision Pro apps are available on the App Store or can be downloaded from the App Store. It’s acceptable to say Name of app for Apple Vision Pro when your promotion is focused on features and benefits related to Apple Vision Pro. Don’t refer to Apple Vision Pro generically as a “headset.” The phrase “Apple Vision Pro” can’t be included in your app name, but it can be included in your app description.\nvisionOS: visionOS begins with a lowercase v, even when it’s the first word in a sentence.\nSpatial computing: Refer to your app as a spatial computing app. Don’t describe your app experience as augmented reality (AR), virtual reality (VR), extended reality (XR), or mixed reality (MR).\nApp Store: Always typeset App Store with an uppercase A and an uppercase S followed by lowercase letters. Refer to just the App Store unless you need to be more specific; in that case, you can use the App Store for Apple Vision Pro.\n\nAlways set visionOS, Apple Vision Pro, and App Store in English, even when they appear within text in a language other than English. These terms should not be translated or transliterated.\n\nApp motion information\n\nApp Store Connect requires app motion information for visionOS apps. If your app contains movement like quick turns or sudden changes in camera perspective, you’ll need to indicate this in App Store Connect so your app’s product page will show a badge informing people who may be sensitive to these experiences.\n\nLearn about assessing your app for high motion\n\nPrivacy labels\n\nApp Store Connect now includes additional data groupings relevant to visionOS apps: Surroundings and Body. Surroundings includes Environment Scanning, which covers mesh, planes, scene classification, and/or image detection. Body comprises Hands (a person’s hand structure and hand movement) and Head (a person’s head movement).\n\nBe sure to include the practices of any third-party partners whose code is integrated into your app. These details inform the app privacy label that appears on your App Store product page and are required to submit new apps and app updates.\n\nLearn about providing app privacy details\n\nGame controllers\n\nApple Vision Pro supports a maximum of two simultaneous touch events, such as taps. This means that some games designed for iPad and iPhone will need a game controller to provide a good player experience. If this is the case for your game, add the Requires Game Controller badge to your product page by using the GCRequiresControllerUserInteraction key.\n\nSubmit your app\n\nUse App Store Connect to submit your app for review and manage availability. Be sure to follow the App Review Guidelines. Once approved by App Review, your app will be published on the App Store based on your selected availability. And when Apple Vision Pro is available, you can gather valuable user feedback with TestFlight.\n\nIf you’ve built your app for visionOS, you can share your app and development story with us for featuring consideration on the App Store."
  },
  {
    "title": "Plan - visionOS - Apple Developer",
    "url": "https://developer.apple.com/visionos/planning/",
    "html": "Plan your visionOS app\n\nTake a moment to familiarize yourself with the tools and technologies you’ll use to develop apps and games for Apple Vision Pro and visionOS. Apple provides everything you need to get started, and visionOS helps you get the features and performance you want from your apps.\n\nExplore the possibilities\nWhere to start\nHow to take it further\nExplore the possibilities\n\nApple Vision Pro is the first platform designed from the ground up for spatial computing. People use Apple Vision Pro to interact with apps and games on an infinite canvas that blends with their surroundings, or to immerse themselves in a single experience that takes them to new places. Learn how to build apps that take advantage of the unique capabilities of visionOS to reimagine what it means to be connected, productive, and entertained. And learn how to use existing frameworks like SwiftUI, UIKit, RealityKit, and ARKit to bring your app to visionOS:\n\nCreate familiar windows in the Shared Space. Open one or more windows, which are SwiftUI scenes and appear as planes in space. They use traditional views and controls, and you can open one or more of them to manage your app’s content. Your app’s windows appear alongside other apps, and people can resize windows and position them in their surroundings.\nExtend your interface with 3D elements. Add 3D objects or a RealityView to your windows to give them added depth. If you want people to have the ability to view content from all angles, consider creating a volume, which appears in the Shared Space alongside your app’s other windows.\nIncrease the level of immersion. When your app opens a Full Space it takes over the whole visionOS canvas. You can place 3D content directly in the person’s surroundings, open a portal to another world, or replace the person’s surroundings altogether. When a Full Space is open, the system shows your app’s windows and volumes, and hides content from other apps.\n\nWhen you build apps for visionOS, you can mix and match windows, volumes, and spaces at any time in your app to create the right moments for your content. Find key moments in your app where you might want to increase immersion, and provide natural transitions from one level of immersion to another.\n\nPeople can also run your existing iPadOS or iOS app as a compatible app in visionOS. Your app appears as a single, scalable window in the person’s surroundings.\n\nWhere to start\n\nStart the software development process with Xcode — Apple’s integrated development environment. Xcode offers a complete set of tools to develop software, including project management support, code editors, visual editors for your UI, debugging tools, simulators for different devices, tools for assessing performance, and much more. Xcode also includes a complete set of system code modules — called frameworks — for developing your software.\n\nDownload Xcode\n\nTo create a new project in Xcode, choose File > New > Project and follow the prompts to create a visionOS app. All new projects use SwiftUI, which offers a modern declarative programming model to create your app’s core functionality.\n\nSwiftUI works seamlessly with Apple’s data management technologies to support the creation of your content. The Swift standard library and Foundation framework provide structural types such as arrays and dictionaries, and value types for strings, numbers, dates, and other common data values. For any custom types you define, adopt Swift’s Codable support to persist those types to disk. If your app manages larger amounts of structured data, SwiftData, Core Data, and CloudKit offer object-oriented models to manage and persist your data.\n\nYou can also use Unity’s robust, familiar authoring tools to create new apps and games. Get access to all the benefits of visionOS, like passthrough and Dynamically Foveated Rendering, in addition to familiar Unity features like AR Foundation.\n\nAdd a new dimension to your interface\n\nWhen building your app, start with a window and add elements as appropriate to help immerse people in your content. Add a volume to showcase 3D content, or increase the level of immersion using a Full Space. The mixed style configures the space to display passthrough, but you can apply the progressive or full style to increase immersion and minimize distractions.\n\nAdd depth to your windows. Apply depth-based offsets to views to emphasize parts of your window, or to indicate a change in modality. Incorporate 3D objects directly into your view layouts to place them side by side with your 2D views.\nAdd hover effects to custom views. Highlight custom elements when someone looks at them using hover effects. Customize the behavior of your hover effects to achieve the look you want.\nImplement menus and toolbars using ornaments. Place frequently used tools and commands on the outside edge of your windows using ornaments.\n\nRealityKit plays an important role in visionOS apps, and you use it to manage the creation and animation of 3D objects in your apps. Create RealityKit content programmatically, or use Reality Composer Pro to build entire scenes that contain all the objects, animations, sounds, and visual effects you need. Include those scenes in your windows, volumes, or spaces using a RealityView. In addition, take advantage of other 3D features in your apps:\n\nAdopt MaterialX shaders for dynamic effects. MaterialX is an open standard supported by leading film, visual effects, entertainment, and gaming companies. Use existing tools to create MaterialX shaders, and integrate them into your RealityKit scenes using Reality Composer Pro.\nStore 3D content in USDZ files. Build complex 3D objects and meshes using your favorite tools and store them as USDZ assets in your project. Make nondestructive changes to your assets in Reality Composer Pro and combine them into larger scenes.\nCreate previews of your 3D content in Xcode. Preview SwiftUI views with 3D content directly from your project window. Specify multiple camera positions for your Xcode previews to see your content from different angles.\n\nHuman Interface Guidelines\n\nApple’s Human Interface Guidelines offer invaluable information on how to design your app’s interface, navigate content, and manage interactions. Make reading these guidelines a priority in your explorations of the visionOS ecosystem.\n\nDevise straightforward interactions\n\nIn visionOS, people interact with apps primarily using their eyes and hands. In an indirect gesture, someone looks at an object, and then selects it by tapping a finger to their thumb. In a direct gesture, the person’s finger interacts with the object in 3D space. When handling input in your app:\n\nAdopt the standard system gestures. Rely on tap, swipe, drag, touch and hold, double-tap, zoom, and rotate gestures for the majority of interactions with your app. SwiftUI and UIKit provide built-in support for handling these gestures across platforms.\nAdd support for external game controllers. Game controllers offer an alternative form of input to your app. The system automatically directs input from connected wireless keyboards, trackpads, and accessibility hardware to your app’s event-handler code. For game controllers, add support explicitly using the Game Controller framework.\nCreate custom gestures with ARKit. The system uses ARKit to facilitate interactions with the person’s surroundings. When your app moves to a Full Space, you can request permission to retrieve the position of the person’s hands and fingers and use that information to create custom gestures.\n\nIn a Full Space, ARKit provides additional services to support content-related interactions. Detect surfaces and known images in the person’s surroundings and attach anchors to them. Obtain a mesh of the surroundings and add it to your RealityKit scene to enable interactions between your app’s content and real-world objects. Determine the position and orientation of Apple Vision Pro relative to its surroundings and add world anchors to place content.\n\nCreate next-level audio and video\n\nApple Vision Pro supports stereoscopic video to help movies and other entertainment leap off the screen and into the person’s surroundings. Spatial Audio is the default experience in visionOS, so think about how you want to take advantage of that experience.\n\nUpdate video assets for 3D. Take movie night to the next level by playing 3D movies in an immersive 3D environment. The QuickTime file format supports the inclusion of content that appears to jump right off the screen. Play your movies using AVKit and AVFoundation. Include atoms for stereoscopic content in your movie files.\nIncorporate support for Spatial Audio. Build your app’s music player using AVFAudio, which contains the audio-specific types from the AVFoundation framework. Take your audio into another dimension using PHASE, which supports the creation of complex, dynamic Spatial Audio experiences in your games and apps.\nStream live or recorded content. Learn how to create streamed content and deploy it to your server using HTTP Live Streaming. Play back that streamed content from your app using AVFoundation.\nEmbrace inclusion\n\nCreating an inclusive app ensures that everyone can access your content. Apple technologies support inclusivity in many different ways. Make sure to support these technologies throughout your app:\n\nInternationalize and localize your app. Embrace a global market by localizing your app for other regions and languages. Prepare your app using the Foundation framework, which provides code to format strings, dates, times, currencies, and numbers for different languages and regions. Ensure your UI looks good for both left-to-right and right-to-left languages. Localize app resources and add them to your Xcode project. For information about the internationalization and localization process, see Localization.\nChoose inclusive words and terms. Consider social and cultural differences when developing content, and avoid images and terms that have negative or derogatory connotations for portions of your audience. For more information, see Human Interface Guidelines > Inclusion.\nUpdate accessibility labels and navigation. Apple builds accessibility support right into its technologies, but screen readers and other accessibility features rely on the information you provide to create the accessible experience. Review accessibility labels and other descriptions to make sure they provide helpful information, and make sure focus-based navigation is simple and intuitive. See Accessibility.\nSupport alternative ways to access features. Give people alternative ways to select and act on your content, such as menu commands or game controllers. Add accessibility components to RealityKit entities so people can navigate and select them using assistive technologies.\nAdd VoiceOver announcements. When VoiceOver is active in visionOS, people navigate their apps using hand gestures. If they enable Direct Gesture mode to interact with your app instead, announcements make sure they can still follow interactions with your content.\nInclude captions for audio content. Captions are a necessity for some, but are practical for everyone in certain situations. For example, they’re useful to someone watching a video in a noisy environment. Include captions not just for text and dialogue, but also for music and sound effects in your app. Make sure captions you present in a custom video engine adopt the system appearance.\nConsider the impacts of vision and motion. Motion effects can be jarring, even for people who aren’t sensitive to motion. Limit the use of effects that incorporate rapid movement, bouncing or wave-like motion, zooming animations, multi-axis movement, spinning, or rotations. When the system accessibility settings indicate reduced motion is preferred, provide suitable alternatives. See Human Interface Guidelines > Motion.\n\nFor additional information about making apps accessible in visionOS, see Improving accessibility support in your visionOS app.\n\nPrioritize privacy\n\nPrivacy is important, so keep people informed about how you use their data. If you collect data, offer a privacy statement that explains how you use that information. When you use Apple technologies that operate on personal data, include usage descriptions for the system to display on first use. For more information, see Adopting best practices for privacy and user preferences.\n\nProvide a tangible benefit for any data you collect. When someone agrees to give you their personal information, make sure your app delivers real value in return. Don’t collect someone’s personal data just to have it.\nExplain clearly how you use the information you collect. Be transparent with how you use people’s data. When requesting authorization for privacy-sensitive technologies, provide clear usage description strings that help someone understand why you need the data. Explain the data on your app’s page on the App Store.\nSecure the data you collect and store. If you do collect data, make sure you protect that data from malicious attacks. Adopt passkeys as a secure alternative to passwords. Store personally identifiable information, financial data, or other sensitive data in the user’s encrypted Keychain. Use on-disk encryption or other Apple security technologies to store other personal data. Use Apple CryptoKit to encrypt data that you store locally or send outside your app.\nTest and tune your app\n\nThere are multiple ways you can test your app during development and make sure it runs well on Apple Vision Pro.\n\nTest and debug your app thoroughly. During development, debug problems as they arise using the built-in Xcode debugger. Build automated test suites using XCTest and run them during every build to validate that new code works as expected. Run those tests under different system loads to determine how your app behaves.\nBe mindful of how much work you do. Make sure the work your app performs offers a tangible benefit. Optimize algorithms to minimize your app’s consumption of CPU and GPU resources. Identify bottlenecks and other performance issues in your code using the Instruments app that comes with Xcode. See Creating a performance plan for your visionOS app.\nAdopt a continuous integration (CI) workflow. Adopt a CI mindset by making sure every commit maintains the quality and stability of your code base. Run performance-related tests as part of your test suite. Use the continuous integration system of Xcode Cloud to automate builds, test cycles, and the distribution of your apps to your QA teams.\nHow to take it further\n\nOnce you have an app up and running, look for additional ways to improve the experience. Little things can make a big difference, whether it’s adding a particular feature, or approaching your content in a different way.\n\nConnect people using SharePlay. Sharing and collaboration are an important part of visionOS, so brainstorm which of your app’s activities to make available over FaceTime. Use the Group Activities framework to add support for starting activities and managing updates.\nDesign SharePlay activities for Spatial Personas. Identify moments in your app that can support SharePlay for Spatial Personas and synchronize additional details needed to maintain the shared context. For example, you might want to share the scroll position of a window in addition to the window’s contents.\nExplore more\n\nLearn more about technologies that provide unique capabilities, yet integrate tightly with Apple platforms to form a seamless ecosystem for apps and games across iOS, iPadOS, macOS, tvOS, visionOS, and watchOS."
  },
  {
    "title": "visionOS - Apple Developer",
    "url": "https://developer.apple.com/visionos/#",
    "html": "Discover visionOS\n\nAll-new platform. Familiar frameworks and tools. Get ready to design and build an entirely new universe of apps and games for Apple Vision Pro.\n\nA spectrum of immersion\n\nApple Vision Pro offers an infinite spatial canvas to explore, experiment, and play, giving you the freedom to completely rethink your experience in 3D. People can interact with your app while staying connected to their surroundings, or immerse themselves completely in a world of your creation. And your experiences can be fluid: start in a window, bring in 3D content, transition to a fully immersive scene, and come right back.\n\nThe choice is yours, and it all starts with the building blocks of spatial computing in visionOS.\n\nWindows\n\nYou can create one or more windows in your visionOS app. They’re built with SwiftUI and contain traditional views and controls, and you can add depth to your experience by adding 3D content.\n\nVolumes\n\nAdd depth to your app with a 3D volume. Volumes are SwiftUI scenes that can showcase 3D content using RealityKit or Unity, creating experiences that are viewable from any angle in the Shared Space or an app’s Full Space.\n\nSpaces\n\nBy default, apps launch into the Shared Space, where they exist side by side — much like multiple apps on a Mac desktop. Apps can use windows and volumes to show content, and the user can reposition these elements wherever they like. For a more immersive experience, an app can open a dedicated Full Space where only that app’s content will appear. Inside a Full Space, an app can use windows and volumes, create unbounded 3D content, open a portal to a different world, or even fully immerse people in an environment.\n\nApple frameworks — extended for spatial computing\nSwiftUI\n\nWhether you’re creating windows, volumes, or spatial experiences, SwiftUI is the best way to build a new visionOS app or bring your existing iPadOS or iOS app to the platform. With all-new 3D capabilities and support for depth, gestures, effects, and immersive scene types, SwiftUI can help you build beautiful and compelling apps for Apple Vision Pro. RealityKit is also deeply integrated with SwiftUI to help you build sharp, responsive, and volumetric interfaces. SwiftUI also works seamlessly with UIKit to help you build apps for visionOS.\n\nRealityKit\n\nPresent 3D content, animations, and visual effects in your app with RealityKit, Apple’s 3D rendering engine. RealityKit can automatically adjust to physical lighting conditions and cast shadows, open portals to a different world, build stunning visual effects, and so much more. And for authoring your materials, RealityKit has adopted MaterialX, an open standard for specifying surface and geometry shaders used by leading film, visual effects, entertainment, and gaming companies.\n\nARKit\n\nOn Apple Vision Pro, ARKit can fully understand a person’s surroundings, giving your apps new ways to interact with the space around them. By default, ARKit powers core system capabilities that your apps automatically benefit from when they’re in the Shared Space — but when your app moves to a Full Space and asks permission, you can take advantage of powerful ARKit APIs, like Plane Estimation, Scene Reconstruction, Image Anchoring, World Tracking, and Skeletal Hand Tracking. So splash water on a wall. Bounce a ball off the floor. Make experiences that wow people by blending the real world with your content.\n\nAccessibility\n\nvisionOS is designed with accessibility in mind for people who want to interact with their device entirely with their eyes, voice, or a combination of both. And for people who prefer a different way to navigate content, Pointer Control lets them select their index finger, wrist, or head as an alternative pointer. You can create accessible apps for visionOS using the same techniques and tools you already use on other Apple platforms and help make Apple Vision Pro a great experience for everyone.\n\nAll the tools you need\nXcode\n\nDevelopment for visionOS starts with Xcode, which supports the visionOS SDK. Add a visionOS target to your existing project or build an entirely new app. Iterate on your app in Xcode Previews. Interact with your app in the all-new visionOS simulator and explore various room layouts and lighting conditions. Create tests and visualizations to explore collisions, occlusions, and scene understanding for your spatial content.\n\nDownload the latest version of Xcode\n\nReality Composer Pro\n\nDiscover the all-new Reality Composer Pro, designed to make it easy to preview and prepare 3D content for your visionOS apps. Available with Xcode, Reality Composer Pro can help you import and organize assets, such as 3D models, materials, and sounds. Best of all, it integrates tightly with the Xcode build process to preview and optimize your visionOS assets.\n\nUnity\n\nNow you can use Unity’s robust and familiar authoring tools to create new apps and games or reimagine your existing Unity-created projects for visionOS. Your apps get access to all the benefits of visionOS, like passthrough and Dynamically Foveated Rendering, in addition to familiar Unity features, like AR Foundation. By combining Unity’s authoring and simulation capabilities with RealityKit-managed app rendering, content created with Unity looks and feels at home in visionOS.\n\nLearn more\n\nYour visionOS journey begins here\n\nStart developing with the visionOS SDK, Xcode, the visionOS simulator, Reality Composer Pro, documentation, sample code, design guidance, and more.\n\nPlan for visionOS\n\nWhether you already have an app on the App Store or it’s your first time developing for Apple platforms, there’s a lot you can do to get ready for creating apps for visionOS. Discover how you can make updates to your app today and explore existing frameworks that make it even easier for you to start developing for visionOS.\n\nPlan for visionOS\n\nLearn about visionOS\n\nWith best-in-class frameworks and tools, visionOS is the perfect platform to help you create incredible spatial experiences. Whether you’re dreaming up a game, building a media experience, designing moments of connection and collaboration with SharePlay, creating apps for business, or updating your website to support visionOS, we’ve got sessions and information to help you make your plan. Get ready for the visionOS SDK with 46 WWDC23 sessions to help you learn about developing for the platform, designing for spatial experiences, and testing and tools.\n\nLearn about visionOS\n\nSubmit your app\n\nWhether you’ve created a new visionOS app or are making your existing iPad or iPhone app available on Apple Vision Pro, here’s everything you need to know to prepare and submit your app to the App Store.\n\nSubmit your app\n\nWork with Apple\n\nGet direct support from Apple as you develop your apps and games for visionOS. Learn about upcoming events, testing opportunities, and other programs to support you as you create incredible experiences for this platform.\n\nLearn about working with Apple\n\nFeatured articles\nBlackbox: Rebooting an inventive puzzle game for visionOS\n\nThe incredible puzzler comes to the infinite canvas.\n\nLearn more\n“The full impact of fruit destruction”\n\nHow Halfbrick cultivated Super Fruit Ninja on Apple Vision Pro.\n\nLearn more\nRealizing their vision: How djay designed for visionOS\n\nThe team behind djay reveals why Apple Vision Pro represents “the culmination of everything” for their app.\n\nLearn more\nQ&A: Building apps for visionOS\n\nGet advice directly from Apple experts on creating incredible apps and games for Apple Vision Pro.\n\nLearn more"
  },
  {
    "title": "visionOS - Apple Developer",
    "url": "https://developer.apple.com/visionos/",
    "html": "Discover visionOS\n\nAll-new platform. Familiar frameworks and tools. Get ready to design and build an entirely new universe of apps and games for Apple Vision Pro.\n\nA spectrum of immersion\n\nApple Vision Pro offers an infinite spatial canvas to explore, experiment, and play, giving you the freedom to completely rethink your experience in 3D. People can interact with your app while staying connected to their surroundings, or immerse themselves completely in a world of your creation. And your experiences can be fluid: start in a window, bring in 3D content, transition to a fully immersive scene, and come right back.\n\nThe choice is yours, and it all starts with the building blocks of spatial computing in visionOS.\n\nWindows\n\nYou can create one or more windows in your visionOS app. They’re built with SwiftUI and contain traditional views and controls, and you can add depth to your experience by adding 3D content.\n\nVolumes\n\nAdd depth to your app with a 3D volume. Volumes are SwiftUI scenes that can showcase 3D content using RealityKit or Unity, creating experiences that are viewable from any angle in the Shared Space or an app’s Full Space.\n\nSpaces\n\nBy default, apps launch into the Shared Space, where they exist side by side — much like multiple apps on a Mac desktop. Apps can use windows and volumes to show content, and the user can reposition these elements wherever they like. For a more immersive experience, an app can open a dedicated Full Space where only that app’s content will appear. Inside a Full Space, an app can use windows and volumes, create unbounded 3D content, open a portal to a different world, or even fully immerse people in an environment.\n\nApple frameworks — extended for spatial computing\nSwiftUI\n\nWhether you’re creating windows, volumes, or spatial experiences, SwiftUI is the best way to build a new visionOS app or bring your existing iPadOS or iOS app to the platform. With all-new 3D capabilities and support for depth, gestures, effects, and immersive scene types, SwiftUI can help you build beautiful and compelling apps for Apple Vision Pro. RealityKit is also deeply integrated with SwiftUI to help you build sharp, responsive, and volumetric interfaces. SwiftUI also works seamlessly with UIKit to help you build apps for visionOS.\n\nRealityKit\n\nPresent 3D content, animations, and visual effects in your app with RealityKit, Apple’s 3D rendering engine. RealityKit can automatically adjust to physical lighting conditions and cast shadows, open portals to a different world, build stunning visual effects, and so much more. And for authoring your materials, RealityKit has adopted MaterialX, an open standard for specifying surface and geometry shaders used by leading film, visual effects, entertainment, and gaming companies.\n\nARKit\n\nOn Apple Vision Pro, ARKit can fully understand a person’s surroundings, giving your apps new ways to interact with the space around them. By default, ARKit powers core system capabilities that your apps automatically benefit from when they’re in the Shared Space — but when your app moves to a Full Space and asks permission, you can take advantage of powerful ARKit APIs, like Plane Estimation, Scene Reconstruction, Image Anchoring, World Tracking, and Skeletal Hand Tracking. So splash water on a wall. Bounce a ball off the floor. Make experiences that wow people by blending the real world with your content.\n\nAccessibility\n\nvisionOS is designed with accessibility in mind for people who want to interact with their device entirely with their eyes, voice, or a combination of both. And for people who prefer a different way to navigate content, Pointer Control lets them select their index finger, wrist, or head as an alternative pointer. You can create accessible apps for visionOS using the same techniques and tools you already use on other Apple platforms and help make Apple Vision Pro a great experience for everyone.\n\nAll the tools you need\nXcode\n\nDevelopment for visionOS starts with Xcode, which supports the visionOS SDK. Add a visionOS target to your existing project or build an entirely new app. Iterate on your app in Xcode Previews. Interact with your app in the all-new visionOS simulator and explore various room layouts and lighting conditions. Create tests and visualizations to explore collisions, occlusions, and scene understanding for your spatial content.\n\nDownload the latest version of Xcode\n\nReality Composer Pro\n\nDiscover the all-new Reality Composer Pro, designed to make it easy to preview and prepare 3D content for your visionOS apps. Available with Xcode, Reality Composer Pro can help you import and organize assets, such as 3D models, materials, and sounds. Best of all, it integrates tightly with the Xcode build process to preview and optimize your visionOS assets.\n\nUnity\n\nNow you can use Unity’s robust and familiar authoring tools to create new apps and games or reimagine your existing Unity-created projects for visionOS. Your apps get access to all the benefits of visionOS, like passthrough and Dynamically Foveated Rendering, in addition to familiar Unity features, like AR Foundation. By combining Unity’s authoring and simulation capabilities with RealityKit-managed app rendering, content created with Unity looks and feels at home in visionOS.\n\nLearn more\n\nYour visionOS journey begins here\n\nStart developing with the visionOS SDK, Xcode, the visionOS simulator, Reality Composer Pro, documentation, sample code, design guidance, and more.\n\nPlan for visionOS\n\nWhether you already have an app on the App Store or it’s your first time developing for Apple platforms, there’s a lot you can do to get ready for creating apps for visionOS. Discover how you can make updates to your app today and explore existing frameworks that make it even easier for you to start developing for visionOS.\n\nPlan for visionOS\n\nLearn about visionOS\n\nWith best-in-class frameworks and tools, visionOS is the perfect platform to help you create incredible spatial experiences. Whether you’re dreaming up a game, building a media experience, designing moments of connection and collaboration with SharePlay, creating apps for business, or updating your website to support visionOS, we’ve got sessions and information to help you make your plan. Get ready for the visionOS SDK with 46 WWDC23 sessions to help you learn about developing for the platform, designing for spatial experiences, and testing and tools.\n\nLearn about visionOS\n\nSubmit your app\n\nWhether you’ve created a new visionOS app or are making your existing iPad or iPhone app available on Apple Vision Pro, here’s everything you need to know to prepare and submit your app to the App Store.\n\nSubmit your app\n\nWork with Apple\n\nGet direct support from Apple as you develop your apps and games for visionOS. Learn about upcoming events, testing opportunities, and other programs to support you as you create incredible experiences for this platform.\n\nLearn about working with Apple\n\nFeatured articles\nBlackbox: Rebooting an inventive puzzle game for visionOS\n\nThe incredible puzzler comes to the infinite canvas.\n\nLearn more\n“The full impact of fruit destruction”\n\nHow Halfbrick cultivated Super Fruit Ninja on Apple Vision Pro.\n\nLearn more\nRealizing their vision: How djay designed for visionOS\n\nThe team behind djay reveals why Apple Vision Pro represents “the culmination of everything” for their app.\n\nLearn more\nQ&A: Building apps for visionOS\n\nGet advice directly from Apple experts on creating incredible apps and games for Apple Vision Pro.\n\nLearn more"
  }
]